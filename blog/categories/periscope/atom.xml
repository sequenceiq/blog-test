<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Periscope | SequenceIQ Blog]]></title>
  <link href="http://blog.sequenceiq.com/blog/categories/periscope/atom.xml" rel="self"/>
  <link href="http://blog.sequenceiq.com/"/>
  <updated>2014-11-20T22:23:40+00:00</updated>
  <id>http://blog.sequenceiq.com/</id>
  <author>
    <name><![CDATA[SequenceIQ]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Real-time adjustments with Hadoop metrics]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/10/15/hadoop-metrics/"/>
    <updated>2014-10-15T13:56:32+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/10/15/hadoop-metrics</id>
    <content type="html"><![CDATA[<p>To properly understand and to be fully aware of the state of our Hadoop clusters at any time we needed a scalable and flexible solution
to monitor our Hadoop nodes. After investigating the possible solutions we realized that there is no available solution which satisfies
all our needs thus we&rsquo;ve created one and recently just open sourced it, called <a href="http://sequenceiq.com/periscope/#monitoring">Baywatch</a>. Baywatch is capable to capture and visualize real-time changes on Hadoop clusters to understand and make adjustments based on the submitted jobs resource
allocation needs. To plan ahead, viewing and comparing old and new metrics is just as
important as analyzing real-time ones, not to mention that we can find possible weaknesses and defects in our clusters.</p>

<p>To be able to do all of the above mentioned, Baywatch processes the metrics information produced by the Hadoop daemons. This might already sound familiar as we have another project called <a href="http://sequenceiq.com/periscope/">Periscope</a> where you can create alarms and cluster scaling activities making use of the same metrics, but just consuming it in a different way. Combine these 2
components and you&rsquo;ll have a powerful tool and you&rsquo;ll be able to view your cluster&rsquo;s state and based on that <code>make smart decisions</code>
to scale up or down, or simply just set alarms. If you&rsquo;re thrilled to see it in action we are at <a href="http://strataconf.com/stratany2014">Strata</a> and happy to show you a quick demo.</p>

<h2>Hadoop metrics</h2>

<p>So what are these metrics? As I mentioned it earlier metrics are collections of information about Hadoop daemons, e.g:
the <code>ResourceManager</code> produces information about the queue statuses which we use in Periscope when we <code>re-prioritise applications</code>.
To distinguish these metrics they are grouped into named contexts, e.g <code>jvm</code> for java virtual machine metrics, <code>rpc</code> for debugging
rcp calls, but there are many more:</p>

<ul>
<li>yarn</li>
<li>rpcdetailed</li>
<li>metricssystem</li>
<li>mapred</li>
<li>dfs</li>
<li>ugi</li>
</ul>


<p>This <code>Metrics2</code> framework is designed to collect and dispatch per-process metrics to monitor the overall status of the Hadoop system.
In Hadoop related technologies it is a common design to use sources and sinks, just like in this case. Metrics sources are where the
metrics are generated and metrics sinks consume the records generated by the metrics sources. A metrics system would poll the metrics
sources periodically and pass the metrics records to metrics sinks.</p>

<p><img class="<a" src="href="http://yuml.me/0faf3738">http://yuml.me/0faf3738</a>"></p>

<!-- more -->


<p>It is really easy to implement new sinks and sources, just for reference here&rsquo;s the <code>FileSink</code>:
```java
  @Override
  public void putMetrics(MetricsRecord record) {</p>

<pre><code>writer.print(record.timestamp());
writer.print(" ");
writer.print(record.context());
writer.print(".");
writer.print(record.name());
String separator = ": ";
for (MetricsTag tag : record.tags()) {
  writer.print(separator);
  separator = ", ";
  writer.print(tag.name());
  writer.print("=");
  writer.print(tag.value());
}
for (AbstractMetric metric : record.metrics()) {
  writer.print(separator);
  separator = ", ";
  writer.print(metric.name());
  writer.print("=");
  writer.print(metric.value());
}
writer.println();
</code></pre>

<p>  }
<code>
and the `FairSchedulerQueueMetrics`:
</code>java
  @Metric(&ldquo;Fair share of memory in MB&rdquo;) MutableGaugeInt fairShareMB;
  @Metric(&ldquo;Fair share of CPU in vcores&rdquo;) MutableGaugeInt fairShareVCores;
  @Metric(&ldquo;Steady fair share of memory in MB&rdquo;) MutableGaugeInt steadyFairShareMB;
  @Metric(&ldquo;Steady fair share of CPU in vcores&rdquo;) MutableGaugeInt steadyFairShareVCores;
  @Metric(&ldquo;Minimum share of memory in MB&rdquo;) MutableGaugeInt minShareMB;
  @Metric(&ldquo;Minimum share of CPU in vcores&rdquo;) MutableGaugeInt minShareVCores;
  @Metric(&ldquo;Maximum share of memory in MB&rdquo;) MutableGaugeInt maxShareMB;
  @Metric(&ldquo;Maximum share of CPU in vcores&rdquo;) MutableGaugeInt maxShareVCores;
```
Hadoop comes by default with 3 sinks:</p>

<ul>
<li>FileSink</li>
<li>GraphiteSink</li>
<li>GangliaSink30</li>
</ul>


<h2>Configuration</h2>

<p>The Metrics2 framework uses the <code>PropertiesConfiguration</code> thus the metrics sinks needs to be defined in a configuration-file:
<code>hadoop-metrics2.properties</code>. The declaration should be familiar for those who used <code>Apache Flume</code> before. Here is an example
taken from our <a href="link">Ambari docker image</a>:
<code>
*.sink.logstash.class=org.apache.hadoop.metrics2.sink.FileSink
namenode.sink.logstash.filename=/var/log/hadoop-metrics/namenode-metrics.out
secondarynamenode.sink.logstash.filename=/var/log/hadoop-metrics/secondarynamenode-metrics.out
datanode.sink.logstash.filename=/var/log/hadoop-metrics/datanode-metrics.out
resourcemanager.sink.logstash.filename=/var/log/hadoop-metrics/resourcemanager-metrics.out
nodemanager.sink.logstash.filename=/var/log/hadoop-metrics/nodemanager-metrics.out
maptask.sink.logstash.filename=/var/log/hadoop-metrics/maptask-metrics.out
reducetask.sink.logstash.filename=/var/log/hadoop-metrics/reducetask-metrics.out
mrappmaster.sink.logstash.filename=/var/log/hadoop-metrics/mrappmaster-metrics.out
</code></p>

<h3>Hadoop WebServices</h3>

<p>There is another way to obtain these metrics without any configuration which the Periscope leverages. It&rsquo;s the <code>WebServices</code> provided
by Hadoop. <code>Jax-RS</code> is used to define the mappings, e.g collect the <code>ResourceManager</code> queue related metrics on mapping <code>/ws/v1/cluster</code>:
```java
  @GET
  @Path(&ldquo;/scheduler&rdquo;)
  @Produces({ MediaType.APPLICATION_JSON, MediaType.APPLICATION_XML })
  public SchedulerTypeInfo getSchedulerInfo() {</p>

<pre><code>init();
ResourceScheduler rs = rm.getResourceScheduler();
SchedulerInfo sinfo;
if (rs instanceof CapacityScheduler) {
  CapacityScheduler cs = (CapacityScheduler) rs;
  CSQueue root = cs.getRootQueue();
  sinfo = new CapacitySchedulerInfo(root);
} else if (rs instanceof FairScheduler) {
  FairScheduler fs = (FairScheduler) rs;
  sinfo = new FairSchedulerInfo(fs);
} else if (rs instanceof FifoScheduler) {
  sinfo = new FifoSchedulerInfo(this.rm);
} else {
  throw new NotFoundException("Unknown scheduler configured");
}
return new SchedulerTypeInfo(sinfo);
</code></pre>

<p>  }
```
The only difference is that you&rsquo;re application have to poll now, while the other way you can create forwarders to create push events
just like we did with Baywatch. To which to use depends on you&rsquo;re needs.</p>

<h2>Summary and resources</h2>

<p>As you see using <strong>Baywatch</strong> and <strong>Periscope</strong> you can monitor and scale your cluster based on the configured policies &ndash; all available open sources in our <a href="https://github.com/sequenceiq">GitHub</a> page.</p>

<ul>
<li><a href="http://sequenceiq.com/periscope/">Periscope</a></li>
<li><a href="https://github.com/sequenceiq/docker-baywatch-client">Baywatch client</a></li>
<li><a href="https://github.com/sequenceiq/docker-baywatch">Baywatch</a></li>
</ul>


<p>For updates follow us
on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or
<a href="https://www.facebook.com/sequenceiq">Facebook</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SLA policies for autoscaling Hadoop clusters]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/09/01/sla-samples-periscope/"/>
    <updated>2014-09-01T16:37:37+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/09/01/sla-samples-periscope</id>
    <content type="html"><![CDATA[<p>Last week we have <a href="http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/">announced</a> and open sourced <a href="http://sequenceiq.com/periscope/">Periscope</a> &ndash; the industry’s first SLA policy based autoscaling API for Hadoop YARN clusters. In this post we’d like to come up with some examples, setting up alarms and attach scaling policies to your Hadoop cluster.</p>

<p>Periscope is built on existing (and coming/contributed by us) features provided by Apache Hadoop, YARN, Ambari, Docker containers and SequenceIQ’s <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a>. Just FYI, <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a> is our open source and cloud agnostic Hadoop as a Service API, built on Docker containers. While Periscope can attach scaling policies to <code>static</code> and <code>dynamic</code> clusters &ndash; in this post we’d like to emphasize Periscope’s capabilities while working with &mdash; `dynamic &ndash; cloud based Hadoop deployments  &ndash; such as Hadoop clusters deployed with <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a>.</p>

<p>SLAs policies are configured based on <code>alarms</code>, whereas an alarm is created based on <code>metrics</code> &ndash; these entities are explained below.</p>

<h2>Alarms</h2>

<p>An alarm watches a <code>metric</code> over a specified time period, and used by one or more action or scaling policy based on the value of the metric relative to a given threshold over the time period. A few of the supported <code>metrics</code> are listed below:</p>

<p>*<code>PENDING_CONTAINERS</code>&ndash; pending YARN containers</p>

<p>*<code>PENDING_APPLICATIONS</code> &ndash; pending/queued YARN applications</p>

<p>*<code>LOST_NODES</code> &ndash; cluster nodes lost</p>

<p>*<code>UNHEALTHY_NODES</code> &ndash; unhealthy cluster nodes</p>

<p>*<code>GLOBAL_RESOURCES</code> &ndash; global resources</p>

<!--more-->


<p>Measured <code>metrics</code> are compared with pre-configured values using operators. The <code>comparison operators</code> are: <code>LESS_THAN</code>, <code>GREATER_THAN</code>, <code>LESS_OR_EQUAL_THAN</code>, <code>GREATER_OR_EQUAL_THAN</code>, <code>EQUALS</code>.
In order to avoid reacting for sudden spikes in the system and apply policies only in case of a sustained system stress, <code>alarms</code> have to be sustained over a <code>period</code> of time.  The <code>period</code> specifies the time period in minutes during the alarm has to be sustained. Also a <code>threshold</code> can be configured, which specifies the variance applied by the operator for the selected <code>metric</code>.</p>

<p>For the <code>alarm</code> related REST operations you can check the <a href="http://docs.periscope.apiary.io/reference/alarms">API</a> documentation. Alarms can issue <code>notifications</code> as well &ndash; for example if a metric is reached for the configured time and threshold a notification event is raised &ndash; in the given example below this notification is an email.</p>

<p>```</p>

<h1>set metric alarms</h1>

<p>curl -X POST -H &ldquo;Content-Type: application/json&rdquo; -d &lsquo;{&ldquo;alarms&rdquo;:[{&ldquo;alarmName&rdquo;:&ldquo;pendingContainerHigh&rdquo;,&ldquo;description&rdquo;:&ldquo;Number of pending containers is high&rdquo;,&ldquo;metric&rdquo;:&ldquo;PENDING_CONTAINERS&rdquo;,&ldquo;threshold&rdquo;:10,&ldquo;comparisonOperator&rdquo;:&ldquo;GREATER_THAN&rdquo;,&ldquo;period&rdquo;:1},{&ldquo;alarmName&rdquo;:&ldquo;freeGlobalResourcesRateLow&rdquo;,&ldquo;description&rdquo;:&ldquo;Low free global resource rate&rdquo;,&ldquo;metric&rdquo;:&ldquo;GLOBAL_RESOURCES&rdquo;,&ldquo;threshold&rdquo;:1,&ldquo;comparisonOperator&rdquo;:&ldquo;EQUALS&rdquo;,&ldquo;period&rdquo;:1,&ldquo;notifications&rdquo;:[{&ldquo;target&rdquo;:[“<a href="&#109;&#97;&#105;&#108;&#116;&#111;&#x3a;&#x6d;&#x69;&#99;&#107;&#x2e;&#x66;&#97;&#x6e;&#x6e;&#x69;&#x6e;&#103;&#x40;&#x61;&#x73;&#x70;&#x77;&#x6f;&#x72;&#x6c;&#100;&#116;&#x6f;&#x75;&#114;&#x2e;&#99;&#111;&#109;">&#109;&#x69;&#x63;&#107;&#46;&#x66;&#x61;&#x6e;&#x6e;&#105;&#x6e;&#103;&#64;&#x61;&#115;&#x70;&#119;&#x6f;&#114;&#108;&#100;&#x74;&#111;&#117;&#114;&#46;&#x63;&#111;&#109;</a>"],&ldquo;notificationType&rdquo;:&ldquo;EMAIL&rdquo;}]}]}&rsquo; localhost:8081/clusters/1/alarms | jq .
curl -X PUT -H &ldquo;Content-Type: application/json&rdquo; -d &lsquo;{&ldquo;alarmName&rdquo;:&ldquo;unhealthyNodesHigh&rdquo;,&ldquo;description&rdquo;:&ldquo;Number of unhealthy nodes is high&rdquo;,&ldquo;metric&rdquo;:&ldquo;UNHEALTHY_NODES&rdquo;,&ldquo;threshold&rdquo;:5,&ldquo;comparisonOperator&rdquo;:&ldquo;GREATER_OR_EQUAL_THAN&rdquo;,&ldquo;period&rdquo;:5}&rsquo; localhost:8081/clusters/1/alarms | jq .
```</p>

<h2>SLA scaling policies</h2>

<p>Scaling is the ability to increase or decrease the capacity of the Hadoop cluster or application.  When scaling policies are used, the capacity is automatically increased or decreased according to the conditions defined.
Periscope will do the heavy lifting and based on the alarms and the scaling policy linked to them it executes the associated policy. By default a fully configured and running <a href="https://cloudbreak.sequenceiq.com/">Cloudbreak</a> cluster contains no SLA policies.  An SLA scaling policy can contain multiple <code>alarms</code>.</p>

<p>As an alarm is triggered a <code>scalingAdjustment</code> is applied, however to keep the cluster size within boundaries a <code>minSize</code> and <code>maxSize</code> is attached to the cluster &ndash; thus a scaling policy can never over or undersize a cluster. Also in order to avoid stressing the cluster we have introduced a <code>cooldown</code> period (minutes) &ndash; though an alarm is raised and there is an associated scaling policy, the system will not apply the policy within the configured timeframe. In an SLA scaling policy the triggered policies are applied in order.</p>

<p>Hosts can be added or removed from specific <code>hostgroups</code>. Periscope and Cloudbreak uses Apache Ambari to provision a Hadoop cluster. Ambari host groups are a set of machines with the same Hadoop “components” installed. You can set up a cluster having different hostgroups &ndash; and run different services, thus having a heterogenous cluster.</p>

<p>In the following example we downscale a cluster when the unused resources are high.</p>

<p>```</p>

<h1>set scaling policy</h1>

<p>curl -X POST -H &ldquo;Content-Type: application/json&rdquo; -d &lsquo;{&ldquo;minSize&rdquo;:2,&ldquo;maxSize&rdquo;:10,&ldquo;cooldown&rdquo;:30,&ldquo;scalingPolicies&rdquo;:[{&ldquo;name&rdquo;:&ldquo;downScaleWhenHighResource&rdquo;,&ldquo;adjustmentType&rdquo;:&ldquo;NODE_COUNT&rdquo;,&ldquo;scalingAdjustment&rdquo;:2,&ldquo;hostGroup&rdquo;:&ldquo;slave_1&rdquo;,&ldquo;alarmId&rdquo;:&ldquo;101&rdquo;},{&ldquo;name&rdquo;:&ldquo;upScaleWhenHighPendingContainers&rdquo;,&ldquo;adjustmentType&rdquo;:&ldquo;PERCENTAGE&rdquo;,&ldquo;scalingAdjustment&rdquo;:40,&ldquo;hostGroup&rdquo;:&ldquo;slave_1&rdquo;,&ldquo;alarmId&rdquo;:&ldquo;100&rdquo;}]}&rsquo; localhost:8081/clusters/1/policies | jq .
```</p>

<p>For the <code>policy</code> related REST operations you can check the <a href="http://docs.periscope.apiary.io/reference/scaling-policy">API</a> documentation.</p>

<p>Let us know how Periscope works for you &ndash; and for updates follow us on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook.com/sequenceiq">Facebook</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Periscope - autoscaling for Hadoop YARN]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/"/>
    <updated>2014-08-27T16:37:37+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope</id>
    <content type="html"><![CDATA[<p><em>Periscope is a powerful, fast, thick and top-to-bottom right-hander, eastward from Sumbawa&rsquo;s famous west-coast. Timing is critical, as needs a number of elements to align before it shows its true colors.</em></p>

<p><em>Periscope brings QoS and autoscaling to Hadoop YARN. Built on cloud resource management and YARN schedulers, allows to associate SLA policies to applications.</em></p>

<p>After the very positive reception of <a href="https://cloudbreak.sequenceiq.com/">Cloudbreak</a> &ndash; the first open source and cloud agnostic Hadoop as a Service API &ndash; today we are releasing the <code>public beta</code> version of our open source <strong>SLA policy based autoscaling API</strong> for Hadoop YARN clusters.</p>

<h2>Overview</h2>

<p>The purpose of Periscope is to bring QoS and autoscaling to a multi-tenant Hadoop YARN cluster, while allowing to apply SLA policies to individual applications.
At <a href="http://sequenceiq.com">SequenceIQ</a> working with multi-tenant Hadoop clusters for quite a while, we have always seen the same frustration and fight for resource between users.
The <strong>FairScheduler</strong> was partially solving this problem &ndash; bringing in fairness based on the notion of <a href="http://static.usenix.org/event/nsdi11/tech/full_papers/Ghodsi.pdf">Dominant Resource Fairness</a>.
With the emergence of Hadoop 2 YARN and the <strong>CapacityScheduler</strong> we had the option to maximize throughput and utilization for a multi-tenant cluster in an operator-friendly manner.
The scheduler works around the concept of queues. These queues are typically setup by administrators to reflect the economics of the shared cluster.
While this is a pretty good abstraction and brings some level of SLA for predictable workloads, it often needs proper design ahead.
The queue hierarchy and resource allocation needs to be changed when new tenants and workloads are moved to the cluster.</p>

<p>Periscope was designed around the idea of <code>autoscaling</code> clusters &ndash; without any need to preconfigure queues, cluster nodes or apply capacity planning ahead.</p>

<!--more-->


<h2>How it works</h2>

<p>Periscope monitors the application progress, the number of YARN containers/resources and their allocation, queue depths, the number of available cluster nodes and their health.
Since we have switched to YARN a while ago (been among the first adopters) we have run an open source <a href="https://github.com/sequenceiq/yarn-monitoring">monitoring project</a>, based on R.
We have been collecting metrics from the YARN Timeline server, Hadoop Metrics2 and Ambari&rsquo;s Nagios/Ganglia &ndash; and profiling the applications and correlating with these metrics.
One of the key findings was that while low level metrics are good to understand the cluster health &ndash; they might not necessarily help on making decisions when applying different SLA policies on a multi-tenant cluster.
Focusing on higher level building blocks as queue depth, YARN containers, etc actually brings in the same quality of service, while not being lost in low level details.</p>

<p>Periscope works with two types of Hadoop clusters: <code>static</code> and <code>dynamic</code>. Periscope does not require any pre-installation &ndash; the only thing it requires is to be <code>attached</code> to an Ambari server&rsquo;s REST API.</p>

<h2>Clusters</h2>

<h3>Static clusters</h3>

<p>From Periscope point of view we consider a cluster <code>static</code> when the cluster capacity can&rsquo;t be increased horizontally.
This means that the hardware resources are already given &ndash; and the throughput can&rsquo;t be increased by adding new nodes.
Periscope introspects the job submission process, monitors the applications and applies the following SLAs:</p>

<ol>
<li> Application ordering &ndash; can guarantee that a higher priority application finishes before another one (supporting parallel or sequential execution)</li>
<li> Moves running applications between priority queues</li>
<li> <em>Attempts</em> to enforce time based SLA (execution time, finish by, finish between, recurring)</li>
<li> <em>Attempts</em> to enforce guaranteed cluster capacity requests ( x % of the resources)</li>
<li> Support for distributed (but not YARN ready) applications using Apache Slider</li>
<li> Attach priorities to SLAs</li>
</ol>


<p><em>Note: not all of the features above are supported in the first <code>public beta</code> version. There are dependencies we contributed to Hadoop, YARN and Ambari and they will be included in the next releases (2.6 and 1.7)</em></p>

<h3>Autoscaling clusters</h3>

<p>From Periscope point of view we consider a cluster <code>dynamic</code> when the cluster capacity can be increased horizontally.
This means that nodes can be added or removed on the fly &ndash; thus the cluster’s throughput can be increased or decreased based on the cluster load and scheduled applications.
Periscope works with <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a> to add or remove nodes from the cluster based on the SLA policies and thus continuously provide a high <em>quality of service</em> for the multi-tenand Hadoop cluster.
Just to refresh memories &ndash; <a href="http://sequenceiq.com/products.html">Cloudbreak</a> is <a href="http://sequenceiq.com">SequenceIQ&rsquo;s</a> open source, cloud agnostic Hadoop as a Service API.
Given the option of provisioning or decommissioning cluster nodes on the fly, Periscope allows you to use the following set of SLAs:</p>

<ol>
<li> Application ordering &ndash; can guarantee that a higher priority application finishes before another one (supporting parallel or sequential execution)</li>
<li> Moves running applications between priority queues</li>
<li> <em>Enforce</em> time based SLA (execution time, finish by, finish between, recurring) by increasing cluster capacity and throughput</li>
<li> Smart decommissioning &ndash; avoids HDFS storms, keeps <code>paid</code> nodes alive till the last minute</li>
<li> <em>Enforce</em> guaranteed cluster capacity requests ( x % of the resources)</li>
<li> <em>Private</em> cluster requests &ndash; supports provisioning of short lived private clusters with the possibility to merge them.</li>
<li> Support for distributed (but not YARN ready) applications using Apache Slider</li>
<li> Attach priorities to SLAs</li>
</ol>


<p><em>Note: not all of the features above are supported in the first <code>public beta</code> version. There are dependencies we contributed to Hadoop, YARN and Ambari and they will be included in the next releases (2.6 and 1.7)</em></p>

<h3>High level technical details</h3>

<p>When we have started to work on Periscope we checked different solutions &ndash; and we quickly realized that there are no any open source solutions available.
Apache YARN in general, and the scheduler API&rsquo;s in particular have solved few of the issues we had &ndash; and they have certainly bring some level of SLA to Hadoop.
At <a href="https://sequenceiq.com">SequenceIQ</a> we run all our different applications on YARN &ndash; and when we decided to create a heuristic scheduler we knew from very beginning that it has to be built on the functionality given by YARN.
In order to create Periscope we had to contribute code to YARN, Hadoop and Ambari &ndash; and were trying to add all the low level features directly into the YARN codebase.
Periscope has a <a href="http://docs.periscope.apiary.io/">REST API</a> and supports pluggable SLA policies.
We will follow up with technical details in coming blog posts, so make sure you subscribe to on of our social channels.</p>

<h3>Resources</h3>

<p>Get the code : <a href="https://github.com/sequenceiq/periscope">https://github.com/sequenceiq/periscope</a></p>

<p>Documentation: <a href="http://sequenceiq.com/periscope">http://sequenceiq.com/periscope</a></p>

<p>API documentation: <a href="http://docs.periscope.apiary.io/">http://docs.periscope.apiary.io/</a></p>

<h3>What&rsquo;s next, etc</h3>

<p>This is the first <code>public beta</code> release of Periscope made available on our <a href="https://github.com/sequenceiq/periscope">GitHub</a> page.
While we are already using this internally we would like the community to help us battle test it, let us know if you find issues or raise feature requests. We are always happy to help.</p>

<p>Further releases will bring tighter integration with Ambari (especially around cluster resources), an enhanced (or potentially new) YARN scheduler and a Machine learning based job classification model.</p>

<p>We would like to say a big <em>thank you</em> for the YARN team &ndash; this effort would have not been possible without their contribution. Also we would like to thank them by supporting us with our contributions as well.
At SequenceIQ we are 100% committed to open source &ndash; and releasing Periscope under an <a href="http://www.apache.org/licenses/LICENSE-2.0">Apache 2 licence</a> was never a question.</p>

<p>Stay tuned and make sure you follow us on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook.com/sequenceiq">Facebook</a>.</p>

<p>Enjoy.</p>
]]></content>
  </entry>
  
</feed>
