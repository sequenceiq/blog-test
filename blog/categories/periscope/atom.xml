<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Periscope | SequenceIQ Blog]]></title>
  <link href="http://blog.sequenceiq.com/blog/categories/periscope/atom.xml" rel="self"/>
  <link href="http://blog.sequenceiq.com/"/>
  <updated>2015-04-13T15:18:25+00:00</updated>
  <id>http://blog.sequenceiq.com/</id>
  <author>
    <name><![CDATA[SequenceIQ]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Periscope - Ambari 2.0 - scale based on any metric]]></title>
    <link href="http://blog.sequenceiq.com/blog/2015/03/29/periscope-ambari-2-dot-0-scale-based-on-any-metric/"/>
    <updated>2015-03-29T09:52:10+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2015/03/29/periscope-ambari-2-dot-0-scale-based-on-any-metric</id>
    <content type="html"><![CDATA[<p>It&rsquo;s been a while since we discussed <a href="http://sequenceiq.com/periscope/">Periscope</a>&rsquo;s scaling capabilities, but it&rsquo;s time to revisit again as we&rsquo;re introducing a more generalized way to monitor and scale your cluster. In the first public beta release we relied on 5 different YARN metrics obtained straight from the <code>ResourceManager</code> to allow users to experiment with it and plan their capacity needs ahead. The feedbacks were really promising. Some people started extending the portfolio with new metrics and others asked us to add certain types which suits their use cases the best. In the meanwhile the <a href="https://ambari.apache.org">Ambari</a> community started to work on redesigning the <a href="https://issues.apache.org/jira/browse/AMBARI-6354">Alert</a> system which the new version of Periscope is going to leverage.</p>

<h2>Ambari 2.0 alerts</h2>

<p>The next version of <a href="https://ambari.apache.org/">Ambari</a> (going to be released soon) will be able to monitor <code>any</code> type of metrics that the full Hadoop ecosystem provides. It&rsquo;s really powerful since you&rsquo;ll not only be able to define simple metric alerts but aggregated, service level, host level and script based ones. Let&rsquo;s jump into it and see how it looks like to define an <code>alert</code> which triggers if the defined <code>root queue</code>&rsquo;s available memory falls below a certain threshold (basically the available memory in the cluster):
```json
{
  &ldquo;AlertDefinition&rdquo;: {</p>

<pre><code>"cluster_name": "cluster-name",
"component_name": "RESOURCEMANAGER",
"description": "This alarm triggers if the free memory falls below a certain threshold. The threshold values are in percent.",
"enabled": true,
"ignore_host": false,
"interval": 1,
"label": "Allocated memory",
"name": "allocated_memory",
"scope": "ANY",
"service_name": "YARN",
"source": {
  "jmx": {
    "property_list": [
      "Hadoop:service=ResourceManager,name=QueueMetrics,q0=root/AvailableMB",
      "Hadoop:service=ResourceManager,name=QueueMetrics,q0=root/AllocatedMB"
    ],
    "value": "{0}/({0} + {1}) * 100"
  },
  "reporting": {
    "ok": {
      "text": "Memory available: {0} MB, allocated: {1} MB"
    },
    "warning": {
      "text": "Memory available: {0} MB, allocated: {1} MB",
      "value": 50
    },
    "critical": {
      "text": "Memory available: {0} MB, allocated: {1} MB",
      "value": 35
    },
    "units": "%"
  },
  "type": "METRIC",
  "uri": {
    "http": "",
    "https": "",
    "https_property": "",
    "https_property_value": "HTTPS_ONLY",
    "default_port": 0,
    "high_availability": {
      "alias_key": "",
      "http_pattern": "}}",
      "https_pattern": "}}"
    }
  }
}
</code></pre>

<p>  }
}
```</p>

<!--more-->


<p>Most of the Hadoop components expose its metrics via <code>jmx</code>, but not all of them (later on this). As you can see we&rsquo;re using the RM&rsquo;s <code>jmx</code> as source to obtain the necessary metrics (in this case the <code>AvailableMB</code> and the <code>AllocatedMB</code> to calculate the overall memory usage: <code>"value": "{0}/({0} + {1}) * 100"</code>). So how does <a href="https://ambari.apache.org/">Ambari</a> knows where to look for these values, like: <code>"Hadoop:service=ResourceManager,name=QueueMetrics,q0=root/AvailableMB"</code>? You have to define which property to use in the <code>uri</code> section: <code>yarn-site/yarn.resourcemanager.webapp.address</code>. It tells Ambari to grab the property from the yarn-site and use the RM&rsquo;s web address and on that use the jmx endpoint. It could be problematic if you&rsquo;re using the RM in HA mode as there are multiple RMs. It can be solved if you provide this information as well in the <code>high_availability</code> part. In this way Ambari will always use the active RM and not the ones in <code>standby</code> mode. To make sure these metric values are there you can use the following endpoint on your cluster:
<code>
RM_IP:8088/jmx?qry=Hadoop:service=ResourceManager,name=QueueMetrics,q0=root
</code>
```</p>

<pre><code>...
"AllocatedMB" : 0,
"AllocatedVCores" : 0,
"AllocatedContainers" : 0,
"AggregateContainersAllocated" : 0,
"AggregateContainersReleased" : 0,
"AvailableMB" : 30720,
"AvailableVCores" : 48,
"PendingMB" : 0,
"PendingVCores" : 0,
"PendingContainers" : 0,
...
</code></pre>

<p><code>
These are the supported source types: `SCRIPT`, `METRIC`, `AGGREGATE`, `PERCENT` and `PORT`. You can cover anything with these types. Simply check if a process is running and listening on a port:
</code>
{
  &ldquo;uri&rdquo;: &ldquo;config/property_with_host_and_port&rdquo;,
  &ldquo;default_port&rdquo;: 12345
}
<code>
or a web UI is available:
</code>
{
  &ldquo;uri&rdquo;: {</p>

<pre><code>"http": "hdfs-site/dfs.datanode.http.address",
"https": "hdfs-site/dfs.datanode.https.address",
"https_property": "hdfs-site/dfs.http.policy",
"https_property_value": "HTTPS_ONLY"
</code></pre>

<p>  }
}
<code>
but the most interesting one besides `jmx` is the `SCRIPT` based:
</code>
{
  &ldquo;location&rdquo;: &ldquo;scripts/alert_check.py&rdquo;,
  &ldquo;arg1&rdquo;: &ldquo;arg2&rdquo;
}
```
You can define a script to check a metric value for you and Ambari will execute that script. A good example is to check the <a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/YARN/2.1.0.2.0/package/alerts/alert_nodemanager_health.py">NodeManager&rsquo;s health</a>.</p>

<h3>Dispatchers</h3>

<p>Alerts will produce either <code>OK</code>, <code>WARNING</code> or <code>CRITICAL</code> states. It&rsquo;s possible to send notifications based on these states. For example if an alert reports <code>CRITICAL</code> state an e-mail could be sent or an SNMP message to some network devices. It&rsquo;s also planned to be able to provide such dispatcher by placing the implementation to the <code>classpath</code>.</p>

<h3>Under the hood</h3>

<p>Alerts are fully supported API resources, with sorting, querying and paging:
<code>bash
curl -X GET -u "admin:admin" http://127.0.0.1:8080/api/v1/clusters/mycluster/alert_definitions
curl -X GET -u "admin:admin" http://127.0.0.1:8080/api/v1/clusters/mycluster/alert_history
curl -X GET -u "admin:admin" http://127.0.0.1:8080/api/v1/clusters/mycluster/alerts
curl -X GET -u "admin:admin" http://127.0.0.1:8080/api/v1/clusters/mycluster/alert_groups
</code>
If you install a cluster there are many pre-defined alerts by default. In order to create new ones you&rsquo;ll have to send a POST request to the appropriate endpoint, the UI doesn&rsquo;t support it.</p>

<p>How does <a href="https://ambari.apache.org/">Ambari</a> collect the metrics?</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/images/ambari_alrts.png" alt="" /></p>

<p>Each alert definition provides an <code>interval</code> property. This interval defines how often Ambari will check the alert. In the allocated memory example above it&rsquo;s <code>1</code> which means every minutes. A python based library will schedule these alerts on the Ambari agents. Due to the distributed nature of the cluster, checking the different alerts will not overwhelm the cluster causing bottlenecks. You can read more on this <a href="https://issues.apache.org/jira/secure/attachment/12677952/AlertTechDesignPublic.pdf">here</a>.</p>

<h2>Periscope alerts</h2>

<p>Previously you had to configure such alerts in Periscope and Periscope did the heavy lifting collecting the metric values. The new alert system in Ambari will take care of that and it means in Periscope you&rsquo;ll have to configure which Ambari alert you want to use to scale your cluster. Periscope will make its decisions based on the alert&rsquo;s history preventing to trigger a scaling activity unnecessarily. You&rsquo;ll be able to attach scaling actions to <code>Ambari defined alerts</code> the same way you did with Periscope based alerts. For example: enable scaling based on the above defined allocated memory:
<code>
{
  "alertName": "allocatedmemory",
  "description": "Allocated memory",
  "period": 5,
  "alertDefinition": "allocated_memory",
  "alertState": "CRITICAL"
}
</code>
This alert will trigger if the <code>allocated_memory</code> defined in Ambari reports <code>CRITICAL</code> state for 5 minutes.</p>

<h2>Docker</h2>

<p>Although Ambari 2.0 is not released yet, a preview <a href="https://github.com/sequenceiq/docker-ambari/tree/2.0.0">Docker</a> image is available to try the latest build (<a href="http://blog.sequenceiq.com/blog/2014/12/04/multinode-ambari-1-7-0/">same way as wid did with 1.7.0</a>.</p>

<p><code>Note</code>: More and more people getting involved developing and maintaining the Ambari docker images, so we like to thank for all of them. Keep up the good work guys.</p>

<h2>What&rsquo;s next</h2>

<p>We&rsquo;re steadily working to make both <a href="http://blog.sequenceiq.com/blog/2014/12/23/cloudbreak-on-hdp-2-dot-2/">Cloudbreak</a> and <a href="http://sequenceiq.com/periscope/">Periscope</a> <code>GA</code>. If you&rsquo;re interested helping us simply register and start using them &ndash; every feedback is welcomed. The key aspect we&rsquo;re focusing on at the moment is the security layer (<code>kerberos</code> based security probably worth a blog entry). In the meanwhile follow us on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook">Facebook</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Periscope: time based autoscaling]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/11/25/periscope-scale-your-cluster-on-time/"/>
    <updated>2014-11-25T14:13:33+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/11/25/periscope-scale-your-cluster-on-time</id>
    <content type="html"><![CDATA[<p><a href="http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/">Periscope</a> allows you to configure SLA policies for your cluster
and scale up or down on demand. You are able to set alarms and notifications for different metrics like <code>pending containers</code>,
<code>lost nodes</code> or <code>memory usage</code>, etc . Recently we got a request to scale based on <code>time interval</code>. What does this mean? It means that you can tell
Periscope to shrink your cluster down to arbitrary number of nodes after work hours or at weekends and grow it back by the time people starts to work. We thought it would make a really useful feature so we quickly implemented it and made available. You can learn more about the Periscope API <a href="http://docs.periscope.apiary.io/">here</a>.</p>

<h3>Cost efficiency</h3>

<p>In this example we&rsquo;ll configure Pericope to downscale at 7PM and upscale at 8AM from Monday to Friday:</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/images/dowscale_diagram.png" alt="" /></p>

<p>Just to make things easier let&rsquo;s assume that our cluster is homogeneous. On AWS a c3.xlarge instance costs $0.210 per hour.
Now let&rsquo;s do the math:</p>

<ul>
<li>24 x 0.21 x 100                      = $504</li>
<li>(11 x 0.21 x 100) + (13 x 0.21 x 10) = $260</li>
</ul>


<p>In a month we can save <strong>$7560</strong> scaling from 100 to 10 and back &ndash; and the weekends are not even counted.</p>

<!--more-->


<h3>Cron based alarms</h3>

<p>In order to configure such actions you&rsquo;ll have to set some <code>time alarms</code>.</p>

<p>```json
{
  &ldquo;alarms&rdquo;: [</p>

<pre><code>{
  "alarmName": "worktime",
  "description": "Number of nodes during worktime",
  "timeZone": "Europe/Budapest",
  "cron": "0 59 07 ? * MON-FRI"
},
{
  "alarmName": "after work",
  "description": "Number of nodes after worktime",
  "timeZone": "Europe/Budapest",
  "cron": "0 59 18 ? * MON-FRI"
}
</code></pre>

<p>  ]
}
```</p>

<p>Now that the alarms are set we need to tell Periscope what to do when they are triggered. Let&rsquo;s define the <code>scaling policies</code>:</p>

<p>```json
{
  &ldquo;minSize&rdquo;: 2,
  &ldquo;maxSize&rdquo;: 100,
  &ldquo;cooldown&rdquo;: 30,
  &ldquo;scalingPolicies&rdquo;: [</p>

<pre><code>{
  "name": "upscale",
  "adjustmentType": "EXACT",
  "scalingAdjustment": 100,
  "hostGroup": "slave_1",
  "alarmId": "150"
},
{
  "name": "downscale",
  "adjustmentType": "EXACT",
  "scalingAdjustment": 10,
  "hostGroup": "slave_1",
  "alarmId": "151"
}
</code></pre>

<p>  ]
}
```
For those who are not familiar with the properties in the scaling JSON:</p>

<ul>
<li>minSize: defines the minimum size of the cluster</li>
<li>maxSize: defines the maximum size of the cluster</li>
<li>cooldown: defines the time between 2 scaling activity</li>
<li>adjustmentType: can be <code>NODE_COUNT</code>, <code>PERCENTAGE</code>, or <code>EXACT</code></li>
<li>scalingAdjustment: defines the number nodes of with to upscale or downscale and depends on the adjustment type as follows:

<ul>
<li><code>NODE_COUNT</code> can be -2 (downscale with 2 nodes) or +2 (upscale with 2 nodes)</li>
<li><code>PERCENTAGE</code> similarly can be 40% and -40%</li>
<li><code>EXACT</code> always a positive number which can mean both upscale or downscale based on the previous size of the cluster</li>
</ul>
</li>
<li>hostGroup: defines the Hadoop services installed on a host. In case of scaling we&rsquo;ll take or add hosts with these services.</li>
</ul>


<p>Many people reached us with their questions of how to scale down properly as they had some concerns about it.
Generally speaking downscaling is much harder to do than upscaling. Am I going to lose portion of my data? What will happen with the running applications? What will happen with say <code>RegionServers</code>? Luckily Hadoop services provide <code>graceful decommission</code>.</p>

<p><em>Note:When you are storing your data in a cloud object store (last week we have blogged about these <a href="http://blog.sequenceiq.com/blog/2014/10/28/datalake-cloudbreak/">here</a> and <a href="http://blog.sequenceiq.com/blog/2014/11/17/datalake-cloudbreak-2/">here</a>) this is less of an issue &ndash; and Periscope will not have to worry about HDFS data replications.</em></p>

<h3>Decommission flow</h3>

<p>Let&rsquo;s dive through an example: Periscope instructs <a href="http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/">Cloudbreak</a> &ndash; our
Hadoop as a service API &ndash; to shut down 10 nodes and Cloudbreak will make sure that nothing gets lost. First it will check which nodes are running <code>ApplicationMasters</code> to leave them out of the process. If it found all the 10 candidates for shutting down
it will decommission the necessary services from them and then it will shut down those nodes. Applications continue to run and Hadoop <code>master</code> services continue to run undisturbed.</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/images/downscale_sequence.png" alt="" /></p>

<p>If you have questions like these don&rsquo;t hesitate to contact us we&rsquo;ll try to help you solve your problems.
Make sure you check back soon to our <a href="http://blog.sequenceiq.com/">blog</a> or follow us
on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook">Facebook</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Real-time adjustments with Hadoop metrics]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/10/15/hadoop-metrics/"/>
    <updated>2014-10-15T13:56:32+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/10/15/hadoop-metrics</id>
    <content type="html"><![CDATA[<p>To properly understand and to be fully aware of the state of our Hadoop clusters at any time we needed a scalable and flexible solution
to monitor our Hadoop nodes. After investigating the possible solutions we realized that there is no available solution which satisfies
all our needs thus we&rsquo;ve created one and recently just open sourced it, called <a href="http://sequenceiq.com/periscope/#monitoring">Baywatch</a>. Baywatch is capable to capture and visualize real-time changes on Hadoop clusters to understand and make adjustments based on the submitted jobs resource
allocation needs. To plan ahead, viewing and comparing old and new metrics is just as
important as analyzing real-time ones, not to mention that we can find possible weaknesses and defects in our clusters.</p>

<p>To be able to do all of the above mentioned, Baywatch processes the metrics information produced by the Hadoop daemons. This might already sound familiar as we have another project called <a href="http://sequenceiq.com/periscope/">Periscope</a> where you can create alarms and cluster scaling activities making use of the same metrics, but just consuming it in a different way. Combine these 2
components and you&rsquo;ll have a powerful tool and you&rsquo;ll be able to view your cluster&rsquo;s state and based on that <code>make smart decisions</code>
to scale up or down, or simply just set alarms. If you&rsquo;re thrilled to see it in action we are at <a href="http://strataconf.com/stratany2014">Strata</a> and happy to show you a quick demo.</p>

<h2>Hadoop metrics</h2>

<p>So what are these metrics? As I mentioned it earlier metrics are collections of information about Hadoop daemons, e.g:
the <code>ResourceManager</code> produces information about the queue statuses which we use in Periscope when we <code>re-prioritise applications</code>.
To distinguish these metrics they are grouped into named contexts, e.g <code>jvm</code> for java virtual machine metrics, <code>rpc</code> for debugging
rcp calls, but there are many more:</p>

<ul>
<li>yarn</li>
<li>rpcdetailed</li>
<li>metricssystem</li>
<li>mapred</li>
<li>dfs</li>
<li>ugi</li>
</ul>


<p>This <code>Metrics2</code> framework is designed to collect and dispatch per-process metrics to monitor the overall status of the Hadoop system.
In Hadoop related technologies it is a common design to use sources and sinks, just like in this case. Metrics sources are where the
metrics are generated and metrics sinks consume the records generated by the metrics sources. A metrics system would poll the metrics
sources periodically and pass the metrics records to metrics sinks.</p>

<p><img class="<a" src="href="http://yuml.me/0faf3738">http://yuml.me/0faf3738</a>"></p>

<!-- more -->


<p>It is really easy to implement new sinks and sources, just for reference here&rsquo;s the <code>FileSink</code>:
```java
  @Override
  public void putMetrics(MetricsRecord record) {</p>

<pre><code>writer.print(record.timestamp());
writer.print(" ");
writer.print(record.context());
writer.print(".");
writer.print(record.name());
String separator = ": ";
for (MetricsTag tag : record.tags()) {
  writer.print(separator);
  separator = ", ";
  writer.print(tag.name());
  writer.print("=");
  writer.print(tag.value());
}
for (AbstractMetric metric : record.metrics()) {
  writer.print(separator);
  separator = ", ";
  writer.print(metric.name());
  writer.print("=");
  writer.print(metric.value());
}
writer.println();
</code></pre>

<p>  }
<code>
and the `FairSchedulerQueueMetrics`:
</code>java
  @Metric(&ldquo;Fair share of memory in MB&rdquo;) MutableGaugeInt fairShareMB;
  @Metric(&ldquo;Fair share of CPU in vcores&rdquo;) MutableGaugeInt fairShareVCores;
  @Metric(&ldquo;Steady fair share of memory in MB&rdquo;) MutableGaugeInt steadyFairShareMB;
  @Metric(&ldquo;Steady fair share of CPU in vcores&rdquo;) MutableGaugeInt steadyFairShareVCores;
  @Metric(&ldquo;Minimum share of memory in MB&rdquo;) MutableGaugeInt minShareMB;
  @Metric(&ldquo;Minimum share of CPU in vcores&rdquo;) MutableGaugeInt minShareVCores;
  @Metric(&ldquo;Maximum share of memory in MB&rdquo;) MutableGaugeInt maxShareMB;
  @Metric(&ldquo;Maximum share of CPU in vcores&rdquo;) MutableGaugeInt maxShareVCores;
```
Hadoop comes by default with 3 sinks:</p>

<ul>
<li>FileSink</li>
<li>GraphiteSink</li>
<li>GangliaSink30</li>
</ul>


<h2>Configuration</h2>

<p>The Metrics2 framework uses the <code>PropertiesConfiguration</code> thus the metrics sinks needs to be defined in a configuration-file:
<code>hadoop-metrics2.properties</code>. The declaration should be familiar for those who used <code>Apache Flume</code> before. Here is an example
taken from our <a href="link">Ambari docker image</a>:
<code>
*.sink.logstash.class=org.apache.hadoop.metrics2.sink.FileSink
namenode.sink.logstash.filename=/var/log/hadoop-metrics/namenode-metrics.out
secondarynamenode.sink.logstash.filename=/var/log/hadoop-metrics/secondarynamenode-metrics.out
datanode.sink.logstash.filename=/var/log/hadoop-metrics/datanode-metrics.out
resourcemanager.sink.logstash.filename=/var/log/hadoop-metrics/resourcemanager-metrics.out
nodemanager.sink.logstash.filename=/var/log/hadoop-metrics/nodemanager-metrics.out
maptask.sink.logstash.filename=/var/log/hadoop-metrics/maptask-metrics.out
reducetask.sink.logstash.filename=/var/log/hadoop-metrics/reducetask-metrics.out
mrappmaster.sink.logstash.filename=/var/log/hadoop-metrics/mrappmaster-metrics.out
</code></p>

<h3>Hadoop WebServices</h3>

<p>There is another way to obtain these metrics without any configuration which the Periscope leverages. It&rsquo;s the <code>WebServices</code> provided
by Hadoop. <code>Jax-RS</code> is used to define the mappings, e.g collect the <code>ResourceManager</code> queue related metrics on mapping <code>/ws/v1/cluster</code>:
```java
  @GET
  @Path(&ldquo;/scheduler&rdquo;)
  @Produces({ MediaType.APPLICATION_JSON, MediaType.APPLICATION_XML })
  public SchedulerTypeInfo getSchedulerInfo() {</p>

<pre><code>init();
ResourceScheduler rs = rm.getResourceScheduler();
SchedulerInfo sinfo;
if (rs instanceof CapacityScheduler) {
  CapacityScheduler cs = (CapacityScheduler) rs;
  CSQueue root = cs.getRootQueue();
  sinfo = new CapacitySchedulerInfo(root);
} else if (rs instanceof FairScheduler) {
  FairScheduler fs = (FairScheduler) rs;
  sinfo = new FairSchedulerInfo(fs);
} else if (rs instanceof FifoScheduler) {
  sinfo = new FifoSchedulerInfo(this.rm);
} else {
  throw new NotFoundException("Unknown scheduler configured");
}
return new SchedulerTypeInfo(sinfo);
</code></pre>

<p>  }
```
The only difference is that you&rsquo;re application have to poll now, while the other way you can create forwarders to create push events
just like we did with Baywatch. To which to use depends on you&rsquo;re needs.</p>

<h2>Summary and resources</h2>

<p>As you see using <strong>Baywatch</strong> and <strong>Periscope</strong> you can monitor and scale your cluster based on the configured policies &ndash; all available open sources in our <a href="https://github.com/sequenceiq">GitHub</a> page.</p>

<ul>
<li><a href="http://sequenceiq.com/periscope/">Periscope</a></li>
<li><a href="https://github.com/sequenceiq/docker-baywatch-client">Baywatch client</a></li>
<li><a href="https://github.com/sequenceiq/docker-baywatch">Baywatch</a></li>
</ul>


<p>For updates follow us
on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or
<a href="https://www.facebook.com/sequenceiq">Facebook</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SLA policies for autoscaling Hadoop clusters]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/09/01/sla-samples-periscope/"/>
    <updated>2014-09-01T16:37:37+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/09/01/sla-samples-periscope</id>
    <content type="html"><![CDATA[<p>Last week we have <a href="http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/">announced</a> and open sourced <a href="http://sequenceiq.com/periscope/">Periscope</a> &ndash; the industry’s first SLA policy based autoscaling API for Hadoop YARN clusters. In this post we’d like to come up with some examples, setting up alarms and attach scaling policies to your Hadoop cluster.</p>

<p>Periscope is built on existing (and coming/contributed by us) features provided by Apache Hadoop, YARN, Ambari, Docker containers and SequenceIQ’s <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a>. Just FYI, <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a> is our open source and cloud agnostic Hadoop as a Service API, built on Docker containers. While Periscope can attach scaling policies to <code>static</code> and <code>dynamic</code> clusters &ndash; in this post we’d like to emphasize Periscope’s capabilities while working with &mdash; `dynamic &ndash; cloud based Hadoop deployments  &ndash; such as Hadoop clusters deployed with <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a>.</p>

<p>SLAs policies are configured based on <code>alarms</code>, whereas an alarm is created based on <code>metrics</code> &ndash; these entities are explained below.</p>

<h2>Alarms</h2>

<p>An alarm watches a <code>metric</code> over a specified time period, and used by one or more action or scaling policy based on the value of the metric relative to a given threshold over the time period. A few of the supported <code>metrics</code> are listed below:</p>

<p>*<code>PENDING_CONTAINERS</code>&ndash; pending YARN containers</p>

<p>*<code>PENDING_APPLICATIONS</code> &ndash; pending/queued YARN applications</p>

<p>*<code>LOST_NODES</code> &ndash; cluster nodes lost</p>

<p>*<code>UNHEALTHY_NODES</code> &ndash; unhealthy cluster nodes</p>

<p>*<code>GLOBAL_RESOURCES</code> &ndash; global resources</p>

<!--more-->


<p>Measured <code>metrics</code> are compared with pre-configured values using operators. The <code>comparison operators</code> are: <code>LESS_THAN</code>, <code>GREATER_THAN</code>, <code>LESS_OR_EQUAL_THAN</code>, <code>GREATER_OR_EQUAL_THAN</code>, <code>EQUALS</code>.
In order to avoid reacting for sudden spikes in the system and apply policies only in case of a sustained system stress, <code>alarms</code> have to be sustained over a <code>period</code> of time.  The <code>period</code> specifies the time period in minutes during the alarm has to be sustained. Also a <code>threshold</code> can be configured, which specifies the variance applied by the operator for the selected <code>metric</code>.</p>

<p>For the <code>alarm</code> related REST operations you can check the <a href="http://docs.periscope.apiary.io/reference/alarms">API</a> documentation. Alarms can issue <code>notifications</code> as well &ndash; for example if a metric is reached for the configured time and threshold a notification event is raised &ndash; in the given example below this notification is an email.</p>

<p>```</p>

<h1>set metric alarms</h1>

<p>curl -X POST -H &ldquo;Content-Type: application/json&rdquo; -d &lsquo;{&ldquo;alarms&rdquo;:[{&ldquo;alarmName&rdquo;:&ldquo;pendingContainerHigh&rdquo;,&ldquo;description&rdquo;:&ldquo;Number of pending containers is high&rdquo;,&ldquo;metric&rdquo;:&ldquo;PENDING_CONTAINERS&rdquo;,&ldquo;threshold&rdquo;:10,&ldquo;comparisonOperator&rdquo;:&ldquo;GREATER_THAN&rdquo;,&ldquo;period&rdquo;:1},{&ldquo;alarmName&rdquo;:&ldquo;freeGlobalResourcesRateLow&rdquo;,&ldquo;description&rdquo;:&ldquo;Low free global resource rate&rdquo;,&ldquo;metric&rdquo;:&ldquo;GLOBAL_RESOURCES&rdquo;,&ldquo;threshold&rdquo;:1,&ldquo;comparisonOperator&rdquo;:&ldquo;EQUALS&rdquo;,&ldquo;period&rdquo;:1,&ldquo;notifications&rdquo;:[{&ldquo;target&rdquo;:[“<a href="&#x6d;&#x61;&#x69;&#x6c;&#x74;&#111;&#58;&#109;&#x69;&#x63;&#x6b;&#46;&#x66;&#97;&#x6e;&#110;&#x69;&#110;&#x67;&#64;&#97;&#115;&#112;&#x77;&#x6f;&#114;&#x6c;&#100;&#116;&#111;&#117;&#x72;&#x2e;&#x63;&#111;&#x6d;">&#x6d;&#105;&#x63;&#107;&#46;&#102;&#97;&#x6e;&#110;&#x69;&#x6e;&#103;&#64;&#97;&#115;&#112;&#119;&#111;&#x72;&#x6c;&#100;&#116;&#x6f;&#117;&#114;&#x2e;&#x63;&#111;&#109;</a>"],&ldquo;notificationType&rdquo;:&ldquo;EMAIL&rdquo;}]}]}&rsquo; localhost:8081/clusters/1/alarms | jq .
curl -X PUT -H &ldquo;Content-Type: application/json&rdquo; -d &lsquo;{&ldquo;alarmName&rdquo;:&ldquo;unhealthyNodesHigh&rdquo;,&ldquo;description&rdquo;:&ldquo;Number of unhealthy nodes is high&rdquo;,&ldquo;metric&rdquo;:&ldquo;UNHEALTHY_NODES&rdquo;,&ldquo;threshold&rdquo;:5,&ldquo;comparisonOperator&rdquo;:&ldquo;GREATER_OR_EQUAL_THAN&rdquo;,&ldquo;period&rdquo;:5}&rsquo; localhost:8081/clusters/1/alarms | jq .
```</p>

<h2>SLA scaling policies</h2>

<p>Scaling is the ability to increase or decrease the capacity of the Hadoop cluster or application.  When scaling policies are used, the capacity is automatically increased or decreased according to the conditions defined.
Periscope will do the heavy lifting and based on the alarms and the scaling policy linked to them it executes the associated policy. By default a fully configured and running <a href="https://cloudbreak.sequenceiq.com/">Cloudbreak</a> cluster contains no SLA policies.  An SLA scaling policy can contain multiple <code>alarms</code>.</p>

<p>As an alarm is triggered a <code>scalingAdjustment</code> is applied, however to keep the cluster size within boundaries a <code>minSize</code> and <code>maxSize</code> is attached to the cluster &ndash; thus a scaling policy can never over or undersize a cluster. Also in order to avoid stressing the cluster we have introduced a <code>cooldown</code> period (minutes) &ndash; though an alarm is raised and there is an associated scaling policy, the system will not apply the policy within the configured timeframe. In an SLA scaling policy the triggered policies are applied in order.</p>

<p>Hosts can be added or removed from specific <code>hostgroups</code>. Periscope and Cloudbreak uses Apache Ambari to provision a Hadoop cluster. Ambari host groups are a set of machines with the same Hadoop “components” installed. You can set up a cluster having different hostgroups &ndash; and run different services, thus having a heterogenous cluster.</p>

<p>In the following example we downscale a cluster when the unused resources are high.</p>

<p>```</p>

<h1>set scaling policy</h1>

<p>curl -X POST -H &ldquo;Content-Type: application/json&rdquo; -d &lsquo;{&ldquo;minSize&rdquo;:2,&ldquo;maxSize&rdquo;:10,&ldquo;cooldown&rdquo;:30,&ldquo;scalingPolicies&rdquo;:[{&ldquo;name&rdquo;:&ldquo;downScaleWhenHighResource&rdquo;,&ldquo;adjustmentType&rdquo;:&ldquo;NODE_COUNT&rdquo;,&ldquo;scalingAdjustment&rdquo;:2,&ldquo;hostGroup&rdquo;:&ldquo;slave_1&rdquo;,&ldquo;alarmId&rdquo;:&ldquo;101&rdquo;},{&ldquo;name&rdquo;:&ldquo;upScaleWhenHighPendingContainers&rdquo;,&ldquo;adjustmentType&rdquo;:&ldquo;PERCENTAGE&rdquo;,&ldquo;scalingAdjustment&rdquo;:40,&ldquo;hostGroup&rdquo;:&ldquo;slave_1&rdquo;,&ldquo;alarmId&rdquo;:&ldquo;100&rdquo;}]}&rsquo; localhost:8081/clusters/1/policies | jq .
```</p>

<p>For the <code>policy</code> related REST operations you can check the <a href="http://docs.periscope.apiary.io/reference/scaling-policy">API</a> documentation.</p>

<p>Let us know how Periscope works for you &ndash; and for updates follow us on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook.com/sequenceiq">Facebook</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Periscope - autoscaling for Hadoop YARN]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/"/>
    <updated>2014-08-27T16:37:37+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope</id>
    <content type="html"><![CDATA[<p><em>Periscope is a powerful, fast, thick and top-to-bottom right-hander, eastward from Sumbawa&rsquo;s famous west-coast. Timing is critical, as needs a number of elements to align before it shows its true colors.</em></p>

<p><em>Periscope brings QoS and autoscaling to Hadoop YARN. Built on cloud resource management and YARN schedulers, allows to associate SLA policies to applications.</em></p>

<p>After the very positive reception of <a href="https://cloudbreak.sequenceiq.com/">Cloudbreak</a> &ndash; the first open source and cloud agnostic Hadoop as a Service API &ndash; today we are releasing the <code>public beta</code> version of our open source <strong>SLA policy based autoscaling API</strong> for Hadoop YARN clusters.</p>

<h2>Overview</h2>

<p>The purpose of Periscope is to bring QoS and autoscaling to a multi-tenant Hadoop YARN cluster, while allowing to apply SLA policies to individual applications.
At <a href="http://sequenceiq.com">SequenceIQ</a> working with multi-tenant Hadoop clusters for quite a while, we have always seen the same frustration and fight for resource between users.
The <strong>FairScheduler</strong> was partially solving this problem &ndash; bringing in fairness based on the notion of <a href="http://static.usenix.org/event/nsdi11/tech/full_papers/Ghodsi.pdf">Dominant Resource Fairness</a>.
With the emergence of Hadoop 2 YARN and the <strong>CapacityScheduler</strong> we had the option to maximize throughput and utilization for a multi-tenant cluster in an operator-friendly manner.
The scheduler works around the concept of queues. These queues are typically setup by administrators to reflect the economics of the shared cluster.
While this is a pretty good abstraction and brings some level of SLA for predictable workloads, it often needs proper design ahead.
The queue hierarchy and resource allocation needs to be changed when new tenants and workloads are moved to the cluster.</p>

<p>Periscope was designed around the idea of <code>autoscaling</code> clusters &ndash; without any need to preconfigure queues, cluster nodes or apply capacity planning ahead.</p>

<!--more-->


<h2>How it works</h2>

<p>Periscope monitors the application progress, the number of YARN containers/resources and their allocation, queue depths, the number of available cluster nodes and their health.
Since we have switched to YARN a while ago (been among the first adopters) we have run an open source <a href="https://github.com/sequenceiq/yarn-monitoring">monitoring project</a>, based on R.
We have been collecting metrics from the YARN Timeline server, Hadoop Metrics2 and Ambari&rsquo;s Nagios/Ganglia &ndash; and profiling the applications and correlating with these metrics.
One of the key findings was that while low level metrics are good to understand the cluster health &ndash; they might not necessarily help on making decisions when applying different SLA policies on a multi-tenant cluster.
Focusing on higher level building blocks as queue depth, YARN containers, etc actually brings in the same quality of service, while not being lost in low level details.</p>

<p>Periscope works with two types of Hadoop clusters: <code>static</code> and <code>dynamic</code>. Periscope does not require any pre-installation &ndash; the only thing it requires is to be <code>attached</code> to an Ambari server&rsquo;s REST API.</p>

<h2>Clusters</h2>

<h3>Static clusters</h3>

<p>From Periscope point of view we consider a cluster <code>static</code> when the cluster capacity can&rsquo;t be increased horizontally.
This means that the hardware resources are already given &ndash; and the throughput can&rsquo;t be increased by adding new nodes.
Periscope introspects the job submission process, monitors the applications and applies the following SLAs:</p>

<ol>
<li> Application ordering &ndash; can guarantee that a higher priority application finishes before another one (supporting parallel or sequential execution)</li>
<li> Moves running applications between priority queues</li>
<li> <em>Attempts</em> to enforce time based SLA (execution time, finish by, finish between, recurring)</li>
<li> <em>Attempts</em> to enforce guaranteed cluster capacity requests ( x % of the resources)</li>
<li> Support for distributed (but not YARN ready) applications using Apache Slider</li>
<li> Attach priorities to SLAs</li>
</ol>


<p><em>Note: not all of the features above are supported in the first <code>public beta</code> version. There are dependencies we contributed to Hadoop, YARN and Ambari and they will be included in the next releases (2.6 and 1.7)</em></p>

<h3>Autoscaling clusters</h3>

<p>From Periscope point of view we consider a cluster <code>dynamic</code> when the cluster capacity can be increased horizontally.
This means that nodes can be added or removed on the fly &ndash; thus the cluster’s throughput can be increased or decreased based on the cluster load and scheduled applications.
Periscope works with <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a> to add or remove nodes from the cluster based on the SLA policies and thus continuously provide a high <em>quality of service</em> for the multi-tenand Hadoop cluster.
Just to refresh memories &ndash; <a href="http://sequenceiq.com/products.html">Cloudbreak</a> is <a href="http://sequenceiq.com">SequenceIQ&rsquo;s</a> open source, cloud agnostic Hadoop as a Service API.
Given the option of provisioning or decommissioning cluster nodes on the fly, Periscope allows you to use the following set of SLAs:</p>

<ol>
<li> Application ordering &ndash; can guarantee that a higher priority application finishes before another one (supporting parallel or sequential execution)</li>
<li> Moves running applications between priority queues</li>
<li> <em>Enforce</em> time based SLA (execution time, finish by, finish between, recurring) by increasing cluster capacity and throughput</li>
<li> Smart decommissioning &ndash; avoids HDFS storms, keeps <code>paid</code> nodes alive till the last minute</li>
<li> <em>Enforce</em> guaranteed cluster capacity requests ( x % of the resources)</li>
<li> <em>Private</em> cluster requests &ndash; supports provisioning of short lived private clusters with the possibility to merge them.</li>
<li> Support for distributed (but not YARN ready) applications using Apache Slider</li>
<li> Attach priorities to SLAs</li>
</ol>


<p><em>Note: not all of the features above are supported in the first <code>public beta</code> version. There are dependencies we contributed to Hadoop, YARN and Ambari and they will be included in the next releases (2.6 and 1.7)</em></p>

<h3>High level technical details</h3>

<p>When we have started to work on Periscope we checked different solutions &ndash; and we quickly realized that there are no any open source solutions available.
Apache YARN in general, and the scheduler API&rsquo;s in particular have solved few of the issues we had &ndash; and they have certainly bring some level of SLA to Hadoop.
At <a href="https://sequenceiq.com">SequenceIQ</a> we run all our different applications on YARN &ndash; and when we decided to create a heuristic scheduler we knew from very beginning that it has to be built on the functionality given by YARN.
In order to create Periscope we had to contribute code to YARN, Hadoop and Ambari &ndash; and were trying to add all the low level features directly into the YARN codebase.
Periscope has a <a href="http://docs.periscope.apiary.io/">REST API</a> and supports pluggable SLA policies.
We will follow up with technical details in coming blog posts, so make sure you subscribe to on of our social channels.</p>

<h3>Resources</h3>

<p>Get the code : <a href="https://github.com/sequenceiq/periscope">https://github.com/sequenceiq/periscope</a></p>

<p>Documentation: <a href="http://sequenceiq.com/periscope">http://sequenceiq.com/periscope</a></p>

<p>API documentation: <a href="http://docs.periscope.apiary.io/">http://docs.periscope.apiary.io/</a></p>

<h3>What&rsquo;s next, etc</h3>

<p>This is the first <code>public beta</code> release of Periscope made available on our <a href="https://github.com/sequenceiq/periscope">GitHub</a> page.
While we are already using this internally we would like the community to help us battle test it, let us know if you find issues or raise feature requests. We are always happy to help.</p>

<p>Further releases will bring tighter integration with Ambari (especially around cluster resources), an enhanced (or potentially new) YARN scheduler and a Machine learning based job classification model.</p>

<p>We would like to say a big <em>thank you</em> for the YARN team &ndash; this effort would have not been possible without their contribution. Also we would like to thank them by supporting us with our contributions as well.
At SequenceIQ we are 100% committed to open source &ndash; and releasing Periscope under an <a href="http://www.apache.org/licenses/LICENSE-2.0">Apache 2 licence</a> was never a question.</p>

<p>Stay tuned and make sure you follow us on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook.com/sequenceiq">Facebook</a>.</p>

<p>Enjoy.</p>
]]></content>
  </entry>
  
</feed>
