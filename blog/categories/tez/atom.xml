<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Tez | SequenceIQ Blog]]></title>
  <link href="http://blog.sequenceiq.com/blog/categories/tez/atom.xml" rel="self"/>
  <link href="http://blog.sequenceiq.com/"/>
  <updated>2014-10-15T14:08:57+00:00</updated>
  <id>http://blog.sequenceiq.com/</id>
  <author>
    <name><![CDATA[SequenceIQ]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Apache Spark - MLlib Introduction]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/07/31/spark-mllib/"/>
    <updated>2014-07-31T07:47:32+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/07/31/spark-mllib</id>
    <content type="html"><![CDATA[<h3>Introduction</h3>

<p>In one of our earlier posts we have mentioned that we use Scalding (among others) for writing MR jobs. Scala/Scalding simplifies the implementation of many MR patterns and makes it easy to implement quite complex jobs like machine learning algorithms. Map Reduce is a mature and widely used framework and it is a good choice for processing large amounts of data &ndash; but not as great if you’d like to use it for fast iterative algorithms/processing. This is a use case where <a href="https://spark.apache.org/">Apache Spark</a> can be quite handy. Spark is fit for these kind of algorithms, because it tries to keep everything in memory (in case of you run out of memory, you can switch to another <a href="http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence">storage levels</a>).</p>

<h3>Apache Spark &ndash; MLlib library</h3>

<p><a href="https://spark.apache.org/docs/latest/mllib-guide.html">MLlib</a> is a machine learning library which ships with Apache Spark, and can run on any Hadoop2/YARN cluster without any pre-installation. At SequenceIQ we use MLlib in Scala &ndash; but you could use it from Java and Python as well. Let us quickly show you an MLlib clustering algorithm with code examples.</p>

<h3>KMeans example</h3>

<p>K-Means (Lloyd&rsquo;s algorithm) is a simple NP-hard unsupervised learning algorithm that solve well known clustering problems. The essence of the algorithm is to separate your data into K cluster. In simple terms it needs 4 steps. First of all you have to vectorize your data. (you can do that with text values too). The code looks like this:</p>

<p>```scala</p>

<pre><code>val data = context.textFile(input).map {
  line =&gt; Vectors.dense(line.split(',').map(_.toDouble))
}.cache()
</code></pre>

<p>```</p>

<!-- more -->


<p>The second step is to choose K center points (centroids). The third one is to assign each vector to the group that has the closest centroid. After all this is done, next thing you will need to do is to recalculate the positions of the centroids. You have to repeat the third and fourth steps until the centroids are not moving (<code>the iterative stuff</code>). The <a href="https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala">KMeans</a> MLlib model is doing that for you.</p>

<p>```scala</p>

<pre><code>val clusters: KMeansModel = KMeans.train(data, K, maxIteration, runs)

val vectorsAndClusterIdx = data.map{ point =&gt;
  val prediction = clusters.predict(point)
  (point.toString, prediction)
}
</code></pre>

<p>```
After you have your model result, you can utilize it in your RDD object.</p>

<h3>Running Spark job on YARN</h3>

<p>In order to run this Spark application on YARN first of all you will need a Hadoop YARN cluster. For that you could use our Hadoop as a Service API called <a href="http://sequenceiq.com/cloudbreak">Cloudbreak</a> &ndash; using a <code>multi-node-hdfs-yarn</code> blueprint will set you up a Spark ready Hadoop cluster in less than 2 minutes on your favorite cloud provider. Give it a try at our hosted <a href="https://cloudbreak.sequenceiq.com">Cloudbreak</a> instance.</p>

<p>Once your cluster it’s up and ready you can run the following command:</p>

<p><code>bash
./bin/spark-submit --class com.sequenceiq.spark.Main --master \
yarn-client --driver-memory 1g --executor-memory 1g --executor-cores 1 \
/root/spark-clustering-1.0.jar hdfs://sandbox:9000/input/input.txt /output 10 10 1
</code>
Alternatively you can run this in our free Docker based Apache Spark container as well. You can get a Spark container from the official <a href="https://registry.hub.docker.com/u/sequenceiq/spark/">Docker registry</a> or from our <a href="https://github.com/sequenceiq/docker-spark">GitHub</a> repository.
As always we are making the source code available at <a href="https://github.com/sequenceiq/sequenceiq-samples/tree/master/spark-clustering">SequenceIQ&rsquo;s GitHub repository</a> (check the other interesting examples as well).  You can find 2 simple input datasets for testing purposes.</p>

<p>The result of the clustering looks like this (generated with R):</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/spark-clustering/data/spark-clustering_1.jpeg" alt="" /></p>

<p>While there is a loud buzz about what’s faster than the other and there are huge numbers thrown in as the <em>X</em> multiplier factor we don’t really want to enter that game &ndash; as a fact we’d like to mention that both example performs better than Mahout KMeans (2-3x faster with 20 iterations), but these are really small datasets. We have seen larger datasets in production where the performances are quite the same, or can go the other way (especially that Spark is new and people don’t always get the configuration right).</p>

<p>In one of our next post we will show you metrics for a much larger dataset and other ML algorithms &ndash; follow us on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook">Facebook</a> for updates.</p>

<h3>Apache Tez</h3>

<p>We can’t finish this blog post before not talking about <a href="http://tez.apache.org/">Apache Tez</a> &ndash; the project is aimed at building an application framework which allows for a complex directed-acyclic-graph of tasks for processing data &ndash; fast. We (and many others) believe that this can be a good alternative for Spark &ndash; especially for machine learning. The number of frameworks which are adding or moving the MR runtime to Tez is increasing &ndash; among the few to mention are Cascading, Summingbird, Conjecture &ndash; including us as well.</p>

<p>Note that Apache Tez has already showed <strong>awesome</strong> result. Being the key building block of the <a href="http://hortonworks.com/labs/stinger/">Stinger inititive</a> &ndash; led by Hortonworks &ndash; managed to bring near real time queries and speed up Hive with 100x.</p>

<h3>Other promising machine learning frameworks</h3>

<p>If you are interested in machine learning frameworks, you have to check  <a href="https://github.com/etsy/Conjecture">Conjecture</a> or <a href="https://github.com/tresata/ganitha">ganitha</a> &ndash; they both show great fueatures and have promising results.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Mahout with Tez]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/03/31/mahout-on-tez/"/>
    <updated>2014-03-31T10:22:09+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/03/31/mahout-on-tez</id>
    <content type="html"><![CDATA[<p>At SequenceIQ we are always open to the latest innovations in Hadoop, and trying to find a way to offer a better performance and cluster utilization to our customers. We came in close touch with the <a href="http://hortonworks.com/labs/stinger/">Stinger initiative</a> last year at the Hadoop Summit in Amsterdam &ndash; and ever since we have followed up with the project progress (latest <a href="http://hortonworks.com/blog/apache-tez-0-3-released/">release</a> is 0.3). The project was initiated by Hortonworks with the goal of a 100x performance improvement of Hive.
Although Hive is not part of our product stack (we use other ways for SQL on Hadoop), there is one particular key component of the Stinger initiative which was very interesting to us: <a href="https://github.com/apache/incubator-tez">Apache Tez</a>.</p>

<p><a href="http://incubator.apache.org/projects/tez.html">Apache Tez</a> is a new application framework built on top of Hadoop Yarn that can execute complex directed acyclic graphs (DAGs) of general data processing tasks. In many ways it can be thought of as a more flexible and powerful successor of the map-reduce framework. This was exactly what draw our attention and made us start thinking about using Tez as our runtime for map-reduce jobs.</p>

<h2>Tez and MapReduce</h2>

<p>At SequenceIQ we have chains of map-reduce jobs which are scheduled individually and read the output of previous jobs from HBase or HDFS. Many times our map-reduce job flow can be represented as a map-reduce-reduce pattern, however building complex job chains with the current map-reduce framework is not that easy (nor saves on performance) &ndash; we combined the ChainMapper/ChainReducer and IdentityMapper trying to build MRR like DAG job flows.</p>

<p>In Tez data coming from reducers' output can be pipelined together and eliminates IO/sync barriers, as no temporary HDFS write is required. Jobs can also be chained and represented as MRR steps with no restriction.
In MapReduce disregarding the data size, the shuffle (internal step between the map and reducer) phase writes the sorted partitions to disk, merge-sorts them and feed into the reducers. All these steps are done <em>in memory</em> with Tez and saves on this I/O heavy step, avoiding unnecessary temporary writes and reads.</p>

<h2>Tez and Mahout</h2>

<p>Part of our system is running machine learning algorithms in batch, using Mahout (we do ML on streaming data using Scala, MLlib and Apache Spark as well). To improve the runtime performance of these Mahout algorithms, and decrease the cluster execution time we started to experiment with combining Tez and Mahout, and rewrite a few Mahout drivers in order to build DAGs of MR jobs (MRR in particular where applicable) and submit the jobs in a Tez runtime on a YARN cluster.</p>

<!--more-->


<p>In this blog post we would like to introduce you to Tez &ndash; for your convenience we have put together a Hadoop 2.3/YARN/Tez  <a href="https://github.com/sequenceiq/tez-docker">Tez-Docker</a> image &ndash; where the Tez runtime is already pre-configured. We have submitted a Mahout classification job into a YARN cluster as a regular MR job and then resubmitted the same job into Tez on a YARN cluster. Finally we made some metrics to highlight the differences: both in elapsed time and resource utilization.</p>

<p>If you don&rsquo;t want to use this docker image, you should configure Tez on your Hadoop cluster first.</p>

<h3>Building Tez</h3>

<p>Get the Tez code from <a href="https://github.com/apache/incubator-tez">GitHub</a>, and run <code>mvn clean install -DskipTests=true -Dmaven.javadoc.skip=true</code>. Alternatively you can get the jars from <a href="https://s3-eu-west-1.amazonaws.com/seq-tez/tez-0.3.0-incubating.tar.gz">SequenceIQ S3</a> and copy into HDFS under the &lsquo;/usr/lib/tez&rsquo; folder.</p>

<h3>Add *-site.xml</h3>

<p>Add <a href="https://raw.githubusercontent.com/sequenceiq/tez-docker/master/tez-site.xml">tez-site.xml</a> and <a href="https://github.com/sequenceiq/tez-docker/blob/master/mapred-site.xml">mapred-site.xml</a> to Hadoop (in case of the docker image it&rsquo;s $HADOOP_PREFIX/etc/hadoop/).</p>

<h3>Add Tez jars and config to HADOOP_CLASSPATH</h3>

<p>Edit your hadoop-env.sh file by executing this script:</p>

<p><code>bash
echo 'TEZ_JARS=/usr/local/tez/*' &gt;&gt; $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh
echo 'TEZ_LIB=/usr/local/tez/lib/*' &gt;&gt; $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh
echo 'TEZ_CONF=/usr/local/hadoop/etc/hadoop' &gt;&gt; $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh
echo 'export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$TEZ_CONF:$TEZ_JARS:$TEZ_LIB' &gt;&gt; $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh
</code></p>

<p>Make sure you set your HADOOP_PREFIX env variable, or use <a href="http://ambari.apache.org/">Apache Ambari</a> to configure Tez (change the mapreduce.framework.name property to yarn-tez).</p>

<h3>Submit a classification job &ndash; get the code and instructions from the SequenceIQ samples <em><a href="https://github.com/sequenceiq/sequenceiq-samples/tree/master/tez-dag-jobs">GitHub</a></em> page.</h3>

<p>After running the job and collecting the metrics we will see that the differences between using MapReduce and Tez are quite significant (~10x faster with Tez).</p>

<p>Below you can see the sample Mahout classification job submitted in YARN using MapReduce.</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/tez-dag-jobs/resources/Classification_Mahout_MR.png" alt="" /></p>

<p>Below you can see the sample Mahout classification job submitted in YARN using Tez.</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/tez-dag-jobs/resources/Classification_Mahout_TEZ.png" alt="" /></p>

<p>If we dig into deeper metrics we can see the huge differences between the file operations and HDFS I/O. The Tez framework does way less file operations as the MapReduce one.</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/tez-dag-jobs/resources/fileops_tez_vs_mr.png" alt="" /></p>

<p>Also if we check the HDFS I/O operations we see the same results &ndash; less and more efficient HDFS operations in case of Tez.</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/tez-dag-jobs/resources/hdfsio_tez_vs_mr.png" alt="" /></p>

<p>All these are because the Tez runtime is using in-memory operations whenever is possible instead of temporarily persisting the sorted partitions to HDFS.
Tez and <a href="http://hortonworks.com/labs/stinger/">Hortonworks' Stinger initiative</a> is opening up new possibilities to write faster and more performant Hadoop jobs, and closes the gap between stream and batch processing.</p>

<p>We are in the middle of rewriting &ndash; and sharing with the Hadoop community all the Mahout drivers we use &ndash; to Apache Tez. Also we are in the middle of proof-of-concepting our Scala/Scalding based map-reduce jobs to use Tez as a runtime.</p>

<p>Follow up with this <a href="http://blog.sequenceiq.com/">blog</a> and visit our <a href="https://github.com/sequenceiq/sequenceiq-samples/tree/master/tez-dag-jobs">GitHub</a> page for further details.</p>
]]></content>
  </entry>
  
</feed>
