<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Hortonworks | SequenceIQ Blog]]></title>
  <link href="http://blog.sequenceiq.com/blog/categories/hortonworks/atom.xml" rel="self"/>
  <link href="http://blog.sequenceiq.com/"/>
  <updated>2015-01-07T14:28:40+00:00</updated>
  <id>http://blog.sequenceiq.com/</id>
  <author>
    <name><![CDATA[SequenceIQ]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[SequenceIQ Joins Hortonworks Technology Partner Program]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/09/30/hortonworks-partnership/"/>
    <updated>2014-09-30T16:00:00+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/09/30/hortonworks-partnership</id>
    <content type="html"><![CDATA[<p>Integration of Hortonworks Data Platform with Cloudbreak enables Hadoop to run in Docker containers &ndash; shipped to the cloud.</p>

<p><strong>SAN FRANCISCO, September 30, 2014</strong> — <a href="http://sequenceiq.com/">SequenceIQ ,Inc.</a> today announced that it has joined the <a href="http://hortonworks.com/partners/become-a-partner/">Hortonworks® Technology Partner Program</a>. <a href="http://hortonworks.com/">Hortonworks</a> is the leading contributor to and provider of Apache™ Hadoop®. SequenceIQ will integrate <a href="http://hortonworks.com/hdp/">Hortonworks Data Platform</a> (HDP) with Cloudbreak to enable a cloud agnostic, autoscaling and <a href="https://www.docker.com/">Docker</a> container based provisioning of HDP.</p>

<p>By joining the Hortonworks Technology Partner program, SequenceIQ will work to enable and accelerate the deployment of a modern data architecture, integrating with the Hortonworks Data Platform—the industry’s only 100 percent open source Hadoop distribution, explicitly architected, built, and tested for enterprise-grade deployments.</p>

<p>SequenceIQ’s technology enables organizations to have a DevOps friendly way to ease and automate provisioning of on-demand Hadoop clusters and services using their favorite cloud provider. With the integration of HDP, users can now leverage all the available features of a 100 percent open source commercial Hadoop distribution.</p>

<p>“SequenceIQ and Hortonworks share a common goal of making the provisioning of Apache Hadoop clusters easier on different cloud and Docker container based environments,” said Janos Matyas, chief technology officer of SequenceIQ. “Cloudbreak and HDP help enterprises to minimize the cost of their Hadoop deployments, and create on-demand autoscaling Hadoop clusters.”</p>

<!-- more -->


<p>Hortonworks Data Platform was built by the core architects, builders and operators of Apache Hadoop and includes all of the necessary components to manage a cluster at scale and uncover business insights from existing and new big data sources. With a <a href="http://hortonworks.com/hadoop/yarn/">YARN</a>-based architecture, HDP is an important component of the modern data architecture, helping organizations mine, process and analyze large batches of unstructured data sets to make more informed business decisions.</p>

<p>“Hortonworks is dedicated to expanding and empowering the Apache Hadoop ecosystem, accelerating innovation and adoption of 100 percent open source enterprise Hadoop,” said John Kreisa, vice president of strategic marketing at Hortonworks. “We welcome SequenceIQ to the Hortonworks Technology Partner Program and look forward to working with them to strengthen Hadoop’s role as the foundation of the next-generation data architecture.”</p>

<p>About SequenceIQ</p>

<p>SequenceIQ is an innovative big data startup with the mission statement to simplify and automate provisioning of on-demand Hadoop clusters running on different environments. Leaders in “containerizing” Hadoop, SequenceIQ is the first company who provisions and runs the full Hadoop stack and components on Docker containers. The company has further plans to create the industry’s first cloud agnostic, autoscaling and use case driven Platform as a Service API, and break the common significant barriers of entry that exist with most big data projects through a series of As-a-Service API offerings.
For more information follow up with us on @SequenceIQ and <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>.</p>

<p><a href="&#x6d;&#97;&#105;&#x6c;&#116;&#x6f;&#x3a;&#105;&#110;&#102;&#111;&#x40;&#115;&#x65;&#113;&#x75;&#101;&#110;&#x63;&#101;&#x69;&#x71;&#x2e;&#x63;&#x6f;&#x6d;">&#x69;&#x6e;&#102;&#111;&#64;&#x73;&#101;&#113;&#117;&#101;&#x6e;&#x63;&#x65;&#x69;&#x71;&#x2e;&#x63;&#111;&#109;</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Mahout with Tez]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/03/31/mahout-on-tez/"/>
    <updated>2014-03-31T10:22:09+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/03/31/mahout-on-tez</id>
    <content type="html"><![CDATA[<p>At SequenceIQ we are always open to the latest innovations in Hadoop, and trying to find a way to offer a better performance and cluster utilization to our customers. We came in close touch with the <a href="http://hortonworks.com/labs/stinger/">Stinger initiative</a> last year at the Hadoop Summit in Amsterdam &ndash; and ever since we have followed up with the project progress (latest <a href="http://hortonworks.com/blog/apache-tez-0-3-released/">release</a> is 0.3). The project was initiated by Hortonworks with the goal of a 100x performance improvement of Hive.
Although Hive is not part of our product stack (we use other ways for SQL on Hadoop), there is one particular key component of the Stinger initiative which was very interesting to us: <a href="https://github.com/apache/incubator-tez">Apache Tez</a>.</p>

<p><a href="http://incubator.apache.org/projects/tez.html">Apache Tez</a> is a new application framework built on top of Hadoop Yarn that can execute complex directed acyclic graphs (DAGs) of general data processing tasks. In many ways it can be thought of as a more flexible and powerful successor of the map-reduce framework. This was exactly what draw our attention and made us start thinking about using Tez as our runtime for map-reduce jobs.</p>

<h2>Tez and MapReduce</h2>

<p>At SequenceIQ we have chains of map-reduce jobs which are scheduled individually and read the output of previous jobs from HBase or HDFS. Many times our map-reduce job flow can be represented as a map-reduce-reduce pattern, however building complex job chains with the current map-reduce framework is not that easy (nor saves on performance) &ndash; we combined the ChainMapper/ChainReducer and IdentityMapper trying to build MRR like DAG job flows.</p>

<p>In Tez data coming from reducers' output can be pipelined together and eliminates IO/sync barriers, as no temporary HDFS write is required. Jobs can also be chained and represented as MRR steps with no restriction.
In MapReduce disregarding the data size, the shuffle (internal step between the map and reducer) phase writes the sorted partitions to disk, merge-sorts them and feed into the reducers. All these steps are done <em>in memory</em> with Tez and saves on this I/O heavy step, avoiding unnecessary temporary writes and reads.</p>

<h2>Tez and Mahout</h2>

<p>Part of our system is running machine learning algorithms in batch, using Mahout (we do ML on streaming data using Scala, MLlib and Apache Spark as well). To improve the runtime performance of these Mahout algorithms, and decrease the cluster execution time we started to experiment with combining Tez and Mahout, and rewrite a few Mahout drivers in order to build DAGs of MR jobs (MRR in particular where applicable) and submit the jobs in a Tez runtime on a YARN cluster.</p>

<!--more-->


<p>In this blog post we would like to introduce you to Tez &ndash; for your convenience we have put together a Hadoop 2.3/YARN/Tez  <a href="https://github.com/sequenceiq/tez-docker">Tez-Docker</a> image &ndash; where the Tez runtime is already pre-configured. We have submitted a Mahout classification job into a YARN cluster as a regular MR job and then resubmitted the same job into Tez on a YARN cluster. Finally we made some metrics to highlight the differences: both in elapsed time and resource utilization.</p>

<p>If you don&rsquo;t want to use this docker image, you should configure Tez on your Hadoop cluster first.</p>

<h3>Building Tez</h3>

<p>Get the Tez code from <a href="https://github.com/apache/incubator-tez">GitHub</a>, and run <code>mvn clean install -DskipTests=true -Dmaven.javadoc.skip=true</code>. Alternatively you can get the jars from <a href="https://s3-eu-west-1.amazonaws.com/seq-tez/tez-0.3.0-incubating.tar.gz">SequenceIQ S3</a> and copy into HDFS under the &lsquo;/usr/lib/tez&rsquo; folder.</p>

<h3>Add *-site.xml</h3>

<p>Add <a href="https://raw.githubusercontent.com/sequenceiq/tez-docker/master/tez-site.xml">tez-site.xml</a> and <a href="https://github.com/sequenceiq/tez-docker/blob/master/mapred-site.xml">mapred-site.xml</a> to Hadoop (in case of the docker image it&rsquo;s $HADOOP_PREFIX/etc/hadoop/).</p>

<h3>Add Tez jars and config to HADOOP_CLASSPATH</h3>

<p>Edit your hadoop-env.sh file by executing this script:</p>

<p><code>bash
echo 'TEZ_JARS=/usr/local/tez/*' &gt;&gt; $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh
echo 'TEZ_LIB=/usr/local/tez/lib/*' &gt;&gt; $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh
echo 'TEZ_CONF=/usr/local/hadoop/etc/hadoop' &gt;&gt; $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh
echo 'export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$TEZ_CONF:$TEZ_JARS:$TEZ_LIB' &gt;&gt; $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh
</code></p>

<p>Make sure you set your HADOOP_PREFIX env variable, or use <a href="http://ambari.apache.org/">Apache Ambari</a> to configure Tez (change the mapreduce.framework.name property to yarn-tez).</p>

<h3>Submit a classification job &ndash; get the code and instructions from the SequenceIQ samples <em><a href="https://github.com/sequenceiq/sequenceiq-samples/tree/master/tez-dag-jobs">GitHub</a></em> page.</h3>

<p>After running the job and collecting the metrics we will see that the differences between using MapReduce and Tez are quite significant (~10x faster with Tez).</p>

<p>Below you can see the sample Mahout classification job submitted in YARN using MapReduce.</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/tez-dag-jobs/resources/Classification_Mahout_MR.png" alt="" /></p>

<p>Below you can see the sample Mahout classification job submitted in YARN using Tez.</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/tez-dag-jobs/resources/Classification_Mahout_TEZ.png" alt="" /></p>

<p>If we dig into deeper metrics we can see the huge differences between the file operations and HDFS I/O. The Tez framework does way less file operations as the MapReduce one.</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/tez-dag-jobs/resources/fileops_tez_vs_mr.png" alt="" /></p>

<p>Also if we check the HDFS I/O operations we see the same results &ndash; less and more efficient HDFS operations in case of Tez.</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/tez-dag-jobs/resources/hdfsio_tez_vs_mr.png" alt="" /></p>

<p>All these are because the Tez runtime is using in-memory operations whenever is possible instead of temporarily persisting the sorted partitions to HDFS.
Tez and <a href="http://hortonworks.com/labs/stinger/">Hortonworks' Stinger initiative</a> is opening up new possibilities to write faster and more performant Hadoop jobs, and closes the gap between stream and batch processing.</p>

<p>We are in the middle of rewriting &ndash; and sharing with the Hadoop community all the Mahout drivers we use &ndash; to Apache Tez. Also we are in the middle of proof-of-concepting our Scala/Scalding based map-reduce jobs to use Tez as a runtime.</p>

<p>Follow up with this <a href="http://blog.sequenceiq.com/">blog</a> and visit our <a href="https://github.com/sequenceiq/sequenceiq-samples/tree/master/tez-dag-jobs">GitHub</a> page for further details.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Hortonworks Hoya at SequenceIQ]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/03/24/hoya-at-sequenceiq/"/>
    <updated>2014-03-24T03:54:09+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/03/24/hoya-at-sequenceiq</id>
    <content type="html"><![CDATA[<p>With this blog post we are starting a series of articles where we&rsquo;d like to describe how we use YARN, why it is central to our product stack and why we believe that Hortonworks Hoya will be a determining building block in the Hadoop ecosystem.</p>

<p>While we don&rsquo;t want to get in details about <a href="http://hortonworks.com/hadoop/yarn/">YARN</a>, we&rsquo;d like to briefly explain the advantages of running an application on YARN, and introduce you to <a href="https://github.com/hortonworks/hoya">Hortonworks Hoya</a>.</p>

<p>At SequenceIQ we are building a multi-tenant, scale on demand data platform, with unpredictable batch and streaming workloads.
Before YARN we have tried different cluster management frameworks with Hadoop and managed to have pretty good results with <a href="http://aws.amazon.com/autoscaling/">Amazon EC2 Autoscaling groups</a>. Being true believers in open source and the need to diversify of provisioning Hadoop on different environments we needed to find an open source and &lsquo;standardised&rsquo; solution &ndash; welcome YARN.
(for example we provision Hadoop on <a href="http://blog.sequenceiq.com/blog/2014/03/19/hadoop-2-dot-3-with-docker/">Docker</a>).</p>

<p>YARN separates the processing engine from the resource management &ndash; and acting effectively as an OS for Hadoop.
With YARN, you can now run multiple applications in Hadoop, all sharing a common resource management and improving cluster utilisation (we will release some metrics soon).
YARN also provides the following features out of the box:</p>

<ul>
<li>Multi-tenancy</li>
<li>Management and monitoring</li>
<li>High availability</li>
<li>Security</li>
<li>Failover and recovery</li>
</ul>


<p>All of the above and the effort of the Hadoop community and the wide adoption convinced us to start implementing our platform to run on top of YARN.
During our proof of concepts we went as far as starting all our non Hadoop (and not YARN compatible) applications on YARN &ndash; using <a href="https://github.com/hortonworks/hoya">Hoya</a>.</p>

<p>Hoya was introduced by Hortonworks mid last year &ndash; with the purpose to create Apache HBase clusters on YARN (since than it supports Apache Accumulo as well).
The code evolved pretty fast and now Hoya is a framework/application which allows you to deploy existing distributed applications on YARN &ndash; and benefit all the nice features of YARN.</p>

<p>In order to support different applications Hoya has a plugin provider architecture (supported plugins are in the <em>org.apache.hoya.providers</em> package).
Once a plugin is implemented (pretty straightforward, took us a few days only to understand and build a Flume and Tomcat plugin), the application is started in a YARN container and is monitored and controlled by YARN/Hoya.
The clusters can be started, stopped, frozen and re-sized dynamically &ndash; and in case of container failures Hoya deploys a replacement.</p>

<p>For a better architectural understanding of Hoya please read the following blog <a href="http://hortonworks.com/blog/hoya-hbase-on-yarn-application-architecture/">post</a>.</p>

<p>In this first post we would like to help you to get familiar with the benefits offered by Hoya and start an HBase cluster, re-scale it dynamically, freeze and stop.
First and foremost you will need an installation of Hadoop (2.3), the latest Hoya release (0.13.1) and HBase (0.98).
For your convenience we have put together an automated install script which lets you start with Hoya in a few minutes.</p>

<p>The script is available from our <a href="https://github.com/sequenceiq/hoya-docker/blob/master/hoya-centos-install.sh">GitHub page</a>. Also an official docker.io image is available at <a href="https://index.docker.io/u/sequenceiq/hoya-docker/">hoya-docker</a>, and the Dockerfile can be downloaded from our <a href="https://github.com/sequenceiq/hoya-docker">GitHub</a> page.</p>

<p>Once Hadoop, HBase and Hoya are installed you can create an HBase cluster.
``` bash
create-hoya-cluster() {
  hoya create hbase &mdash;role master 1 &mdash;role worker 1</p>

<pre><code>--manager localhost:8032
--filesystem hdfs://localhost:9000 --image hdfs://localhost:9000/hbase.tar.gz
--appconf file:///tmp/hoya-master/hoya-core/src/main/resources/org/apache/hoya/providers/hbase/conf
--zkhosts localhost
</code></pre>

<p>}
```
This will launch a 2 node HBase cluster (1 Master and 1 RegionServer). Now lets increase the number of RegionServers.</p>

<p><code>bash
flex-hoya-cluster() {
  num_of_workers=$1
  hoya flex hbase --role worker $num_of_workers --manager localhost:8032 --filesystem hdfs://localhost:9000
}
</code></p>

<!-- more -->


<p>This will start as many RegionServers as specified &ndash; in new YARN containers. Also the size of the cluster can be decreased if the load on the system does not demand for a larger number of RegionServers. The cluster can also be freezed (Hoya takes care about persisting the state).</p>

<p><code>bash
freeze-hoya-cluster() {
  hoya freeze hbase --manager localhost:8032 --filesystem hdfs://localhost:9000
}
</code></p>

<p>Finally when you&rsquo;d like to destroy the cluster and the state associated with the application you can use:</p>

<p><code>bash
destroy-hoya-cluster() {
  hoya destroy hbase --manager localhost:8032 --filesystem hdfs://localhost:9000
}
</code>
As you see installing Hoya and starting different applications (HBase in this case) is very simple &ndash; and all the nice features of YARN are instantly available for any clustered applications.
In our next post we will drive you through the steps of creating your own Hoya provider, deploy it and run on a YARN cluster.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Set up HDP2 on Amazon EC2]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/02/07/hdp2-on-amazon/"/>
    <updated>2014-02-07T16:17:04+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/02/07/hdp2-on-amazon</id>
    <content type="html"><![CDATA[<p>During the last years we have seen many blog entries and articles about how to set up Hadoop on Amazon EC2. All these tutorials and articles had one thing in common &ndash; you had to go through a large number of manual (and painful) steps, read screenshots and redo the whole thing all over again, in case you needed a new cluster.</p>

<p>Since we use Amazon EC2 quite a lot, and Hadoop as well (Hortonworks distribution) we have gone through these steps many times &ndash; and have scripted the whole process from the first steps up to launching an N node Hadoop/HDP2 cluster in less then five minutes.</p>

<p>Moreover, the cluster is a &lsquo;production ready&rsquo; setup from infrastructural point of view &ndash; it is provisioned in a logically isolated section of the cloud (Virtual Private Cloud), with his own IP address range, creation of subnets, and configuration of route tables and network gateways.</p>

<p>Once the instances are provisoned, the HDP2 setup is done by Apache Ambari &ndash; for more advanced users we will provide the setup thorugh Ambari&rsquo;s RESTful API &ndash; watch this space or our GitHub page.</p>

<p>All the EC2 instances are tagged with the user name &ndash; thus you can create different clusters for different employees, all under the same AWS account (with IAM).</p>

<p>We believe that this is the right way to provision Hadoop in the cloud &ndash; during development and testing we had to provision Hadoop clusters of different sizes, and going through these steps manually would take lots of time.
This way we are able to provision clusters in the cloud in the matter of minutes &ndash; independently of the size.</p>

<p>The script is available at: <a href="https://github.com/sequenceiq/hadoop-cloud-scripts">https://github.com/sequenceiq/hadoop-cloud-scripts</a></p>

<p>Enjoy,
SequenceIQ</p>
]]></content>
  </entry>
  
</feed>
