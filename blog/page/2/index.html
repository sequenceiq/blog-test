
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>SequenceIQ Blog</title>
  <meta name="author" content="SequenceIQ">

   
  <meta name="description" content="">
  
  <meta name="keywords" content="">

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://blog.sequenceiq.com/blog/page/2">
  <link href="/favicon.png" rel="icon">
  <link href='http://fonts.googleapis.com/css?family=Quicksand:300,400' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,300' rel='stylesheet' type='text/css'>
    <link href="/stylesheets/sequenceiq.css" media="screen, projection" rel="stylesheet" type="text/css">
   <!-- <link href="/stylesheets/syntax.css" media="screen, projection" rel="stylesheet" type="text/css">-->
    <link href="/stylesheets/bootstrap.css" rel='stylesheet' type='text/css'>
  <link href="/stylesheets/bootstrap-theme.css"rel='stylesheet' type='text/css'>
 <!-- <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">-->

  <link href="/blog/atom.xml" rel="alternate" title="SequenceIQ Blog" type="application/atom+xml">
  <script src="/js/jquery.js"></script>
  <script src="/js/bootstrap-collapse.js"></script>
  <script src="/js/modernizr-2.0.js"></script>
  <script src="/js/octopress.js" type="text/javascript"></script>
  <script src="/js/application.js"></script>
  <script src="/js/bootstrap.js"></script>
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >

  <!--<div class="jumbotron seq-jumborton">-->
  <!--<div class="container">
      <a href="/">
        <img src="/images/logo.png" >
      </a>
    <h3 class="tagline">
      
        Our view on big data
      
    </h3>
  </div>-->
  <!--  <div class="navbar-static-top" id="company_div">
        <a href="http://sequenceiq.com/">
            <h5 style="margin: 0; margin-right: 5px;padding-bottom: 2px;padding-top: 2px; padding-right: 50px; font-weight: bolder;color: #003140;font-size: 10px;" class="pull-right" >SEQUENCEIQ.COM</h5>
        </a>
    </div>-->
    <header class="navbar navbar-static-top bs-docs-nav" id="top" role="banner" >
        <div class="container">
            <div class="navbar-header">
                <button class="navbar-toggle" type="button" data-toggle="collapse" data-target=".bs-navbar-collapse">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="http://sequenceiq.com/" class="navbar-brand">
                    <img id="logo" src="http://sequenceiq.com/img/logo@2x.png" width="154" height="39" alt="SequenceIQ">
                </a>
            </div>
            <div class="collapse navbar-collapse" role="navigation" style="/* margin-right: 6.2em; */">
                <ul class="nav navbar-nav navbar-right" id="menu-tag">
                    <li><a href="http://blog.sequenceiq.com/">Blog</a></li>
                    <li><a href="http://blog.sequenceiq.com/archives/">Archives</a></li>
                </ul>

            </div>
        </div>
    </header>
  <div class="container social-jumbotron-container">
      <div class="row">
        
        <div class="col-md-1"><a class="social-link" href="http://github.com/sequenceiq" title="Github Profile"><i class="icon-github-sign social-navbar"></i></a></div>
        
        
        
        <div class="col-md-1"><a class="social-link" href="http://linkedin.com/company/sequenceiq" title="Linkedin Profile"><i class="icon-linkedin-sign social-navbar"></i></a></div>
        
        
        <div class="col-md-1"><a class="social-link" href="http://twitter.com/sequenceiq" title="Twitter Profile"><i class="icon-twitter-sign social-navbar"></i></a></div>
        
        
        
        <div class="col-md-1"><a class="social-link" href="http://facebook.com/sequenceiq" title="Facebook Profile"><i class="icon-facebook-sign social-navbar"></i></a></div>
        
        

        
     </div>
  </div>
<!--</div>-->


  <div id="silent-container">

  </div>
  <div class="container" style="width: 95%;">
      <div class="row" id="main">
              <div class="col-md-9" id="">
                  <div class="">
                   <!-- <div id="content">-->
                      <div class="blog-index">
  
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/11/04/yarn-timeline-service-tez/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">04 November 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/timeline-service/"><span class="label label-warning">Timeline service</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/11/04/yarn-timeline-service-tez/">YARN Timeline Service</a>
          <span class="badge name-badge">Laszlo Puskas</span>

      </h1>
      <p>As you may know from our earlier <a href="http://blog.sequenceiq.com/blog/2014/10/07/hadoop-monitoring/">blogposts</a> we are continuously monitoring and trying to find out what happens inside our YARN clusters, let it be MapReduce jobs, TEZ DAGs, etc&hellip; We&rsquo;ve analyzed our clusters from various aspects so far; now it&rsquo;s the time to take a look at the information provided by the built YARN <code>timeline</code> service.</p>

<p>This post is about how to set up a YARN cluster so that the Timeline Server is available and how to configure applications running in the cluster to report information to it. As an example we&rsquo;ve chosen to run a simple TEZ example. (MapReduce2 also reports to the <code>timeline</code> service)</p>

<p>As a playground we will use a multinode cluster set up on the local machine; alternatively one could do the same on a cluster provisioned with <a href="http://sequenceiq.com/cloudbreak">Cloudbreak</a>. Cluster nodes run in Docker containers, YARN / TEZ provisioning and configuration is done with <a href="http://ambari.apache.org/">Apache Ambari</a>.</p>

<h2>Building a multinode cluster</h2>

<p>To build a multinode cluster we use a set of commodity functions that you can install by running the following in a terminal:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -Lo .amb j.mp/docker-ambari && . .amb</span></code></pre></td></tr></table></div></figure>


<p>(The commodity functions use our docker-ambari image: sequenceiq/ambari:1.6.0)</p>


      
       <a href="/blog/2014/11/04/yarn-timeline-service-tez/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/11/02/spark-on-tez/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">02 November 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/apache-spark/"><span class="label label-warning">Apache Spark</span></a>
            
            <a href="/blog/categories/apache-tez/"><span class="label label-warning">Apache Tez</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/11/02/spark-on-tez/">Spark on Tez execution context - running in Docker</a>
          <span class="badge name-badge">Janos Matyas</span>

      </h1>
      <p>Last week Hortonworks <a href="http://hortonworks.com/blog/improving-spark-data-pipelines-native-yarn-integration/">announced</a> improvements for running Apache Spark at scale by introducing a new pluggable <code>execution context</code> and has <a href="https://github.com/hortonworks/spark-native-yarn-samples">open sourced</a> it.</p>

<p>At <a href="http://sequenceiq.com/">SequenceIQ</a> we are always trying to work and offer the latest technology solutions for our clients and help them to choose their favorite technology/option. We are running a project called <a href="http://docs.banzai.apiary.io/">Banzai Pipeline</a> &ndash; to be open sourced soon &ndash; with the goal (among many others) to abstract and allow our customers to use their favorite big data runtime: MR2, Spark or Tez. Along this process we have <code>dockerized</code> most of the Hadoop ecosystem &ndash; we are running MR2, Spark, Storm, Hive, HBase, Pig, Oozie, Drill etc in Docker containers &ndash; on bare metal and in the cloud as well (all of these containers have made <strong>top</strong> downloads on the official Docker repository). For details you can check these older posts/resources:</p>

<table>
<thead>
<tr>
<th></th>
<th> Name                  </th>
<th> Description </th>
<th> Documentation </th>
<th> GitHub</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td> Apache Hadoop  </td>
<td> Pseudo distributed container </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/08/18/hadoop-2-5-0-docker/">http://blog.sequenceiq.com/blog/2014/08/18/hadoop-2-5-0-docker/</a> </td>
<td> <a href="https://github.com/sequenceiq/hadoop-docker">https://github.com/sequenceiq/hadoop-docker</a></td>
</tr>
<tr>
<td></td>
<td> Apache Ambari   </td>
<td> Multi node &ndash; full Hadoop stack, blueprint based </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/06/19/multinode-hadoop-cluster-on-docker/">http://blog.sequenceiq.com/blog/2014/06/19/multinode-hadoop-cluster-on-docker/</a> </td>
<td> <a href="https://github.com/sequenceiq/docker-ambari">https://github.com/sequenceiq/docker-ambari</a></td>
</tr>
<tr>
<td></td>
<td> Cloudbreak         </td>
<td> Cloud agnostic Hadoop as a Service </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/">http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/</a> </td>
<td> <a href="https://github.com/sequenceiq/cloudbreak">https://github.com/sequenceiq/cloudbreak</a></td>
</tr>
<tr>
<td></td>
<td> Periscope          </td>
<td> SLA policy based autoscaling for Hadoop clusters </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/">http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/</a> </td>
<td> <a href="https://github.com/sequenceiq/periscope">https://github.com/sequenceiq/periscope</a></td>
</tr>
</tbody>
</table>


<p>We have always been big fans on Apache Spark &ndash; due to the simplicity of development and at the same time we are big fans of Apache Tez, for reasons we have <a href="http://blog.sequenceiq.com/blog/2014/09/23/topn-on-apache-tez/">blogged before</a>.</p>

<p>When the <a href="https://issues.apache.org/jira/browse/SPARK-3561">SPARK-3561</a> has been submitted we were eager to get our hands on the WIP and early implementation &ndash; and this time we&rsquo;d like to help you with a quick ramp-up and easy solution to have a Spark Docker <a href="https://github.com/sequenceiq/docker-spark-native-yarn">container</a> where the <code>execution context</code> has been changed to <a href="http://tez.apache.org/">Apache Tez</a> and everything is preconfigured. The only thing you will need to do is to follow these easy steps.</p>

<h3>Pull the image from the Docker Repository</h3>

<p>We suggest to always pull the container from the official Docker repository &ndash; as this is always maintained and supported by us.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker pull sequenceiq/spark-native-yarn</span></code></pre></td></tr></table></div></figure>


<p>Once you have pulled the container you are ready to run the image.</p>

<h3>Run the image</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker run -i -t -h sandbox sequenceiq/spark-native-yarn /etc/bootstrap.sh -bash</span></code></pre></td></tr></table></div></figure>



      
       <a href="/blog/2014/11/02/spark-on-tez/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/30/cloudbreak-devops/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">30 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/cli/shell/"><span class="label label-warning">CLI/Shell</span></a>
            
            <a href="/blog/categories/cloudbreak/"><span class="label label-warning">Cloudbreak</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/30/cloudbreak-devops/">Deploying a Hadoop Cluster - DevOps way</a>
          <span class="badge name-badge">Marton Sereg</span>

      </h1>
      <p>A while ago we have announced <a href="http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/">Cloudbreak</a> &ndash; the open source Hadoop as a Service API. Included in the release we open sourced a REST API, REST client, UI and a CLI/shell. In this post we’d like to show you how easy is to use <a href="https://github.com/sequenceiq/cloudbreak-shell">Cloudbreak shell</a> in order to create on demand Hadoop clusters on your favorite cloud provider &ndash; record the process and automate it.</p>

<p>While it’s up to everybody&rsquo;s personal preference whether to use a UI, a command line interface or the REST API directly, at SequenceIQ we prefer to use command line tools whenever it’s possible because it’s much faster than interacting with a web UI and it’s a better candidate for automation. Are we <code>obsessed with automation</code>? Definitely yes &ndash; all the step which are candidates of doing it twice we script or automate it.</p>

<p>This <code>thing</code> with the automation does not affect the effort and quality standards we put on building the UI &ndash; <a href="https://cloudbreak.sequenceiq.com/">Cloudbreak</a> has an extremely intuitive and clean <strong>responsive</strong> UI and it’s built on the latest and greatest web UI framework &ndash; <a href="https://angularjs.org/">Angular JS</a>. We will have a post about the UI, however we consider it so simple to use that we ask you to go ahead and give it a try. You are a signup and a few clicks away from your Hadoop cluster.</p>

<p>Now back to the CLI. Remember one of our Apache contribution &ndash; the <a href="http://blog.sequenceiq.com/blog/2014/05/26/ambari-shell/">Ambari shell and REST API</a>? Well, the Cloudbreak shell is built on the same technology &ndash; Spring Shell. It’s an interactive shell that can be easily extended using a Spring based programming model and battle tested in various projects like Spring Roo, Spring XD, and Spring REST Shell Combine these two projects to create a powerful tool.</p>

<h2>Cloudbreak Shell</h2>

<p>The goal with the CLI was to provide an interactive command line tool which supports:</p>

<ul>
<li>all functionality available through the REST API or Cloudbreak web UI</li>
<li>makes possible complete automation of management task via <strong>scripts</strong></li>
<li>context aware command availability</li>
<li>tab completion</li>
<li>required/optional parameter support</li>
<li><strong>hint</strong> command to guide you on the usual path</li>
</ul>


<h2>Install Cloudbreak Shell</h2>

<p>You have 3 options to give it a try:</p>

<ul>
<li>use our prepared <a href="https://registry.hub.docker.com/u/sequenceiq/cloudbreak/">docker image</a></li>
<li>download the latest self-containing executable jar form our maven repo</li>
<li>build it from source</li>
</ul>


<h3>Build from source</h3>

<p>If want to use the code or extend it with new commands follow the steps below. You will need:
&ndash; jdk 1.7
&ndash; maven 3.x.x</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/sequenceiq/cloudbreak-shell.git
</span><span class='line'>cd cloudbreak-shell
</span><span class='line'>mvn clean package</span></code></pre></td></tr></table></div></figure>





      
       <a href="/blog/2014/10/30/cloudbreak-devops/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/28/datalake-cloudbreak/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">28 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/cloudbreak/"><span class="label label-warning">Cloudbreak</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/28/datalake-cloudbreak/">Building the data lake in the cloud - Part1</a>
          <span class="badge name-badge">Tamas Bihari</span>

      </h1>
      <p>A while ago we have released our cloud agnostic and Docker container based Hadoop as a Service API &ndash; <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a>. Though the purpose of <a href="https://cloudbreak.sequenceiq.com">Cloudbreak</a> is to quickly provision arbitrary sized Hadoop clusters in the cloud, the project emerged from bare metal Hadoop provisioning in Docker containers. We were (still doing it) <a href="http://blog.sequenceiq.com/blog/2014/06/19/multinode-hadoop-cluster-on-docker/">provisioning</a> Hadoop on bare metal using Docker &ndash; and because of this legacy the data was always stored in HDFS. Recently we have been asked to run a proof-of-concept project and build an <code>always on</code> data lake using a cloud <code>object storage</code>.</p>

<p>This post is the first in this series and will cover the connectivity, interoperability and access of data from an <code>object storage</code> and work with that in Hadoop. For this post we choose to create a <code>data lake</code> on Google Cloud Compute and guide you through the steps, run performance tests and understand the benefits/drawbacks of such a setup.</p>

<p><em>Next post will be about sharing the <code>data lake</code> among multiple clusters, using <a href="http://hortonworks.com/hadoop/hcatalog/">Apache HCatalog</a>.</em></p>

<h2>Object storage</h2>

<p>An object storage usually is an <code>internet service</code> to store data in the cloud and comes with a programming interface which allows to retrieve data in a secure, durable and highly-scalable way. The most well know object storage is <strong>Amazon S3</strong> &ndash; with a pretty well covered literature, thus in this example we will use the <strong>Google Cloud Storage</strong>. Google Cloud Storage enables application developers to store their data on Google’s infrastructure with very high reliability, performance and availability, and can be used to distribute large data objects &ndash; like HDFS. In many occasions companies stores their data in objects storages &ndash; but for analytics they would like to access it from their Hadoop cluster. There are several options available:</p>

<ul>
<li>replicate the full dataset in HDFS</li>
<li>read and write from <code>object storage</code> at start/stop of the flow and use HDFS for intermediary data</li>
<li>use a connector such as Google Cloud Storage Connector for Hadoop</li>
</ul>


<h2>Google Cloud Storage Connector for Hadoop</h2>

<p>Using <a href="https://cloud.google.com/hadoop/google-cloud-storage-connector">this</a> connector developed by Google allows you to choose <code>Google Cloud Storage</code> as the default file system for Hadoop, and run all your jobs on top (we will come up with MR2 and Spark examples). Using the connector can have several benefits, to name a few:</p>

<ul>
<li>Direct data access &ndash; data is stored in GCS, no need to transfer it into HDFS</li>
<li>HDFS compatibility &ndash; data stored in HDFS can be accessed through the connector</li>
<li>Data accessibility &ndash; data is always accessible, even when the Hadoop cluster is shut down</li>
<li>High data availability &ndash; data is highly available and globally replicated</li>
</ul>



      
       <a href="/blog/2014/10/28/datalake-cloudbreak/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/23/spark-operations-overview/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">23 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/spark/"><span class="label label-warning">Spark</span></a>
            
            <a href="/blog/categories/yarn/"><span class="label label-warning">YARN</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/23/spark-operations-overview/">Apache Spark RDD operation examples</a>
          <span class="badge name-badge">Oliver Szabo</span>

      </h1>
      <p>Recently we blogged about how you can write simple Apache Spark jobs and how to test them. Now we&rsquo;d like to introduce all basic RDD operations with easy examples (our goal is to come up with examples as simply as possible). The Spark <a href="http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations">documentation</a> explains well what each operations is doing in detail. We made tests for most of the RDD operations with good ol&#8217; <code>TestNG</code>. e.g.:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'> <span class="nd">@Test</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">testRightOuterJoin</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">input1</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">makeRDD</span><span class="o">(</span><span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="mi">4</span><span class="o">)))</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">input2</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">makeRDD</span><span class="o">(</span><span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="sc">&#39;1&#39;</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="sc">&#39;2&#39;</span><span class="o">)))</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">expectedOutput</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="o">(</span><span class="nc">Some</span><span class="o">(</span><span class="mi">4</span><span class="o">),</span> <span class="sc">&#39;1&#39;</span><span class="o">)),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="o">(</span><span class="nc">None</span><span class="o">,</span> <span class="sc">&#39;2&#39;</span><span class="o">)))</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">input1</span><span class="o">.</span><span class="n">rightOuterJoin</span><span class="o">(</span><span class="n">input2</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="nc">Assert</span><span class="o">.</span><span class="n">assertEquals</span><span class="o">(</span><span class="n">output</span><span class="o">.</span><span class="n">collect</span><span class="o">(),</span> <span class="n">expectedOutput</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>



      
       <a href="/blog/2014/10/23/spark-operations-overview/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/20/cascading-on-tez/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">20 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/apache-tez/"><span class="label label-warning">Apache Tez</span></a>
            
            <a href="/blog/categories/cascading/"><span class="label label-warning">Cascading</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/20/cascading-on-tez/">Cascading on Apache Tez</a>
          <span class="badge name-badge">Oliver Szabo</span>

      </h1>
      <p>In one of our previous <a href="http://blog.sequenceiq.com/blog/2014/09/23/topn-on-apache-tez/">posts</a> we showed how to do a TopK using directly the Apache Tez API. In this post we’d like to show how to do a similarly complex algorithm with Cascading &ndash; running on Apache Tez.
At <a href="http://sequenceiq.com">SequenceIQ</a> we use Scalding, Cascading and Spark to write most of our jobs. For a while our big data pipeline API called <a href="http://docs.banzai.apiary.io/">Banzai Pipeline</a> offers a unified API over different runtimes: MR2, Spark and Tez; recently Cascading has announced support for Apache Tez and we’d like to show you that by writing a detailed example.</p>

<h2>Cascading Application &ndash; GroupBy, Each, Every</h2>

<p>Cascading data flows are to be constructed from Source taps (input), Sink taps (output) and Pipes.
At first, we have to setup our properties for the Cascading flow.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>    <span class="n">Properties</span> <span class="n">properties</span> <span class="o">=</span> <span class="n">AppProps</span><span class="o">.</span><span class="na">appProps</span><span class="o">()</span>
</span><span class='line'>            <span class="o">.</span><span class="na">setJarClass</span><span class="o">(</span><span class="n">Main</span><span class="o">.</span><span class="na">class</span><span class="o">)</span>
</span><span class='line'>            <span class="o">.</span><span class="na">buildProperties</span><span class="o">();</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">properties</span> <span class="o">=</span> <span class="n">FlowRuntimeProps</span><span class="o">.</span><span class="na">flowRuntimeProps</span><span class="o">()</span>
</span><span class='line'>            <span class="o">.</span><span class="na">setGatherPartitions</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
</span><span class='line'>            <span class="o">.</span><span class="na">buildProperties</span><span class="o">(</span><span class="n">properties</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Then in order to use Apache Tez, setup the Tez specific <code>Flow Connector</code>.</p>


      
       <a href="/blog/2014/10/20/cascading-on-tez/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/17/boot2docker-tls-workaround/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">17 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/docker/"><span class="label label-warning">docker</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/17/boot2docker-tls-workaround/">Boot2docker TLS workaround</a>
          <span class="badge name-badge">Lajos Papp</span>

      </h1>
      <p>Docker 1.3.0 has been released with the invaluable <code>docker exec</code>
<a href="https://docs.docker.com/reference/commandline/cli/#exec">command</a>.</p>

<p>Boot2docker 1.3.0 delivered also some really neat features such
as <a href="https://github.com/boot2docker/boot2docker#virtualbox-guest-additions">Folder sharing</a>
with virtualbox guest additions. So finally OSX users are able to for example serve local html files in a container:
<code>docker run -v /Users/lalyos/webapp/:/usr/share/nginx/html:ro nginx</code></p>

<h2>Issue</h2>

<p>Boot2docker also changed Docker listening from <a href="http://0.0.0.0:2375">http://0.0.0.0:2375</a> to <a href="https://0.0.0.0:2376.">https://0.0.0.0:2376.</a>
While switching on TLS is highly recommended, but its not backward compatible.
Some tools or environments are relying to be able to connect to Docker
via simple http. So after upgrading to 1.3.0 something might be broken.</p>

<h2>Workaround</h2>

<h3>Update 2014-11-01</h3>

<p>Please note that since Boot2docker 1.3.1 is released, you can simply use <code>DOCKER_TLS=no</code>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ boot2docker ssh -t 'sudo vi /var/lib/boot2docker/profile'</span></code></pre></td></tr></table></div></figure>


<p>If you still want to run the daemon with TLS enabled, but need temporary access on
plain http, read on:</p>

<h3>Socat</h3>

<p>One alternative solution is to start a container which uses <code>socat</code> to proxy the unix
socket file <code>/var/run/docker.sock</code> as a tcp port. It is containerized for you:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$(docker run sequenceiq/socat)</span></code></pre></td></tr></table></div></figure>


<p>Now you can reach Docker the <em>old</em> way:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl http://192.168.59.103:2375/_ping
</span><span class='line'>OK</span></code></pre></td></tr></table></div></figure>



      
       <a href="/blog/2014/10/17/boot2docker-tls-workaround/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/16/using-uaa-as-an-identity-server/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">16 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/cloudfoundry/"><span class="label label-warning">CloudFoundry</span></a>
            
            <a href="/blog/categories/cloudbreak/"><span class="label label-warning">Cloudbreak</span></a>
            
            <a href="/blog/categories/docker/"><span class="label label-warning">Docker</span></a>
            
            <a href="/blog/categories/oauth2/"><span class="label label-warning">OAuth2</span></a>
            
            <a href="/blog/categories/uaa/"><span class="label label-warning">UAA</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/16/using-uaa-as-an-identity-server/">Securing Cloudbreak with OAuth2</a>
          <span class="badge name-badge">Marton Sereg</span>

      </h1>
      <p>When we first released <a href="https://cloudbreak.sequenceiq.com/">Cloudbreak</a> &ndash; our Hadoop as a Service API &ndash; it contained its own authentication and user management layer.
We were using basic authentication for the API calls so every request had to contain a username and a password <em>Base64</em> encoded in the authorization header.
Cloudbreak also had its own user representation and we were binding the resources &ndash; like clusters &ndash; to these users.</p>

<p>This approach had multiple flaws. As we were starting to develop multiple <a href="http://sequenceiq.com/periscope/">projects</a> for our future Platform as a Service solution it became obvious that we will have to refactor our whole user management layer out from Cloudbreak and <strong>share it across our projects</strong>.
Base64 encoding of usernames and passwords is not the best solution either even if transport layer security is working.</p>

<p>What comes into play almost instantly when dealing with these kind of problems is <strong>OAuth2</strong> but it&rsquo;s not as trivial as it first sounds.</p>

<h2>OAuth2</h2>

<p>The main &ldquo;problem&rdquo; with OAuth2 is that its <a href="http://tools.ietf.org/html/rfc6749">specification</a> leaves a lot of decisions up to the implementations.
First of all it does not speak at all about authentication, only authorization. It also leaves out details such as how to manage users, how scopes and tokens look like or how these tokens should be checked by a resource server.</p>

<p>Because of all these reasons implementing a full OAuth2 solution from scratch means a <em>lot</em> of work and reinventing the wheel and of course we didn&rsquo;t want to do that.
Luckily there are a few specifications that complement the original standard and there are also some solutions that implement not only the basic specification but these complementary specifications too.</p>

<p><strong><a href="https://github.com/cloudfoundry/uaa">UAA</a> is CloudFoundry&rsquo;s fully open source identity management service.</strong>
According to the documentation its primary role is as an OAuth2 provider that can issue tokens for client applications, but it can also authenticate users and can manage user accounts and OAuth2 clients through an HTTP API.
To achieve these things it uses these specifications:</p>

<ul>
<li><p><a href="http://openid.net/connect/">OpenID Connect</a> for authentication</p></li>
<li><p><a href="http://www.simplecloud.info/">SCIM</a> for user management</p></li>
<li><p><a href="http://self-issued.info/docs/draft-ietf-oauth-json-web-token.html">JWT</a> for token representation</p></li>
</ul>


<p>UAA adds a few more things on top of these like client management endpoints which makes it a complete solution as an identity server.
And the best thing is that it is <strong>fully configurable through environment variables and a YAML file</strong>.</p>


      
       <a href="/blog/2014/10/16/using-uaa-as-an-identity-server/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/15/hadoop-metrics/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">15 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/baywatch/"><span class="label label-warning">Baywatch</span></a>
            
            <a href="/blog/categories/hadoop/"><span class="label label-warning">Hadoop</span></a>
            
            <a href="/blog/categories/periscope/"><span class="label label-warning">Periscope</span></a>
            
            <a href="/blog/categories/metrics/"><span class="label label-warning">metrics</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/15/hadoop-metrics/">Real-time adjustments with Hadoop metrics</a>
          <span class="badge name-badge">Krisztian Horvath</span>

      </h1>
      <p>To properly understand and to be fully aware of the state of our Hadoop clusters at any time we needed a scalable and flexible solution
to monitor our Hadoop nodes. After investigating the possible solutions we realized that there is no available solution which satisfies
all our needs thus we&rsquo;ve created one and recently just open sourced it, called <a href="http://sequenceiq.com/periscope/#monitoring">Baywatch</a>. Baywatch is capable to capture and visualize real-time changes on Hadoop clusters to understand and make adjustments based on the submitted jobs resource
allocation needs. To plan ahead, viewing and comparing old and new metrics is just as
important as analyzing real-time ones, not to mention that we can find possible weaknesses and defects in our clusters.</p>

<p>To be able to do all of the above mentioned, Baywatch processes the metrics information produced by the Hadoop daemons. This might already sound familiar as we have another project called <a href="http://sequenceiq.com/periscope/">Periscope</a> where you can create alarms and cluster scaling activities making use of the same metrics, but just consuming it in a different way. Combine these 2
components and you&rsquo;ll have a powerful tool and you&rsquo;ll be able to view your cluster&rsquo;s state and based on that <code>make smart decisions</code>
to scale up or down, or simply just set alarms. If you&rsquo;re thrilled to see it in action we are at <a href="http://strataconf.com/stratany2014">Strata</a> and happy to show you a quick demo.</p>

<h2>Hadoop metrics</h2>

<p>So what are these metrics? As I mentioned it earlier metrics are collections of information about Hadoop daemons, e.g:
the <code>ResourceManager</code> produces information about the queue statuses which we use in Periscope when we <code>re-prioritise applications</code>.
To distinguish these metrics they are grouped into named contexts, e.g <code>jvm</code> for java virtual machine metrics, <code>rpc</code> for debugging
rcp calls, but there are many more:</p>

<ul>
<li>yarn</li>
<li>rpcdetailed</li>
<li>metricssystem</li>
<li>mapred</li>
<li>dfs</li>
<li>ugi</li>
</ul>


<p>This <code>Metrics2</code> framework is designed to collect and dispatch per-process metrics to monitor the overall status of the Hadoop system.
In Hadoop related technologies it is a common design to use sources and sinks, just like in this case. Metrics sources are where the
metrics are generated and metrics sinks consume the records generated by the metrics sources. A metrics system would poll the metrics
sources periodically and pass the metrics records to metrics sinks.</p>

<p><img src="http://yuml.me/0faf3738"></p>


      
       <a href="/blog/2014/10/15/hadoop-metrics/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/09/ngrok-docker/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">09 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/docker/"><span class="label label-warning">docker</span></a>
            
            <a href="/blog/categories/ngrok/"><span class="label label-warning">ngrok</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/09/ngrok-docker/">Self hosted ngrok server in Docker</a>
          <span class="badge name-badge">Lajos Papp</span>

      </h1>
      <p><a href="vhttps://ngrok.com/">Ngrok</a> is used for <code>introspected</code> tunnels to localhost.
In integration testing situations is really common that you want to bind some webhooks
to localhost. For example you want AWS SNS deliver messages to your service,
but is not reachable publicly, as it runs only on localhost.</p>

<p>So its really 2 in 1: <strong>local tunnel</strong> and <strong>introspection</strong>. Sometimes you
just want to use its <strong>introspection</strong> feature, to get insight about how a
specific API works. It&rsquo;s like a local <a href="https://www.runscope.com/">runscope</a>.</p>

<p>While you can always use the free hosted version: <a href="https://ngrok.com/">ngrok</a>,
there are reasons to roll you own:</p>

<ul>
<li>Sometimes the free hosted version has <strong>availability</strong> issues,when it gets heavy traffic</li>
<li>Yo don&rsquo;t want your messages/calls go through a public free service, for
<strong>security</strong> concerns</li>
<li>You just want to use its <strong>introspection</strong> feature, and want to avoid the
extra <strong>network</strong> round trip to ngrok.com and back.</li>
</ul>


<p>There is documentation about <a href="https://github.com/inconshreveable/ngrok/blob/master/docs/SELFHOSTING.md">self hosting ngrok</a>
But it include steps, like:</p>

<ul>
<li>create an SSL certificate</li>
<li>build server/client binaries using the cert above</li>
<li>configure, and install it on your server</li>
</ul>


<p>How about using a <strong>single click</strong> version of this? Easy: we have already containerized
this process and made it available in the official Docker
<a href="https://registry.hub.docker.com/u/sequenceiq/ngrokd/">repository</a>.</p>


      
       <a href="/blog/2014/10/09/ngrok-docker/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
  
  <div class="pagination">
    
    <a class="prev" href="/blog/page/3/">&larr; Older</a>
    

    
    <a class="next" href="/">Newer &rarr;</a>
    
  </div>
</div>


                    <!--</div>-->
                  </div>

              </div>
              <div class="col-md-3">
                 <section>
  <h2 class="blue">Recent Posts</h2>
  <ul id="recent_posts" class="list-group">
    
      <li class="list-group-item">
        <a href="/blog/2014/12/12/cloudbreak-got-periscope/">Cloudbreak welcomes Periscope</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/12/04/multinode-ambari-1-7-0/">Multinode cluster with Ambari 1.7.0 - in Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/12/02/hadoop-2-6-0-docker/">Running Hadoop 2.6.0 in Docker containers</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/11/25/periscope-scale-your-cluster-on-time/">Periscope: time based autoscaling</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/11/24/hadoop-252-docker/">Apache Hadoop 2.5.2 on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/11/20/yarn-containers-and-docker/">YARN containers as Docker containers in Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/11/17/datalake-cloudbreak-2/">Building the data lake in the cloud - Part2</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/11/13/kylin-on-docker/">Extreme OLAP Engine running in Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/11/10/new-yarn-features-part-1-label-based-scheduling/">New YARN features: Label based scheduling</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/11/06/securing-cloudbreak-with-oauth2-part-2/">Securing Cloudbreak with OAuth2 - part 2</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/11/04/yarn-timeline-service-tez/">YARN Timeline Service</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/11/02/spark-on-tez/">Spark on Tez execution context - running in Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/30/cloudbreak-devops/">Deploying a Hadoop Cluster - DevOps way</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/28/datalake-cloudbreak/">Building the data lake in the cloud - Part1</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/23/spark-operations-overview/">Apache Spark RDD operation examples</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/20/cascading-on-tez/">Cascading on Apache Tez</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/17/boot2docker-tls-workaround/">Boot2docker TLS workaround</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/16/using-uaa-as-an-identity-server/">Securing Cloudbreak with OAuth2</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/15/hadoop-metrics/">Real-time adjustments with Hadoop metrics</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/09/ngrok-docker/">Self hosted ngrok server in Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/07/hadoop-monitoring/">Real-time monitoring of Hadoop clusters</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/30/hortonworks-partnership/">SequenceIQ Joins Hortonworks Technology Partner Program</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/29/spark-correlation-and-testing/">Apache Spark - create and test jobs</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/26/database-upgrade-process/">Managing database upgrades with Liquibase and Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/25/strata-hadoop-world-2014/">Strata + Hadoop World 2014 Startup Showcase</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/25/euroventures-invests-in-sequenceiq/">Euroventures invests in SequenceIQ</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/24/edit-files-docker/">Edit files in Docker containers</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/23/topn-on-apache-tez/">TopK on Apache Tez</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/19/apache-tez-cluster/">Apache Tez cluster on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/18/custom-image-on-gcc/">Cloudbreak new provider implementation - Part I: Build your custom image</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/17/spark-1-1-0-docker/">Apache Spark 1.1.0 on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/15/hadoop-2-5-1-docker/">Apache Hadoop 2.5.1 on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/11/apache-drill-docker/">Apache Drill on Docker - query as a service </a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/09/yarn-schedulers-demystified-part-2-fair/">YARN Schedulers demystified - Part 2: Fair</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/05/apache-ambari-1-7-0-ea/">Apache Ambari 1.7.0 early access</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/04/sql-on-hbase-with-apache-phoenix/">SQL on HBase with Apache Phoenix</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/01/sla-samples-periscope/">SLA policies for autoscaling Hadoop clusters</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/29/aws-cloudformation-makes-everything-easier/">Infrastructure management with CloudFormation</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/27/announcing-periscope/">Periscope - autoscaling for Hadoop YARN</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/22/spark-submit-in-java/">Submit a Spark job to YARN from code</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/18/hadoop-2-5-0-docker/">Apache Hadoop 2.5.0 on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/16/fairplay/">Fair play</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/12/docker-networking/">Docker intercontainer networking explained</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/07/clodubreak-shell/">Create Hadoop clusters in the cloud using a CLI</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/04/launch-docker-containers-on-azure/">Launch Docker containers on Azure</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/31/spark-mllib/">Apache Spark - MLlib Introduction</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/25/cloudbreak-technology/">Docker ships Hadoop to the cloud</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/22/schedulers-part-1/">YARN Schedulers demystified - Part 1: Capacity</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/18/announcing-cloudbreak/">Cloudbreak - the Hadoop as a Service API</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/13/groovy-and-java-runtime-bug/">Groovy and Java, the runtime bug</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/09/ambari-configuration-service/">Apache Ambari configuration service</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/05/docker-debug-with-nsenter-on-boot2docker/">Docker debug with nsenter on boot2docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/02/move-applications-between-queues/">Re-prioritize running jobs with YARN schedulers</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/06/25/hadoop-2-4-0-docker/">Apache Hadoop 2.4.1 on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/06/23/scalding-correlation-example/">Pearson correlation with Scalding</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/06/19/multinode-hadoop-cluster-on-docker/">Multi-node Hadoop cluster on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/06/17/ambari-cluster-on-docker/">Ambari provisioned Hadoop cluster on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/06/06/hadoop-summit-slides/">Hadoop Summit 2014 - SequenceIQ slides</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/05/26/ambari-shell/">Apache Ambari + Spring Shell = Ambari Shell</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/05/09/building-the-build-environment-with-ansible-and-docker/">Building the build environment with Ansible and Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/05/01/mapreduce-job-profiling-with-R/">Job profiling with R</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/04/17/apache-phoenix-sneak-peak/">Apache Phoenix (sneak peak)</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/04/14/mapreduce-with-scalding/">Writing MapReduce jobs in Scala</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/04/04/hadoop-docker-introduction/">Hadoop on Docker introduction</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/31/mahout-on-tez/">Using Mahout with Tez</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/24/hoya-at-sequenceiq/">Using Hortonworks Hoya at SequenceIQ</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/19/hadoop-2-dot-3-with-docker/">Hadoop 2.3 with docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/14/yarn-capacity-scheduler/">YARN Capacity Scheduler</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/11/data-cleaning-with-mapreduce-and-morphlines/">Data cleaning with MapReduce and Morphlines</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/07/read-from-hdfs/">HDFS and java.nio.channels</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/05/access-hdp2-sandbox/">Accessing HDP2 sandbox from the host</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/02/28/etl-and-data-quality/">ETL - producing better quality data</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/02/26/vote-for-us/">Vote for us - 2014 Hadoop Summit San Jose</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/02/22/custom-flume-source/">Custom Apache Flume source</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/02/07/hdp2-on-amazon/">Set up HDP2 on Amazon EC2</a>
      </li>
    
  </ul>
</section>

              </div>
      </div>
  </div>
  <div class="row-fluid" id="footer-container">
    <div class="container">
        <footer class="footer-page" role="contentinfo">
            <div class="row">
                <div class="col-md-6">
                    <div class="row">
    
    <div class="col-md-1"><a class="social-link" href="http://github.com/sequenceiq" title="Github Profile"><i class="fa fa-github fa-lg"></i></a></div>
    
    
    
    <div class="col-md-1"><a class="social-link" href="http://linkedin.com/company/sequenceiq" title="Linkedin Profile"><i class="fa fa-linkedin fa-lg"></i></a></div>
    
    
    <div class="col-md-1"><a class="social-link" href="http://twitter.com/sequenceiq" title="Twitter Profile"><i class="fa fa-twitter fa-lg"></i></a></div>
    
    
    
    <div class="col-md-1"><a class="social-link" href="http://facebook.com/sequenceiq" title="Facebook Profile"><i class="fa fa-facebook fa-lg"></i></a></div>
    
    

    
    <div class="col-md-1"><a class="social-link" href="http://blog.sequenceiq.com/atom.xml" title="RSS"><i class="fa fa-rss fa-lg"></i></a></div>

</div>

                </div>
                <div class="col-md-5">
                    


<p class="pull-right" >
  <span class="credit">&copy; SequenceIQ Inc. 2014. All rights reserved. </span>
    <br><a href="pp.html" style="color: #508190;">Privacy Policy</a> &nbsp; <a href="tos.html" style="color: #508190;">Terms of Service</a></p>
</p>


                </div>
            </div>
        </footer>
    </div>

  </div>
  

<script type="text/javascript">
      var disqus_shortname = 'sequenceiqblog';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=625149054184531";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>




  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-48528840-1', 'sequenceiq.com');
  ga('send', 'pageview');

</script>
</html>
