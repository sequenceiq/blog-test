
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>SequenceIQ Blog</title>
  <meta name="author" content="SequenceIQ">

   
  <meta name="description" content="">
  
  <meta name="keywords" content="">

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://blog.sequenceiq.com">
  <link href="/favicon.png" rel="icon">
  <link href='http://fonts.googleapis.com/css?family=Quicksand:300,400' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,300' rel='stylesheet' type='text/css'>
    <link href="/stylesheets/sequenceiq.css" media="screen, projection" rel="stylesheet" type="text/css">
   <!-- <link href="/stylesheets/syntax.css" media="screen, projection" rel="stylesheet" type="text/css">-->
    <link href="/stylesheets/bootstrap.css" rel='stylesheet' type='text/css'>
  <link href="/stylesheets/bootstrap-theme.css"rel='stylesheet' type='text/css'>
 <!-- <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">-->

  <link href="/blog/atom.xml" rel="alternate" title="SequenceIQ Blog" type="application/atom+xml">
  <script src="/js/jquery.js"></script>
  <script src="/js/bootstrap-collapse.js"></script>
  <script src="/js/modernizr-2.0.js"></script>
  <script src="/js/octopress.js" type="text/javascript"></script>
  <script src="/js/application.js"></script>
  <script src="/js/bootstrap.js"></script>
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >

  <!--<div class="jumbotron seq-jumborton">-->
  <!--<div class="container">
      <a href="/">
        <img src="/images/logo.png" >
      </a>
    <h3 class="tagline">
      
        Our view on big data
      
    </h3>
  </div>-->
  <!--  <div class="navbar-static-top" id="company_div">
        <a href="http://sequenceiq.com/">
            <h5 style="margin: 0; margin-right: 5px;padding-bottom: 2px;padding-top: 2px; padding-right: 50px; font-weight: bolder;color: #003140;font-size: 10px;" class="pull-right" >SEQUENCEIQ.COM</h5>
        </a>
    </div>-->
    <header class="navbar navbar-static-top bs-docs-nav" id="top" role="banner" >
        <div class="container">
            <div class="navbar-header">
                <button class="navbar-toggle" type="button" data-toggle="collapse" data-target=".bs-navbar-collapse">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="http://sequenceiq.com/" class="navbar-brand">
                    <img id="logo" src="http://sequenceiq.com/img/logo@2x.png" width="154" height="39" alt="SequenceIQ">
                </a>
            </div>
            <div class="collapse navbar-collapse" role="navigation" style="/* margin-right: 6.2em; */">
                <ul class="nav navbar-nav navbar-right" id="menu-tag">
                    <li><a href="http://blog.sequenceiq.com/">Blog</a></li>
                    <li><a href="http://blog.sequenceiq.com/archives/">Archives</a></li>
                </ul>

            </div>
        </div>
    </header>
  <div class="container social-jumbotron-container">
      <div class="row">
        
        <div class="col-md-1"><a class="social-link" href="http://github.com/sequenceiq" title="Github Profile"><i class="icon-github-sign social-navbar"></i></a></div>
        
        
        
        <div class="col-md-1"><a class="social-link" href="http://linkedin.com/company/sequenceiq" title="Linkedin Profile"><i class="icon-linkedin-sign social-navbar"></i></a></div>
        
        
        <div class="col-md-1"><a class="social-link" href="http://twitter.com/sequenceiq" title="Twitter Profile"><i class="icon-twitter-sign social-navbar"></i></a></div>
        
        
        
        <div class="col-md-1"><a class="social-link" href="http://facebook.com/sequenceiq" title="Facebook Profile"><i class="icon-facebook-sign social-navbar"></i></a></div>
        
        

        
     </div>
  </div>
<!--</div>-->


  <div id="silent-container">

  </div>
  <div class="container" style="width: 95%;">
      <div class="row" id="main">
              <div class="col-md-9" id="">
                  <div class="">
                   <!-- <div id="content">-->
                      <div class="blog-index">
  
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/28/datalake-cloudbreak/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">28 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/cloudbreak/"><span class="label label-warning">Cloudbreak</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/28/datalake-cloudbreak/">Building the data lake in the cloud - Part1</a>
          <span class="badge name-badge">Tamas Bihari</span>

      </h1>
      <p>A while ago we have released our cloud agnostic and Docker container based Hadoop as a Service API &ndash; <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a>. Though the purpose of <a href="https://cloudbreak.sequenceiq.com">Cloudbreak</a> is to quickly provision arbitrary sized Hadoop clusters in the cloud, the project emerged from bare metal Hadoop provisioning in Docker containers. We were (still doing it) <a href="http://blog.sequenceiq.com/blog/2014/06/19/multinode-hadoop-cluster-on-docker/">provisioning</a> Hadoop on bare metal using Docker &ndash; and because of this legacy the data was always stored in HDFS. Recently we have been asked to run a proof-of-concept project and build an <code>always on</code> data lake using a cloud <code>object storage</code>.</p>

<p>This post is the first in this series and will cover the connectivity, interoperability and access of data from an <code>object storage</code> and work with that in Hadoop. For this post we choose to create a <code>data lake</code> on Google Cloud Compute and guide you through the steps, run performance tests and understand the benefits/drawbacks of such a setup.</p>

<p><em>Next post will be about sharing the <code>data lake</code> among multiple clusters, using <a href="http://hortonworks.com/hadoop/hcatalog/">Apache HCatalog</a>.</em></p>

<h2>Object storage</h2>

<p>An object storage usually is an <code>internet service</code> to store data in the cloud and comes with a programming interface which allows to retrieve data in a secure, durable and highly-scalable way. The most well know object storage is <strong>Amazon S3</strong> &ndash; with a pretty well covered literature, thus in this example we will use the <strong>Google Cloud Storage</strong>. Google Cloud Storage enables application developers to store their data on Google’s infrastructure with very high reliability, performance and availability, and can be used to distribute large data objects &ndash; like HDFS. In many occasions companies stores their data in objects storages &ndash; but for analytics they would like to access it from their Hadoop cluster. There are several options available:</p>

<ul>
<li>replicate the full dataset in HDFS</li>
<li>read and write from <code>object storage</code> at start/stop of the flow and use HDFS for intermediary data</li>
<li>use a connector such as Google Cloud Storage Connector for Hadoop</li>
</ul>


<h2>Google Cloud Storage Connector for Hadoop</h2>

<p>Using <a href="https://cloud.google.com/hadoop/google-cloud-storage-connector">this</a> connector developed by Google allows you to choose <code>Google Cloud Storage</code> as the default file system for Hadoop, and run all your jobs on top (we will come up with MR2 and Spark examples). Using the connector can have several benefits, to name a few:</p>

<ul>
<li>Direct data access &ndash; data is stored in GCS, no need to transfer it into HDFS</li>
<li>HDFS compatibility &ndash; data stored in HDFS can be accessed through the connector</li>
<li>Data accessibility &ndash; data is always accessible, even when the Hadoop cluster is shut down</li>
<li>High data availability &ndash; data is highly available and globally replicated</li>
</ul>



      
       <a href="/blog/2014/10/28/datalake-cloudbreak/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/23/spark-operations-overview/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">23 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/spark/"><span class="label label-warning">Spark</span></a>
            
            <a href="/blog/categories/yarn/"><span class="label label-warning">YARN</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/23/spark-operations-overview/">Apache Spark RDD operation examples</a>
          <span class="badge name-badge">Oliver Szabo</span>

      </h1>
      <p>Recently we blogged about how you can write simple Apache Spark jobs and how to test them. Now we&rsquo;d like to introduce all basic RDD operations with easy examples (our goal is to come up with examples as simply as possible). The Spark <a href="http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations">documentation</a> explains well what each operations is doing in detail. We made tests for most of the RDD operations with good ol&#8217; <code>TestNG</code>. e.g.:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'> <span class="nd">@Test</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">testRightOuterJoin</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">input1</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">makeRDD</span><span class="o">(</span><span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="mi">4</span><span class="o">)))</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">input2</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">makeRDD</span><span class="o">(</span><span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="sc">&#39;1&#39;</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="sc">&#39;2&#39;</span><span class="o">)))</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">expectedOutput</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="o">(</span><span class="nc">Some</span><span class="o">(</span><span class="mi">4</span><span class="o">),</span> <span class="sc">&#39;1&#39;</span><span class="o">)),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="o">(</span><span class="nc">None</span><span class="o">,</span> <span class="sc">&#39;2&#39;</span><span class="o">)))</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">input1</span><span class="o">.</span><span class="n">rightOuterJoin</span><span class="o">(</span><span class="n">input2</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="nc">Assert</span><span class="o">.</span><span class="n">assertEquals</span><span class="o">(</span><span class="n">output</span><span class="o">.</span><span class="n">collect</span><span class="o">(),</span> <span class="n">expectedOutput</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>



      
       <a href="/blog/2014/10/23/spark-operations-overview/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/20/cascading-on-tez/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">20 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/apache-tez/"><span class="label label-warning">Apache Tez</span></a>
            
            <a href="/blog/categories/cascading/"><span class="label label-warning">Cascading</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/20/cascading-on-tez/">Cascading on Apache Tez</a>
          <span class="badge name-badge">Oliver Szabo</span>

      </h1>
      <p>In one of our previous <a href="http://blog.sequenceiq.com/blog/2014/09/23/topn-on-apache-tez/">posts</a> we showed how to do a TopK using directly the Apache Tez API. In this post we’d like to show how to do a similarly complex algorithm with Cascading &ndash; running on Apache Tez.
At <a href="http://sequenceiq.com">SequenceIQ</a> we use Scalding, Cascading and Spark to write most of our jobs. For a while our big data pipeline API called <a href="http://docs.banzai.apiary.io/">Banzai Pipeline</a> offers a unified API over different runtimes: MR2, Spark and Tez; recently Cascading has announced support for Apache Tez and we’d like to show you that by writing a detailed example.</p>

<h2>Cascading Application &ndash; GroupBy, Each, Every</h2>

<p>Cascading data flows are to be constructed from Source taps (input), Sink taps (output) and Pipes.
At first, we have to setup our properties for the Cascading flow.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>    <span class="n">Properties</span> <span class="n">properties</span> <span class="o">=</span> <span class="n">AppProps</span><span class="o">.</span><span class="na">appProps</span><span class="o">()</span>
</span><span class='line'>            <span class="o">.</span><span class="na">setJarClass</span><span class="o">(</span><span class="n">Main</span><span class="o">.</span><span class="na">class</span><span class="o">)</span>
</span><span class='line'>            <span class="o">.</span><span class="na">buildProperties</span><span class="o">();</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">properties</span> <span class="o">=</span> <span class="n">FlowRuntimeProps</span><span class="o">.</span><span class="na">flowRuntimeProps</span><span class="o">()</span>
</span><span class='line'>            <span class="o">.</span><span class="na">setGatherPartitions</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
</span><span class='line'>            <span class="o">.</span><span class="na">buildProperties</span><span class="o">(</span><span class="n">properties</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Then in order to use Apache Tez, setup the Tez specific <code>Flow Connector</code>.</p>


      
       <a href="/blog/2014/10/20/cascading-on-tez/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/17/boot2docker-tls-workaround/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">17 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/docker/"><span class="label label-warning">docker</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/17/boot2docker-tls-workaround/">Boot2docker TLS workaround</a>
          <span class="badge name-badge">Lajos Papp</span>

      </h1>
      <p>Docker 1.3.0 has been released with the invaluable <code>docker exec</code>
<a href="https://docs.docker.com/reference/commandline/cli/#exec">command</a>.</p>

<p>Boot2docker 1.3.0 delivered also some really neat features such
as <a href="https://github.com/boot2docker/boot2docker#virtualbox-guest-additions">Folder sharing</a>
with virtualbox guest additions. So finally OSX users are able to for example serve local html files in a container:
<code>docker run -v /Users/lalyos/webapp/:/usr/share/nginx/html:ro nginx</code></p>

<h2>Issue</h2>

<p>Boot2docker also changed Docker listening from <a href="http://0.0.0.0:2375">http://0.0.0.0:2375</a> to <a href="https://0.0.0.0:2376.">https://0.0.0.0:2376.</a>
While switching on TLS is highly recommended, but its not backward compatible.
Some tools or environments are relying to be able to connect to Docker
via simple http. So after upgrading to 1.3.0 something might be broken.</p>

<h2>Workaround</h2>

<p>Downgrading is for the weak ;)
One alternative solution is to start a container which uses <code>socat</code> to proxy the unix
socket file <code>/var/run/docker.sock</code> as a tcp port. It is containerized for you:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$(docker run sequenceiq/socat)</span></code></pre></td></tr></table></div></figure>


<p>Now you can reach Docker the <em>old</em> way:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl http://192.168.59.103:2375/_ping
</span><span class='line'>OK</span></code></pre></td></tr></table></div></figure>



      
       <a href="/blog/2014/10/17/boot2docker-tls-workaround/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/16/using-uaa-as-an-identity-server/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">16 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/cloudfoundry/"><span class="label label-warning">CloudFoundry</span></a>
            
            <a href="/blog/categories/cloudbreak/"><span class="label label-warning">Cloudbreak</span></a>
            
            <a href="/blog/categories/docker/"><span class="label label-warning">Docker</span></a>
            
            <a href="/blog/categories/oauth2/"><span class="label label-warning">OAuth2</span></a>
            
            <a href="/blog/categories/uaa/"><span class="label label-warning">UAA</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/16/using-uaa-as-an-identity-server/">Securing Cloudbreak with OAuth2</a>
          <span class="badge name-badge">Marton Sereg</span>

      </h1>
      <p>When we first released <a href="https://cloudbreak.sequenceiq.com/">Cloudbreak</a> &ndash; our Hadoop as a Service API &ndash; it contained its own authentication and user management layer.
We were using basic authentication for the API calls so every request had to contain a username and a password <em>Base64</em> encoded in the authorization header.
Cloudbreak also had its own user representation and we were binding the resources &ndash; like clusters &ndash; to these users.</p>

<p>This approach had multiple flaws. As we were starting to develop multiple <a href="http://sequenceiq.com/periscope/">projects</a> for our future Platform as a Service solution it became obvious that we will have to refactor our whole user management layer out from Cloudbreak and <strong>share it across our projects</strong>.
Base64 encoding of usernames and passwords is not the best solution either even if transport layer security is working.</p>

<p>What comes into play almost instantly when dealing with these kind of problems is <strong>OAuth2</strong> but it&rsquo;s not as trivial as it first sounds.</p>

<h2>OAuth2</h2>

<p>The main &ldquo;problem&rdquo; with OAuth2 is that its <a href="http://tools.ietf.org/html/rfc6749">specification</a> leaves a lot of decisions up to the implementations.
First of all it does not speak at all about authentication, only authorization. It also leaves out details such as how to manage users, how scopes and tokens look like or how these tokens should be checked by a resource server.</p>

<p>Because of all these reasons implementing a full OAuth2 solution from scratch means a <em>lot</em> of work and reinventing the wheel and of course we didn&rsquo;t want to do that.
Luckily there are a few specifications that complement the original standard and there are also some solutions that implement not only the basic specification but these complementary specifications too.</p>

<p><strong><a href="https://github.com/cloudfoundry/uaa">UAA</a> is CloudFoundry&rsquo;s fully open source identity management service.</strong>
According to the documentation its primary role is as an OAuth2 provider that can issue tokens for client applications, but it can also authenticate users and can manage user accounts and OAuth2 clients through an HTTP API.
To achieve these things it uses these specifications:</p>

<ul>
<li><p><a href="http://openid.net/connect/">OpenID Connect</a> for authentication</p></li>
<li><p><a href="http://www.simplecloud.info/">SCIM</a> for user management</p></li>
<li><p><a href="http://self-issued.info/docs/draft-ietf-oauth-json-web-token.html">JWT</a> for token representation</p></li>
</ul>


<p>UAA adds a few more things on top of these like client management endpoints which makes it a complete solution as an identity server.
And the best thing is that it is <strong>fully configurable through environment variables and a YAML file</strong>.</p>


      
       <a href="/blog/2014/10/16/using-uaa-as-an-identity-server/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/15/hadoop-metrics/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">15 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/baywatch/"><span class="label label-warning">Baywatch</span></a>
            
            <a href="/blog/categories/hadoop/"><span class="label label-warning">Hadoop</span></a>
            
            <a href="/blog/categories/periscope/"><span class="label label-warning">Periscope</span></a>
            
            <a href="/blog/categories/metrics/"><span class="label label-warning">metrics</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/15/hadoop-metrics/">Real-time adjustments with Hadoop metrics</a>
          <span class="badge name-badge">Krisztian Horvath</span>

      </h1>
      <p>To properly understand and to be fully aware of the state of our Hadoop clusters at any time we needed a scalable and flexible solution
to monitor our Hadoop nodes. After investigating the possible solutions we realized that there is no available solution which satisfies
all our needs thus we&rsquo;ve created one and recently just open sourced it, called <a href="http://sequenceiq.com/periscope/#monitoring">Baywatch</a>. Baywatch is capable to capture and visualize real-time changes on Hadoop clusters to understand and make adjustments based on the submitted jobs resource
allocation needs. To plan ahead, viewing and comparing old and new metrics is just as
important as analyzing real-time ones, not to mention that we can find possible weaknesses and defects in our clusters.</p>

<p>To be able to do all of the above mentioned, Baywatch processes the metrics information produced by the Hadoop daemons. This might already sound familiar as we have another project called <a href="http://sequenceiq.com/periscope/">Periscope</a> where you can create alarms and cluster scaling activities making use of the same metrics, but just consuming it in a different way. Combine these 2
components and you&rsquo;ll have a powerful tool and you&rsquo;ll be able to view your cluster&rsquo;s state and based on that <code>make smart decisions</code>
to scale up or down, or simply just set alarms. If you&rsquo;re thrilled to see it in action we are at <a href="http://strataconf.com/stratany2014">Strata</a> and happy to show you a quick demo.</p>

<h2>Hadoop metrics</h2>

<p>So what are these metrics? As I mentioned it earlier metrics are collections of information about Hadoop daemons, e.g:
the <code>ResourceManager</code> produces information about the queue statuses which we use in Periscope when we <code>re-prioritise applications</code>.
To distinguish these metrics they are grouped into named contexts, e.g <code>jvm</code> for java virtual machine metrics, <code>rpc</code> for debugging
rcp calls, but there are many more:</p>

<ul>
<li>yarn</li>
<li>rpcdetailed</li>
<li>metricssystem</li>
<li>mapred</li>
<li>dfs</li>
<li>ugi</li>
</ul>


<p>This <code>Metrics2</code> framework is designed to collect and dispatch per-process metrics to monitor the overall status of the Hadoop system.
In Hadoop related technologies it is a common design to use sources and sinks, just like in this case. Metrics sources are where the
metrics are generated and metrics sinks consume the records generated by the metrics sources. A metrics system would poll the metrics
sources periodically and pass the metrics records to metrics sinks.</p>

<p><img src="http://yuml.me/0faf3738"></p>


      
       <a href="/blog/2014/10/15/hadoop-metrics/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/09/ngrok-docker/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">09 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/docker/"><span class="label label-warning">docker</span></a>
            
            <a href="/blog/categories/ngrok/"><span class="label label-warning">ngrok</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/09/ngrok-docker/">Self hosted ngrok server in Docker</a>
          <span class="badge name-badge">Lajos Papp</span>

      </h1>
      <p><a href="vhttps://ngrok.com/">Ngrok</a> is used for <code>introspected</code> tunnels to localhost.
In integration testing situations is really common that you want to bind some webhooks
to localhost. For example you want AWS SNS deliver messages to your service,
but is not reachable publicly, as it runs only on localhost.</p>

<p>So its really 2 in 1: <strong>local tunnel</strong> and <strong>introspection</strong>. Sometimes you
just want to use its <strong>introspection</strong> feature, to get insight about how a
specific API works. It&rsquo;s like a local <a href="https://www.runscope.com/">runscope</a>.</p>

<p>While you can always use the free hosted version: <a href="https://ngrok.com/">ngrok</a>,
there are reasons to roll you own:</p>

<ul>
<li>Sometimes the free hosted version has <strong>availability</strong> issues,when it gets heavy traffic</li>
<li>Yo don&rsquo;t want your messages/calls go through a public free service, for
<strong>security</strong> concerns</li>
<li>You just want to use its <strong>introspection</strong> feature, and want to avoid the
extra <strong>network</strong> round trip to ngrok.com and back.</li>
</ul>


<p>There is documentation about <a href="https://github.com/inconshreveable/ngrok/blob/master/docs/SELFHOSTING.md">self hosting ngrok</a>
But it include steps, like:</p>

<ul>
<li>create an SSL certificate</li>
<li>build server/client binaries using the cert above</li>
<li>configure, and install it on your server</li>
</ul>


<p>How about using a <strong>single click</strong> version of this? Easy: we have already containerized
this process and made it available in the official Docker
<a href="https://registry.hub.docker.com/u/sequenceiq/ngrokd/">repository</a>.</p>


      
       <a href="/blog/2014/10/09/ngrok-docker/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/07/hadoop-monitoring/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">07 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/docker/"><span class="label label-warning">Docker</span></a>
            
            <a href="/blog/categories/elasticsearch/"><span class="label label-warning">Elasticsearch</span></a>
            
            <a href="/blog/categories/hadoop/"><span class="label label-warning">Hadoop</span></a>
            
            <a href="/blog/categories/kibana/"><span class="label label-warning">Kibana</span></a>
            
            <a href="/blog/categories/yarn/"><span class="label label-warning">Yarn</span></a>
            
            <a href="/blog/categories/metrics/"><span class="label label-warning">metrics</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/07/hadoop-monitoring/">Real-time monitoring of Hadoop clusters</a>
          <span class="badge name-badge">Attila Kanto</span>

      </h1>
      <p>At <a href="http://sequenceiq.com">SequenceIQ</a> we are running Hadoop clusters on different environments using <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a> and apply <a href="http://sequenceiq.com/periscope/">SLA autoscaling</a> policies on the fly, thus monitoring the cluster is a key operation.</p>

<p>Although various solutions have been created in the software industry for monitoring of activities taking place in a cluster, but it turned out that only a very few of them satisfies most of our needs. When we made the decision about which monitoring libraries and components to integrate in our stack we kept in mind that it needs to be:</p>

<ul>
<li><p><strong>scalable</strong> to be able to efficiently monitor small Hadoop clusters which are consisting of only a few nodes and also clusters which containing thousands of nodes</p></li>
<li><p><strong>flexible</strong> to be able to provide overview about the health of the whole cluster or about the health of individual nodes or even dive deeper into the internals of Hadoop, e.g. shall be able to visualize how our autoscaling solution for Hadoop YARN called  <a href="http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope">Periscope</a> moves running applications between <a href="http://blog.sequenceiq.com/blog/2014/07/02/move-applications-between-queues">queues</a></p></li>
<li><p><strong>extensible</strong> to be able to use the gathered and stored data by extensions written by 3rd parties, e.g. a module which processes the stored (metrics) data and does real-time anomaly detection</p></li>
<li><p><strong>zero-configuration</strong> to be able to plug into any existing Hadoop cluster without additional configuration, component installation</p></li>
</ul>


<p>Based on the requirements above our choice were the followings:</p>

<ul>
<li><a href="http://logstash.net">Logstash</a> for log/metrics enrichment, parsing and transformation</li>
<li><a href="http://www.elasticsearch.org">Elasticsearch</a> for data storage, indexing</li>
<li><a href="http://www.elasticsearch.org/overview/kibana">Kibana</a> for data visualization</li>
</ul>


<h2>High Level Architecture</h2>

<p>In our monitoring solution one of the design goal was to provide a <strong>generic, pluggable and isolated monitoring component</strong> to existing Hadoop deployments. We also wanted to make it non-invasive and avoid adding any monitoring related dependency to our Ambari, Hadoop or other Docker images. For that reason we have packaged the monitoring client component into its own Docker image which can be launched alongside with a Hadoop running in another container or even alongside a Hadoop which is not even containerized.</p>

<p style="text-align:center;"> <img src="https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/hadoop-monitoring/hadoop-monitoring-arch.png"></p>

<p>In a nutshell the monitoring solution consist of client and server containers. The <code>server</code> contains the Elasticsearch and the Kibana module. The server container is horizontally scalable and it can be clustered trough the clustering capabilities of Elasticsearch.</p>

<p>The <code>client</code> container &ndash; which is deployed on the machine what is needed to be monitored &ndash; contains the Logstash and the collectd module. The Logstash connects to Elasticsearch cluster as client and stores the processed and transformed metrics data there.</p>


      
       <a href="/blog/2014/10/07/hadoop-monitoring/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/09/30/hortonworks-partnership/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">30 September 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/hortonworks/"><span class="label label-warning">Hortonworks</span></a>
            
            <a href="/blog/categories/sequenceiq/"><span class="label label-warning">SequenceIQ</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/09/30/hortonworks-partnership/">SequenceIQ Joins Hortonworks Technology Partner Program</a>
          <span class="badge name-badge">Janos Matyas</span>

      </h1>
      <p>Integration of Hortonworks Data Platform with Cloudbreak enables Hadoop to run in Docker containers &ndash; shipped to the cloud.</p>

<p><strong>SAN FRANCISCO, September 30, 2014</strong> — <a href="http://sequenceiq.com/">SequenceIQ ,Inc.</a> today announced that it has joined the <a href="http://hortonworks.com/partners/become-a-partner/">Hortonworks® Technology Partner Program</a>. <a href="http://hortonworks.com/">Hortonworks</a> is the leading contributor to and provider of Apache™ Hadoop®. SequenceIQ will integrate <a href="http://hortonworks.com/hdp/">Hortonworks Data Platform</a> (HDP) with Cloudbreak to enable a cloud agnostic, autoscaling and <a href="https://www.docker.com/">Docker</a> container based provisioning of HDP.</p>

<p>By joining the Hortonworks Technology Partner program, SequenceIQ will work to enable and accelerate the deployment of a modern data architecture, integrating with the Hortonworks Data Platform—the industry’s only 100 percent open source Hadoop distribution, explicitly architected, built, and tested for enterprise-grade deployments.</p>

<p>SequenceIQ’s technology enables organizations to have a DevOps friendly way to ease and automate provisioning of on-demand Hadoop clusters and services using their favorite cloud provider. With the integration of HDP, users can now leverage all the available features of a 100 percent open source commercial Hadoop distribution.</p>

<p>“SequenceIQ and Hortonworks share a common goal of making the provisioning of Apache Hadoop clusters easier on different cloud and Docker container based environments,” said Janos Matyas, chief technology officer of SequenceIQ. “Cloudbreak and HDP help enterprises to minimize the cost of their Hadoop deployments, and create on-demand autoscaling Hadoop clusters.”</p>


      
       <a href="/blog/2014/09/30/hortonworks-partnership/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/09/29/spark-correlation-and-testing/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">29 September 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/correlation/"><span class="label label-warning">Correlation</span></a>
            
            <a href="/blog/categories/mllib/"><span class="label label-warning">MLlib</span></a>
            
            <a href="/blog/categories/spark/"><span class="label label-warning">Spark</span></a>
            
            <a href="/blog/categories/testing/"><span class="label label-warning">Testing</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/09/29/spark-correlation-and-testing/">Apache Spark - create and test jobs</a>
          <span class="badge name-badge">Oliver Szabo</span>

      </h1>
      <p>At <a href="http://sequenceiq.com/">SequenceIQ</a> we use different runtimes (MR2, Spark, Tez) when submitting jobs from <a href="http://docs.banzai.apiary.io/reference">Banzai</a> to a YARN clusters.
Some of these jobs are quite simple (filtering, sorting, projection etc.), but most of them can be complicated or not so oblivious at first (e.g.: complex machine learning algorithms).
From Banzai’s perspective/looking from outside a YARN cluster, what only matters is the input and the output dataset &ndash; as we have abstracted all the pipeline steps &ndash;  so testing of this steps properly is a must.
In this post we’d like to show such an example that &ndash; a correlation job on vectors with <a href="https://spark.apache.org/">Apache Spark</a> and how we test it.</p>

<h2>Correlation example (on vectors) with Apache Spark</h2>

<p>Suppose that we have an input dataset (CSV file for the sake of simplicity of the sample code) and we want to reveal the dependency between all of the columns. (all data is vectorized, if not you will have to vectorize your data first).
If we want to build a <code>testable</code> job, we have to focus only on the algorithm part. Our goal here is to work only on the Resilient Distributed Dataset and take the context creation outside of the job.
This way you cab run and create your <code>SparkContext</code>locally and substitute an HDFS data source (or something else) with simple objects.</p>

<p>Interface: (output: vector index pairs with their correlation coefficient)</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">abstract</span> <span class="k">class</span> <span class="nc">CorrelationJob</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">computeCorrelation</span><span class="o">(</span><span class="n">input</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="k">:</span> <span class="kt">Array</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">Int</span>, <span class="kt">Double</span><span class="o">)]</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">d2d</span><span class="o">(</span><span class="n">d</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span> <span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="k">new</span> <span class="n">java</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="nc">DecimalFormat</span><span class="o">(</span><span class="s">&quot;#.######&quot;</span><span class="o">).</span><span class="n">format</span><span class="o">(</span><span class="n">d</span><span class="o">).</span><span class="n">toDouble</span>
</span><span class='line'>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>





      
       <a href="/blog/2014/09/29/spark-correlation-and-testing/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
  
  <div class="pagination">
    
    <a class="prev" href="/blog/page/2/">&larr; Older</a>
    

    
  </div>
</div>


                    <!--</div>-->
                  </div>

              </div>
              <div class="col-md-3">
                 <section>
  <h2 class="blue">Recent Posts</h2>
  <ul id="recent_posts" class="list-group">
    
      <li class="list-group-item">
        <a href="/blog/2014/10/28/datalake-cloudbreak/">Building the data lake in the cloud - Part1</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/23/spark-operations-overview/">Apache Spark RDD operation examples</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/20/cascading-on-tez/">Cascading on Apache Tez</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/17/boot2docker-tls-workaround/">Boot2docker TLS workaround</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/16/using-uaa-as-an-identity-server/">Securing Cloudbreak with OAuth2</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/15/hadoop-metrics/">Real-time adjustments with Hadoop metrics</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/09/ngrok-docker/">Self hosted ngrok server in Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/07/hadoop-monitoring/">Real-time monitoring of Hadoop clusters</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/30/hortonworks-partnership/">SequenceIQ Joins Hortonworks Technology Partner Program</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/29/spark-correlation-and-testing/">Apache Spark - create and test jobs</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/26/database-upgrade-process/">Managing database upgrades with Liquibase and Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/25/strata-hadoop-world-2014/">Strata + Hadoop World 2014 Startup Showcase</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/25/euroventures-invests-in-sequenceiq/">Euroventures invests in SequenceIQ</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/24/edit-files-docker/">Edit files in Docker containers</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/23/topn-on-apache-tez/">TopK on Apache Tez</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/19/apache-tez-cluster/">Apache Tez cluster on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/18/custom-image-on-gcc/">Cloudbreak new provider implementation - Part I: Build your custom image</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/17/spark-1-1-0-docker/">Apache Spark 1.1.0 on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/15/hadoop-2-5-1-docker/">Apache Hadoop 2.5.1 on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/11/apache-drill-docker/">Apache Drill on Docker - query as a service </a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/09/yarn-schedulers-demystified-part-2-fair/">YARN Schedulers demystified - Part 2: Fair</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/05/apache-ambari-1-7-0-ea/">Apache Ambari 1.7.0 early access</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/04/sql-on-hbase-with-apache-phoenix/">SQL on HBase with Apache Phoenix</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/01/sla-samples-periscope/">SLA policies for autoscaling Hadoop clusters</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/29/aws-cloudformation-makes-everything-easier/">Infrastructure management with CloudFormation</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/27/announcing-periscope/">Periscope - autoscaling for Hadoop YARN</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/22/spark-submit-in-java/">Submit a Spark job to YARN from code</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/18/hadoop-2-5-0-docker/">Apache Hadoop 2.5.0 on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/16/fairplay/">Fair play</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/12/docker-networking/">Docker intercontainer networking explained</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/07/clodubreak-shell/">Create Hadoop clusters in the cloud using a CLI</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/04/launch-docker-containers-on-azure/">Launch Docker containers on Azure</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/31/spark-mllib/">Apache Spark - MLlib Introduction</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/25/cloudbreak-technology/">Docker ships Hadoop to the cloud</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/22/schedulers-part-1/">YARN Schedulers demystified - Part 1: Capacity</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/18/announcing-cloudbreak/">Cloudbreak - the Hadoop as a Service API</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/13/groovy-and-java-runtime-bug/">Groovy and Java, the runtime bug</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/09/ambari-configuration-service/">Apache Ambari configuration service</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/05/docker-debug-with-nsenter-on-boot2docker/">Docker debug with nsenter on boot2docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/02/move-applications-between-queues/">Re-prioritize running jobs with YARN schedulers</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/06/25/hadoop-2-4-0-docker/">Apache Hadoop 2.4.1 on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/06/23/scalding-correlation-example/">Pearson correlation with Scalding</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/06/19/multinode-hadoop-cluster-on-docker/">Multi-node Hadoop cluster on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/06/17/ambari-cluster-on-docker/">Ambari provisioned Hadoop cluster on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/06/06/hadoop-summit-slides/">Hadoop Summit 2014 - SequenceIQ slides</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/05/26/ambari-shell/">Apache Ambari + Spring Shell = Ambari Shell</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/05/09/building-the-build-environment-with-ansible-and-docker/">Building the build environment with Ansible and Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/05/01/mapreduce-job-profiling-with-R/">Job profiling with R</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/04/17/apache-phoenix-sneak-peak/">Apache Phoenix (sneak peak)</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/04/14/mapreduce-with-scalding/">Writing MapReduce jobs in Scala</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/04/04/hadoop-docker-introduction/">Hadoop on Docker introduction</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/31/mahout-on-tez/">Using Mahout with Tez</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/24/hoya-at-sequenceiq/">Using Hortonworks Hoya at SequenceIQ</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/19/hadoop-2-dot-3-with-docker/">Hadoop 2.3 with docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/14/yarn-capacity-scheduler/">YARN Capacity Scheduler</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/11/data-cleaning-with-mapreduce-and-morphlines/">Data cleaning with MapReduce and Morphlines</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/07/read-from-hdfs/">HDFS and java.nio.channels</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/05/access-hdp2-sandbox/">Accessing HDP2 sandbox from the host</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/02/28/etl-and-data-quality/">ETL - producing better quality data</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/02/26/vote-for-us/">Vote for us - 2014 Hadoop Summit San Jose</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/02/22/custom-flume-source/">Custom Apache Flume source</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/02/07/hdp2-on-amazon/">Set up HDP2 on Amazon EC2</a>
      </li>
    
  </ul>
</section>

              </div>
      </div>
  </div>
  <div class="row-fluid" id="footer-container">
    <div class="container">
        <footer class="footer-page" role="contentinfo">
            <div class="row">
                <div class="col-md-6">
                    <div class="row">
    
    <div class="col-md-1"><a class="social-link" href="http://github.com/sequenceiq" title="Github Profile"><i class="fa fa-github fa-lg"></i></a></div>
    
    
    
    <div class="col-md-1"><a class="social-link" href="http://linkedin.com/company/sequenceiq" title="Linkedin Profile"><i class="fa fa-linkedin fa-lg"></i></a></div>
    
    
    <div class="col-md-1"><a class="social-link" href="http://twitter.com/sequenceiq" title="Twitter Profile"><i class="fa fa-twitter fa-lg"></i></a></div>
    
    
    
    <div class="col-md-1"><a class="social-link" href="http://facebook.com/sequenceiq" title="Facebook Profile"><i class="fa fa-facebook fa-lg"></i></a></div>
    
    

    
    <div class="col-md-1"><a class="social-link" href="http://blog.sequenceiq.com/atom.xml" title="RSS"><i class="fa fa-rss fa-lg"></i></a></div>

</div>

                </div>
                <div class="col-md-5">
                    


<p class="pull-right" >
  <span class="credit">&copy; SequenceIQ Inc. 2014. All rights reserved. </span>
    <br><a href="pp.html" style="color: #508190;">Privacy Policy</a> &nbsp; <a href="tos.html" style="color: #508190;">Terms of Service</a></p>
</p>


                </div>
            </div>
        </footer>
    </div>

  </div>
  

<script type="text/javascript">
      var disqus_shortname = 'sequenceiqblog';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=625149054184531";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>




  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-48528840-1', 'sequenceiq.com');
  ga('send', 'pageview');

</script>
</html>
