
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>SequenceIQ Blog</title>
  <meta name="author" content="SequenceIQ">

   
  <meta name="description" content="">
  
  <meta name="keywords" content="">

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://blog.sequenceiq.com">
  <link href="/favicon.png" rel="icon">
  <link href='http://fonts.googleapis.com/css?family=Quicksand:300,400' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,300' rel='stylesheet' type='text/css'>
    <link href="/stylesheets/sequenceiq.css" media="screen, projection" rel="stylesheet" type="text/css">
   <!-- <link href="/stylesheets/syntax.css" media="screen, projection" rel="stylesheet" type="text/css">-->
    <link href="/stylesheets/bootstrap.css" rel='stylesheet' type='text/css'>
  <link href="/stylesheets/bootstrap-theme.css"rel='stylesheet' type='text/css'>
 <!-- <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">-->

  <link href="/blog/atom.xml" rel="alternate" title="SequenceIQ Blog" type="application/atom+xml">
  <script src="/js/jquery.js"></script>
  <script src="/js/bootstrap-collapse.js"></script>
  <script src="/js/modernizr-2.0.js"></script>
  <script src="/js/octopress.js" type="text/javascript"></script>
  <script src="/js/application.js"></script>
  <script src="/js/bootstrap.js"></script>
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >

  <!--<div class="jumbotron seq-jumborton">-->
  <!--<div class="container">
      <a href="/">
        <img src="/images/logo.png" >
      </a>
    <h3 class="tagline">
      
        Our view on big data
      
    </h3>
  </div>-->
  <!--  <div class="navbar-static-top" id="company_div">
        <a href="http://sequenceiq.com/">
            <h5 style="margin: 0; margin-right: 5px;padding-bottom: 2px;padding-top: 2px; padding-right: 50px; font-weight: bolder;color: #003140;font-size: 10px;" class="pull-right" >SEQUENCEIQ.COM</h5>
        </a>
    </div>-->
    <header class="navbar navbar-static-top bs-docs-nav" id="top" role="banner" >
        <div class="container">
            <div class="navbar-header">
                <button class="navbar-toggle" type="button" data-toggle="collapse" data-target=".bs-navbar-collapse">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="http://sequenceiq.com/" class="navbar-brand">
                    <img id="logo" src="http://sequenceiq.com/img/logo@2x.png" width="154" height="39" alt="SequenceIQ">
                </a>
            </div>
            <div class="collapse navbar-collapse" role="navigation" style="/* margin-right: 6.2em; */">
                <ul class="nav navbar-nav navbar-right" id="menu-tag">
                    <li><a href="http://blog.sequenceiq.com/">Blog</a></li>
                    <li><a href="http://blog.sequenceiq.com/archives/">Archives</a></li>
                </ul>

            </div>
        </div>
    </header>
  <div class="container social-jumbotron-container">
      <div class="row">
        
        <div class="col-md-1"><a class="social-link" href="http://github.com/sequenceiq" title="Github Profile"><i class="icon-github-sign social-navbar"></i></a></div>
        
        
        
        <div class="col-md-1"><a class="social-link" href="http://linkedin.com/company/sequenceiq" title="Linkedin Profile"><i class="icon-linkedin-sign social-navbar"></i></a></div>
        
        
        <div class="col-md-1"><a class="social-link" href="http://twitter.com/sequenceiq" title="Twitter Profile"><i class="icon-twitter-sign social-navbar"></i></a></div>
        
        
        
        <div class="col-md-1"><a class="social-link" href="http://facebook.com/sequenceiq" title="Facebook Profile"><i class="icon-facebook-sign social-navbar"></i></a></div>
        
        

        
     </div>
  </div>
<!--</div>-->


  <div id="silent-container">

  </div>
  <div class="container" style="width: 95%;">
      <div class="row" id="main">
              <div class="col-md-9" id="">
                  <div class="">
                   <!-- <div id="content">-->
                      <div class="blog-index">
  
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/11/17/datalake-cloudbreak-2/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">17 November 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/cloudbreak/"><span class="label label-warning">Cloudbreak</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/11/17/datalake-cloudbreak-2/">Building the data lake in the cloud - Part2</a>
          <span class="badge name-badge">Marton Sereg</span>

      </h1>
      <p>Few weeks ago we had a <a href="http://blog.sequenceiq.com/blog/2014/10/28/datalake-cloudbreak/">post</a> about building a <code>data lake</code> in the cloud using a cloud based <code>object storage</code> as the primary file system.
In this post we&rsquo;d like to move forward and show you how to create an <code>always on</code> persistent datalake with <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a> and create <code>ephemeral</code> clusters which can be scaled up and down based on configured SLA policies using <a href="http://sequenceiq.com/periscope/">Periscope</a>.</p>

<p>Just as a quick reminder &ndash; both are open source projects under Apache2 license and the documentation and code is available following these links below.</p>

<table>
<thead>
<tr>
<th></th>
<th> Name                  </th>
<th> Description </th>
<th> Documentation </th>
<th> GitHub</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td> Cloudbreak         </td>
<td> Cloud agnostic Hadoop as a Service </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/">http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/</a> </td>
<td> <a href="https://github.com/sequenceiq/cloudbreak">https://github.com/sequenceiq/cloudbreak</a></td>
</tr>
<tr>
<td></td>
<td> Periscope          </td>
<td> SLA policy based autoscaling for Hadoop clusters </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/">http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/</a> </td>
<td> <a href="https://github.com/sequenceiq/periscope">https://github.com/sequenceiq/periscope</a></td>
</tr>
</tbody>
</table>


<h2>Sample architecture</h2>

<p>For the sample use case we will create a <code>datalake</code> on <strong>AWS</strong> and <strong>Google Cloud</strong> as well &ndash; and use the most popular data warehouse software with an SQL interface &ndash; <a href="https://hive.apache.org/">Apache Hive</a>.</p>


      
       <a href="/blog/2014/11/17/datalake-cloudbreak-2/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/11/13/kylin-on-docker/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">13 November 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/olap/"><span class="label label-warning">OLAP</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/11/13/kylin-on-docker/">Extreme OLAP Engine running in Docker</a>
          <span class="badge name-badge">Krisztian Horvath</span>

      </h1>
      <p><em><a href="https://github.com/KylinOLAP/Kylin">Kylin</a> is an open source Distributed Analytics Engine from eBay Inc. that provides SQL interface and multi-dimensional analysis (OLAP) on Hadoop supporting extremely large datasets.</em></p>

<p>At <a href="http://sequenceiq.com/">SequenceIQ</a> we are always interested in the latest emerging technologies, and try to offer those to our customers and the open source community. A few weeks ago <a href="http://www.ebayinc.com/">eBay Inc.</a> released <a href="https://github.com/KylinOLAP/Kylin">Kylin</a> as an open source product and made available for the community under an Apache 2 license. Since we share the approach towards <code>open source</code> software we have partnered with them to <code>Dockerize</code> Kylin &ndash; and made it extremely easy for people to deploy a Kylin locally or in the cloud, using our Hadoop as a Service API &ndash; <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a>.</p>

<p>While there is a pretty good <a href="http://www.kylin.io/document.html">documentation</a> available for Kylin we&rsquo;d like to give you a really short introduction and overview.</p>


      
       <a href="/blog/2014/11/13/kylin-on-docker/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/11/10/new-yarn-features-part-1-label-based-scheduling/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">10 November 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/yarn/"><span class="label label-warning">YARN</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/11/10/new-yarn-features-part-1-label-based-scheduling/">New YARN features: Label based scheduling</a>
          <span class="badge name-badge">Krisztian Horvath</span>

      </h1>
      <p>The release of Hadoop 2.6.0 is upon us thus it&rsquo;s time to highlight a few upcoming features, especially those which we are building/planning to use in our Hadoop as a Service API &ndash; <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a> and our SLA policy based autoscaling API &ndash; <a href="http://sequenceiq.com/periscope/">Periscope</a>.</p>

<p>Recently we explained how the
<a href="http://blog.sequenceiq.com/blog/2014/07/22/schedulers-part-1/">CapacityScheduler</a> and the <a href="http://blog.sequenceiq.com/blog/2014/09/09/yarn-schedulers-demystified-part-2-fair/">FairScheduler</a>
works and the upcoming release is about to add a few really interesting functionality to them which you should be aware as they might
change the way we think about resource scheduling. The first one which we are going to discuss is the <code>label based scheduling</code> although it&rsquo;s
not fully finished, yet. You can track its progress here: <a href="https://issues.apache.org/jira/browse/YARN-796">YARN-796</a>.</p>

<h2>Motivation</h2>

<p>Hadoop clusters are usually not fully homogeneous which means that different nodes can have different parameters. For example some nodes
have more memory than the others while others have better cpu&rsquo;s or better network bandwidth. At the moment YARN doesn&rsquo;t have the
ability to segregate nodes in a cluster based on their architectural parameters. Applications which are aware of their resource usages
cannot choose which nodes they want to run their containers on. Labels are about to solve this problem. Administrators will have
the ability to <code>mark</code> the nodes with different labels like: cpu, memory, network, rackA, rackB so applications can specify where they&rsquo;d
like to run.</p>

<h2>Cloud</h2>

<p>Things are different in cloud environments as the composition of the Hadoop clusters are more homogeneous. By the nature of cloud it&rsquo;s
easier and more convenient to request nodes with the exact same capabilities. <a href="http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/">Cloudbreak</a>
our Hadoop as a service API will address this problem, by giving the ability to the users to specify their needs. Take one example: on AWS
users can launch <code>spot price</code> instances which EC2 can <code>take away any time</code>. Labeling them as <code>spot</code> we can avoid spinning up the
<code>ApplicationMasters</code> on those nodes, thus operate safely and re-launch new containers on different nodes in case it happens.
Furthermore <a href="http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/">Periscope</a> with its autoscaling capabilities will be able
to scale out with nodes that are marked with <code>cpu</code>.</p>


      
       <a href="/blog/2014/11/10/new-yarn-features-part-1-label-based-scheduling/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/11/06/securing-cloudbreak-with-oauth2-part-2/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">06 November 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/oauth2/"><span class="label label-warning">OAuth2</span></a>
            
            <a href="/blog/categories/uaa/"><span class="label label-warning">UAA</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/11/06/securing-cloudbreak-with-oauth2-part-2/">Securing Cloudbreak with OAuth2 - part 2</a>
          <span class="badge name-badge">Marton Sereg</span>

      </h1>
      <p>A few weeks ago we&rsquo;ve published a <a href="http://blog.sequenceiq.com/blog/2014/10/16/using-uaa-as-an-identity-server/">blog post</a> about securing our <a href="https://cloudbreak.sequenceiq.com/">Cloudbreak</a> infrastructure with OAuth2.
We&rsquo;ve discussed how we were setting up and configuring a new UAA OAuth2 identity server with Docker but we haven&rsquo;t detailed how to use this identity server in client applications.
And that&rsquo;s exactly what we&rsquo;ll do now: we&rsquo;ll show some code examples about how to obtain tokens from different clients and how to check these tokens in resource servers.</p>

<p>We&rsquo;re using almost every type of the OAuth2 flows in our infrastructure: Cloudbreak and <a href="http://sequenceiq.com/periscope/">Periscope</a> act as resource servers while <a href="https://github.com/sequenceiq/uluwatu">Uluwatu</a> and <a href="https://github.com/sequenceiq/cloudbreak-shell">Cloudbreak shell</a> for example are clients for these APIs.</p>

<h2>Obtaining an access token</h2>

<p>The main goal of an OAuth2 flow is to obtain an access token for the resource owner that can be used to access a resource server later.
There are multiple common flows depending on the client type, we&rsquo;ll have examples for three of them now: <em>implicit</em>, <em>authorization code</em> and <em>client credentials</em>.
If you&rsquo;re not familiar with the roles and expressions that take part in the OAuth2 flows I suggest to check out some <a href="http://aaronparecki.com/articles/2012/07/29/1/oauth2-simplified">&ldquo;Getting started&rdquo; resources</a> first before going forward with this post.</p>

<h3>Implicit flow</h3>

<p>This is not the most common flow with OAuth2 but it is the most simple one because only one request should be made to the identity server and the token will arrive directly in the response.
Two different types of this flow is supported by UAA. One for browser-based applications and one for those scenarios when there is no browser interaction (e.g.: CLIs).
The common part of these scenarios is that it would be useless to have a client secret because it couldn&rsquo;t be kept as a secret.</p>

<p>We are using the <em>implicit flow with credentials</em> in the <a href="https://github.com/sequenceiq/cloudbreak-shell">Cloudbreak Shell</a>.
When using the shell you must provide your SequenceIQ credentials as environment variables and the shell uses those to obtain an access token.
Cloudbreak shell is written in Java but let&rsquo;s see a basic <code>curl</code> example instead &ndash; it does exactly the same as the Java code. (If you&rsquo;re still eager you can check out the code <a href="https://github.com/sequenceiq/cloudbreak-shell/blob/master/src/main/java/com/sequenceiq/cloudbreak/shell/configuration/ShellConfiguration.java#L122">here</a>)</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -iX POST -H "accept: application/x-www-form-urlencoded"  \
</span><span class='line'> -d 'credentials={"username":"admin","password":"periscope"}' \
</span><span class='line'> "http://localhost:8080/oauth/authorize?response_type=token&client_id=cli&scope.0=openid&redirect_uri=http://cli"</span></code></pre></td></tr></table></div></figure>





      
       <a href="/blog/2014/11/06/securing-cloudbreak-with-oauth2-part-2/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/11/04/yarn-timeline-service-tez/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">04 November 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/timeline-service/"><span class="label label-warning">Timeline service</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/11/04/yarn-timeline-service-tez/">YARN Timeline Service</a>
          <span class="badge name-badge">Laszlo Puskas</span>

      </h1>
      <p>As you may know from our earlier <a href="http://blog.sequenceiq.com/blog/2014/10/07/hadoop-monitoring/">blogposts</a> we are continuously monitoring and trying to find out what happens inside our YARN clusters, let it be MapReduce jobs, TEZ DAGs, etc&hellip; We&rsquo;ve analyzed our clusters from various aspects so far; now it&rsquo;s the time to take a look at the information provided by the built YARN <code>timeline</code> service.</p>

<p>This post is about how to set up a YARN cluster so that the Timeline Server is available and how to configure applications running in the cluster to report information to it. As an example we&rsquo;ve chosen to run a simple TEZ example. (MapReduce2 also reports to the <code>timeline</code> service)</p>

<p>As a playground we will use a multinode cluster set up on the local machine; alternatively one could do the same on a cluster provisioned with <a href="http://sequenceiq.com/cloudbreak">Cloudbreak</a>. Cluster nodes run in Docker containers, YARN / TEZ provisioning and configuration is done with <a href="http://ambari.apache.org/">Apache Ambari</a>.</p>

<h2>Building a multinode cluster</h2>

<p>To build a multinode cluster we use a set of commodity functions that you can install by running the following in a terminal:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -Lo .amb j.mp/docker-ambari && . .amb</span></code></pre></td></tr></table></div></figure>


<p>(The commodity functions use our docker-ambari image: sequenceiq/ambari:1.6.0)</p>


      
       <a href="/blog/2014/11/04/yarn-timeline-service-tez/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/11/02/spark-on-tez/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">02 November 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/apache-spark/"><span class="label label-warning">Apache Spark</span></a>
            
            <a href="/blog/categories/apache-tez/"><span class="label label-warning">Apache Tez</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/11/02/spark-on-tez/">Spark on Tez execution context - running in Docker</a>
          <span class="badge name-badge">Janos Matyas</span>

      </h1>
      <p>Last week Hortonworks <a href="http://hortonworks.com/blog/improving-spark-data-pipelines-native-yarn-integration/">announced</a> improvements for running Apache Spark at scale by introducing a new pluggable <code>execution context</code> and has <a href="https://github.com/hortonworks/spark-native-yarn-samples">open sourced</a> it.</p>

<p>At <a href="http://sequenceiq.com/">SequenceIQ</a> we are always trying to work and offer the latest technology solutions for our clients and help them to choose their favorite technology/option. We are running a project called <a href="http://docs.banzai.apiary.io/">Banzai Pipeline</a> &ndash; to be open sourced soon &ndash; with the goal (among many others) to abstract and allow our customers to use their favorite big data runtime: MR2, Spark or Tez. Along this process we have <code>dockerized</code> most of the Hadoop ecosystem &ndash; we are running MR2, Spark, Storm, Hive, HBase, Pig, Oozie, Drill etc in Docker containers &ndash; on bare metal and in the cloud as well (all of these containers have made <strong>top</strong> downloads on the official Docker repository). For details you can check these older posts/resources:</p>

<table>
<thead>
<tr>
<th></th>
<th> Name                  </th>
<th> Description </th>
<th> Documentation </th>
<th> GitHub</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td> Apache Hadoop  </td>
<td> Pseudo distributed container </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/08/18/hadoop-2-5-0-docker/">http://blog.sequenceiq.com/blog/2014/08/18/hadoop-2-5-0-docker/</a> </td>
<td> <a href="https://github.com/sequenceiq/hadoop-docker">https://github.com/sequenceiq/hadoop-docker</a></td>
</tr>
<tr>
<td></td>
<td> Apache Ambari   </td>
<td> Multi node &ndash; full Hadoop stack, blueprint based </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/06/19/multinode-hadoop-cluster-on-docker/">http://blog.sequenceiq.com/blog/2014/06/19/multinode-hadoop-cluster-on-docker/</a> </td>
<td> <a href="https://github.com/sequenceiq/docker-ambari">https://github.com/sequenceiq/docker-ambari</a></td>
</tr>
<tr>
<td></td>
<td> Cloudbreak         </td>
<td> Cloud agnostic Hadoop as a Service </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/">http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/</a> </td>
<td> <a href="https://github.com/sequenceiq/cloudbreak">https://github.com/sequenceiq/cloudbreak</a></td>
</tr>
<tr>
<td></td>
<td> Periscope          </td>
<td> SLA policy based autoscaling for Hadoop clusters </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/">http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/</a> </td>
<td> <a href="https://github.com/sequenceiq/periscope">https://github.com/sequenceiq/periscope</a></td>
</tr>
</tbody>
</table>


<p>We have always been big fans on Apache Spark &ndash; due to the simplicity of development and at the same time we are big fans of Apache Tez, for reasons we have <a href="http://blog.sequenceiq.com/blog/2014/09/23/topn-on-apache-tez/">blogged before</a>.</p>

<p>When the <a href="https://issues.apache.org/jira/browse/SPARK-3561">SPARK-3561</a> has been submitted we were eager to get our hands on the WIP and early implementation &ndash; and this time we&rsquo;d like to help you with a quick ramp-up and easy solution to have a Spark Docker <a href="https://github.com/sequenceiq/docker-spark-native-yarn">container</a> where the <code>execution context</code> has been changed to <a href="http://tez.apache.org/">Apache Tez</a> and everything is preconfigured. The only thing you will need to do is to follow these easy steps.</p>

<h3>Pull the image from the Docker Repository</h3>

<p>We suggest to always pull the container from the official Docker repository &ndash; as this is always maintained and supported by us.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker pull sequenceiq/spark-native-yarn</span></code></pre></td></tr></table></div></figure>


<p>Once you have pulled the container you are ready to run the image.</p>

<h3>Run the image</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker run -i -t -h sandbox sequenceiq/spark-native-yarn /etc/bootstrap.sh -bash</span></code></pre></td></tr></table></div></figure>



      
       <a href="/blog/2014/11/02/spark-on-tez/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/30/cloudbreak-devops/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">30 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/cli/shell/"><span class="label label-warning">CLI/Shell</span></a>
            
            <a href="/blog/categories/cloudbreak/"><span class="label label-warning">Cloudbreak</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/30/cloudbreak-devops/">Deploying a Hadoop Cluster - DevOps way</a>
          <span class="badge name-badge">Marton Sereg</span>

      </h1>
      <p>A while ago we have announced <a href="http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/">Cloudbreak</a> &ndash; the open source Hadoop as a Service API. Included in the release we open sourced a REST API, REST client, UI and a CLI/shell. In this post we’d like to show you how easy is to use <a href="https://github.com/sequenceiq/cloudbreak-shell">Cloudbreak shell</a> in order to create on demand Hadoop clusters on your favorite cloud provider &ndash; record the process and automate it.</p>

<p>While it’s up to everybody&rsquo;s personal preference whether to use a UI, a command line interface or the REST API directly, at SequenceIQ we prefer to use command line tools whenever it’s possible because it’s much faster than interacting with a web UI and it’s a better candidate for automation. Are we <code>obsessed with automation</code>? Definitely yes &ndash; all the step which are candidates of doing it twice we script or automate it.</p>

<p>This <code>thing</code> with the automation does not affect the effort and quality standards we put on building the UI &ndash; <a href="https://cloudbreak.sequenceiq.com/">Cloudbreak</a> has an extremely intuitive and clean <strong>responsive</strong> UI and it’s built on the latest and greatest web UI framework &ndash; <a href="https://angularjs.org/">Angular JS</a>. We will have a post about the UI, however we consider it so simple to use that we ask you to go ahead and give it a try. You are a signup and a few clicks away from your Hadoop cluster.</p>

<p>Now back to the CLI. Remember one of our Apache contribution &ndash; the <a href="http://blog.sequenceiq.com/blog/2014/05/26/ambari-shell/">Ambari shell and REST API</a>? Well, the Cloudbreak shell is built on the same technology &ndash; Spring Shell. It’s an interactive shell that can be easily extended using a Spring based programming model and battle tested in various projects like Spring Roo, Spring XD, and Spring REST Shell Combine these two projects to create a powerful tool.</p>

<h2>Cloudbreak Shell</h2>

<p>The goal with the CLI was to provide an interactive command line tool which supports:</p>

<ul>
<li>all functionality available through the REST API or Cloudbreak web UI</li>
<li>makes possible complete automation of management task via <strong>scripts</strong></li>
<li>context aware command availability</li>
<li>tab completion</li>
<li>required/optional parameter support</li>
<li><strong>hint</strong> command to guide you on the usual path</li>
</ul>


<h2>Install Cloudbreak Shell</h2>

<p>You have 3 options to give it a try:</p>

<ul>
<li>use our prepared <a href="https://registry.hub.docker.com/u/sequenceiq/cloudbreak/">docker image</a></li>
<li>download the latest self-containing executable jar form our maven repo</li>
<li>build it from source</li>
</ul>


<h3>Build from source</h3>

<p>If want to use the code or extend it with new commands follow the steps below. You will need:
&ndash; jdk 1.7
&ndash; maven 3.x.x</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/sequenceiq/cloudbreak-shell.git
</span><span class='line'>cd cloudbreak-shell
</span><span class='line'>mvn clean package</span></code></pre></td></tr></table></div></figure>





      
       <a href="/blog/2014/10/30/cloudbreak-devops/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/28/datalake-cloudbreak/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">28 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/cloudbreak/"><span class="label label-warning">Cloudbreak</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/28/datalake-cloudbreak/">Building the data lake in the cloud - Part1</a>
          <span class="badge name-badge">Tamas Bihari</span>

      </h1>
      <p>A while ago we have released our cloud agnostic and Docker container based Hadoop as a Service API &ndash; <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a>. Though the purpose of <a href="https://cloudbreak.sequenceiq.com">Cloudbreak</a> is to quickly provision arbitrary sized Hadoop clusters in the cloud, the project emerged from bare metal Hadoop provisioning in Docker containers. We were (still doing it) <a href="http://blog.sequenceiq.com/blog/2014/06/19/multinode-hadoop-cluster-on-docker/">provisioning</a> Hadoop on bare metal using Docker &ndash; and because of this legacy the data was always stored in HDFS. Recently we have been asked to run a proof-of-concept project and build an <code>always on</code> data lake using a cloud <code>object storage</code>.</p>

<p>This post is the first in this series and will cover the connectivity, interoperability and access of data from an <code>object storage</code> and work with that in Hadoop. For this post we choose to create a <code>data lake</code> on Google Cloud Compute and guide you through the steps, run performance tests and understand the benefits/drawbacks of such a setup.</p>

<p><em>Next post will be about sharing the <code>data lake</code> among multiple clusters, using <a href="http://hortonworks.com/hadoop/hcatalog/">Apache HCatalog</a>.</em></p>

<h2>Object storage</h2>

<p>An object storage usually is an <code>internet service</code> to store data in the cloud and comes with a programming interface which allows to retrieve data in a secure, durable and highly-scalable way. The most well know object storage is <strong>Amazon S3</strong> &ndash; with a pretty well covered literature, thus in this example we will use the <strong>Google Cloud Storage</strong>. Google Cloud Storage enables application developers to store their data on Google’s infrastructure with very high reliability, performance and availability, and can be used to distribute large data objects &ndash; like HDFS. In many occasions companies stores their data in objects storages &ndash; but for analytics they would like to access it from their Hadoop cluster. There are several options available:</p>

<ul>
<li>replicate the full dataset in HDFS</li>
<li>read and write from <code>object storage</code> at start/stop of the flow and use HDFS for intermediary data</li>
<li>use a connector such as Google Cloud Storage Connector for Hadoop</li>
</ul>


<h2>Google Cloud Storage Connector for Hadoop</h2>

<p>Using <a href="https://cloud.google.com/hadoop/google-cloud-storage-connector">this</a> connector developed by Google allows you to choose <code>Google Cloud Storage</code> as the default file system for Hadoop, and run all your jobs on top (we will come up with MR2 and Spark examples). Using the connector can have several benefits, to name a few:</p>

<ul>
<li>Direct data access &ndash; data is stored in GCS, no need to transfer it into HDFS</li>
<li>HDFS compatibility &ndash; data stored in HDFS can be accessed through the connector</li>
<li>Data accessibility &ndash; data is always accessible, even when the Hadoop cluster is shut down</li>
<li>High data availability &ndash; data is highly available and globally replicated</li>
</ul>



      
       <a href="/blog/2014/10/28/datalake-cloudbreak/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/23/spark-operations-overview/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">23 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/spark/"><span class="label label-warning">Spark</span></a>
            
            <a href="/blog/categories/yarn/"><span class="label label-warning">YARN</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/23/spark-operations-overview/">Apache Spark RDD operation examples</a>
          <span class="badge name-badge">Oliver Szabo</span>

      </h1>
      <p>Recently we blogged about how you can write simple Apache Spark jobs and how to test them. Now we&rsquo;d like to introduce all basic RDD operations with easy examples (our goal is to come up with examples as simply as possible). The Spark <a href="http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations">documentation</a> explains well what each operations is doing in detail. We made tests for most of the RDD operations with good ol&#8217; <code>TestNG</code>. e.g.:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'> <span class="nd">@Test</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">testRightOuterJoin</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">input1</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">makeRDD</span><span class="o">(</span><span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="mi">4</span><span class="o">)))</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">input2</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">makeRDD</span><span class="o">(</span><span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="sc">&#39;1&#39;</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="sc">&#39;2&#39;</span><span class="o">)))</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">expectedOutput</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="o">(</span><span class="nc">Some</span><span class="o">(</span><span class="mi">4</span><span class="o">),</span> <span class="sc">&#39;1&#39;</span><span class="o">)),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="o">(</span><span class="nc">None</span><span class="o">,</span> <span class="sc">&#39;2&#39;</span><span class="o">)))</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">input1</span><span class="o">.</span><span class="n">rightOuterJoin</span><span class="o">(</span><span class="n">input2</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="nc">Assert</span><span class="o">.</span><span class="n">assertEquals</span><span class="o">(</span><span class="n">output</span><span class="o">.</span><span class="n">collect</span><span class="o">(),</span> <span class="n">expectedOutput</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>



      
       <a href="/blog/2014/10/23/spark-operations-overview/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row">
    <div class="col-md-2 post-meta">


      <div class="row-fluid">
        
            <a href="http://blog.sequenceiq.com/blog/2014/10/20/cascading-on-tez/#disqus_thread">Comments </a> <i class="fa fa-comments-o" style="color: #3ba9c4 !important;"></i>
        
      </div>

<span class="badge name-badge">20 October 2014</span>
      
        <div class="row-fluid">
            
            <a href="/blog/categories/apache-tez/"><span class="label label-warning">Apache Tez</span></a>
            
            <a href="/blog/categories/cascading/"><span class="label label-warning">Cascading</span></a>
            
        </div>
      
    </div>
    <div class="col-md-10 post-container">
      <h1 class="link">
          <a href="/blog/2014/10/20/cascading-on-tez/">Cascading on Apache Tez</a>
          <span class="badge name-badge">Oliver Szabo</span>

      </h1>
      <p>In one of our previous <a href="http://blog.sequenceiq.com/blog/2014/09/23/topn-on-apache-tez/">posts</a> we showed how to do a TopK using directly the Apache Tez API. In this post we’d like to show how to do a similarly complex algorithm with Cascading &ndash; running on Apache Tez.
At <a href="http://sequenceiq.com">SequenceIQ</a> we use Scalding, Cascading and Spark to write most of our jobs. For a while our big data pipeline API called <a href="http://docs.banzai.apiary.io/">Banzai Pipeline</a> offers a unified API over different runtimes: MR2, Spark and Tez; recently Cascading has announced support for Apache Tez and we’d like to show you that by writing a detailed example.</p>

<h2>Cascading Application &ndash; GroupBy, Each, Every</h2>

<p>Cascading data flows are to be constructed from Source taps (input), Sink taps (output) and Pipes.
At first, we have to setup our properties for the Cascading flow.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>    <span class="n">Properties</span> <span class="n">properties</span> <span class="o">=</span> <span class="n">AppProps</span><span class="o">.</span><span class="na">appProps</span><span class="o">()</span>
</span><span class='line'>            <span class="o">.</span><span class="na">setJarClass</span><span class="o">(</span><span class="n">Main</span><span class="o">.</span><span class="na">class</span><span class="o">)</span>
</span><span class='line'>            <span class="o">.</span><span class="na">buildProperties</span><span class="o">();</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">properties</span> <span class="o">=</span> <span class="n">FlowRuntimeProps</span><span class="o">.</span><span class="na">flowRuntimeProps</span><span class="o">()</span>
</span><span class='line'>            <span class="o">.</span><span class="na">setGatherPartitions</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
</span><span class='line'>            <span class="o">.</span><span class="na">buildProperties</span><span class="o">(</span><span class="n">properties</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Then in order to use Apache Tez, setup the Tez specific <code>Flow Connector</code>.</p>


      
       <a href="/blog/2014/10/20/cascading-on-tez/">Read on &rarr;</a> 
    </div>
  </div>



    </article>
    
  
  <div class="pagination">
    
    <a class="prev" href="/blog/page/2/">&larr; Older</a>
    

    
  </div>
</div>


                    <!--</div>-->
                  </div>

              </div>
              <div class="col-md-3">
                 <section>
  <h2 class="blue">Recent Posts</h2>
  <ul id="recent_posts" class="list-group">
    
      <li class="list-group-item">
        <a href="/blog/2014/11/17/datalake-cloudbreak-2/">Building the data lake in the cloud - Part2</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/11/13/kylin-on-docker/">Extreme OLAP Engine running in Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/11/10/new-yarn-features-part-1-label-based-scheduling/">New YARN features: Label based scheduling</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/11/06/securing-cloudbreak-with-oauth2-part-2/">Securing Cloudbreak with OAuth2 - part 2</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/11/04/yarn-timeline-service-tez/">YARN Timeline Service</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/11/02/spark-on-tez/">Spark on Tez execution context - running in Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/30/cloudbreak-devops/">Deploying a Hadoop Cluster - DevOps way</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/28/datalake-cloudbreak/">Building the data lake in the cloud - Part1</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/23/spark-operations-overview/">Apache Spark RDD operation examples</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/20/cascading-on-tez/">Cascading on Apache Tez</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/17/boot2docker-tls-workaround/">Boot2docker TLS workaround</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/16/using-uaa-as-an-identity-server/">Securing Cloudbreak with OAuth2</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/15/hadoop-metrics/">Real-time adjustments with Hadoop metrics</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/09/ngrok-docker/">Self hosted ngrok server in Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/10/07/hadoop-monitoring/">Real-time monitoring of Hadoop clusters</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/30/hortonworks-partnership/">SequenceIQ Joins Hortonworks Technology Partner Program</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/29/spark-correlation-and-testing/">Apache Spark - create and test jobs</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/26/database-upgrade-process/">Managing database upgrades with Liquibase and Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/25/strata-hadoop-world-2014/">Strata + Hadoop World 2014 Startup Showcase</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/25/euroventures-invests-in-sequenceiq/">Euroventures invests in SequenceIQ</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/24/edit-files-docker/">Edit files in Docker containers</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/23/topn-on-apache-tez/">TopK on Apache Tez</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/19/apache-tez-cluster/">Apache Tez cluster on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/18/custom-image-on-gcc/">Cloudbreak new provider implementation - Part I: Build your custom image</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/17/spark-1-1-0-docker/">Apache Spark 1.1.0 on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/15/hadoop-2-5-1-docker/">Apache Hadoop 2.5.1 on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/11/apache-drill-docker/">Apache Drill on Docker - query as a service </a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/09/yarn-schedulers-demystified-part-2-fair/">YARN Schedulers demystified - Part 2: Fair</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/05/apache-ambari-1-7-0-ea/">Apache Ambari 1.7.0 early access</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/04/sql-on-hbase-with-apache-phoenix/">SQL on HBase with Apache Phoenix</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/09/01/sla-samples-periscope/">SLA policies for autoscaling Hadoop clusters</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/29/aws-cloudformation-makes-everything-easier/">Infrastructure management with CloudFormation</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/27/announcing-periscope/">Periscope - autoscaling for Hadoop YARN</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/22/spark-submit-in-java/">Submit a Spark job to YARN from code</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/18/hadoop-2-5-0-docker/">Apache Hadoop 2.5.0 on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/16/fairplay/">Fair play</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/12/docker-networking/">Docker intercontainer networking explained</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/07/clodubreak-shell/">Create Hadoop clusters in the cloud using a CLI</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/08/04/launch-docker-containers-on-azure/">Launch Docker containers on Azure</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/31/spark-mllib/">Apache Spark - MLlib Introduction</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/25/cloudbreak-technology/">Docker ships Hadoop to the cloud</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/22/schedulers-part-1/">YARN Schedulers demystified - Part 1: Capacity</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/18/announcing-cloudbreak/">Cloudbreak - the Hadoop as a Service API</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/13/groovy-and-java-runtime-bug/">Groovy and Java, the runtime bug</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/09/ambari-configuration-service/">Apache Ambari configuration service</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/05/docker-debug-with-nsenter-on-boot2docker/">Docker debug with nsenter on boot2docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/07/02/move-applications-between-queues/">Re-prioritize running jobs with YARN schedulers</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/06/25/hadoop-2-4-0-docker/">Apache Hadoop 2.4.1 on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/06/23/scalding-correlation-example/">Pearson correlation with Scalding</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/06/19/multinode-hadoop-cluster-on-docker/">Multi-node Hadoop cluster on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/06/17/ambari-cluster-on-docker/">Ambari provisioned Hadoop cluster on Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/06/06/hadoop-summit-slides/">Hadoop Summit 2014 - SequenceIQ slides</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/05/26/ambari-shell/">Apache Ambari + Spring Shell = Ambari Shell</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/05/09/building-the-build-environment-with-ansible-and-docker/">Building the build environment with Ansible and Docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/05/01/mapreduce-job-profiling-with-R/">Job profiling with R</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/04/17/apache-phoenix-sneak-peak/">Apache Phoenix (sneak peak)</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/04/14/mapreduce-with-scalding/">Writing MapReduce jobs in Scala</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/04/04/hadoop-docker-introduction/">Hadoop on Docker introduction</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/31/mahout-on-tez/">Using Mahout with Tez</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/24/hoya-at-sequenceiq/">Using Hortonworks Hoya at SequenceIQ</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/19/hadoop-2-dot-3-with-docker/">Hadoop 2.3 with docker</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/14/yarn-capacity-scheduler/">YARN Capacity Scheduler</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/11/data-cleaning-with-mapreduce-and-morphlines/">Data cleaning with MapReduce and Morphlines</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/07/read-from-hdfs/">HDFS and java.nio.channels</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/03/05/access-hdp2-sandbox/">Accessing HDP2 sandbox from the host</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/02/28/etl-and-data-quality/">ETL - producing better quality data</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/02/26/vote-for-us/">Vote for us - 2014 Hadoop Summit San Jose</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/02/22/custom-flume-source/">Custom Apache Flume source</a>
      </li>
    
      <li class="list-group-item">
        <a href="/blog/2014/02/07/hdp2-on-amazon/">Set up HDP2 on Amazon EC2</a>
      </li>
    
  </ul>
</section>

              </div>
      </div>
  </div>
  <div class="row-fluid" id="footer-container">
    <div class="container">
        <footer class="footer-page" role="contentinfo">
            <div class="row">
                <div class="col-md-6">
                    <div class="row">
    
    <div class="col-md-1"><a class="social-link" href="http://github.com/sequenceiq" title="Github Profile"><i class="fa fa-github fa-lg"></i></a></div>
    
    
    
    <div class="col-md-1"><a class="social-link" href="http://linkedin.com/company/sequenceiq" title="Linkedin Profile"><i class="fa fa-linkedin fa-lg"></i></a></div>
    
    
    <div class="col-md-1"><a class="social-link" href="http://twitter.com/sequenceiq" title="Twitter Profile"><i class="fa fa-twitter fa-lg"></i></a></div>
    
    
    
    <div class="col-md-1"><a class="social-link" href="http://facebook.com/sequenceiq" title="Facebook Profile"><i class="fa fa-facebook fa-lg"></i></a></div>
    
    

    
    <div class="col-md-1"><a class="social-link" href="http://blog.sequenceiq.com/atom.xml" title="RSS"><i class="fa fa-rss fa-lg"></i></a></div>

</div>

                </div>
                <div class="col-md-5">
                    


<p class="pull-right" >
  <span class="credit">&copy; SequenceIQ Inc. 2014. All rights reserved. </span>
    <br><a href="pp.html" style="color: #508190;">Privacy Policy</a> &nbsp; <a href="tos.html" style="color: #508190;">Terms of Service</a></p>
</p>


                </div>
            </div>
        </footer>
    </div>

  </div>
  

<script type="text/javascript">
      var disqus_shortname = 'sequenceiqblog';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=625149054184531";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>




  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-48528840-1', 'sequenceiq.com');
  ga('send', 'pageview');

</script>
</html>
